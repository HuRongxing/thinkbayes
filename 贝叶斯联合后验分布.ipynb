{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 狮子、老虎和熊"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们参观野生动物园保护区，看到了3只狮子、2只老虎和1头熊，如果我们观察到任何动物的机会均等，那么动物园所有动物中，狮子、老虎和熊的占比各是多少？  \n",
    "先验分布可以假定每种动物的占比是一样的，但各类动物占比不是独立的，所有的占比之和为1。可以用狄利克雷分布来建模。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 狄利克雷分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**狄利克雷分布**$Dir(\\alpha)$ , 是一组$k$个连续多元随机分布的分布族，这组多元连续分布随机变量的参数为$\\mathbf{a}=(\\alpha_{1}, \\alpha_{2}, \\cdots, \\alpha_{k})$，$\\alpha_{i}\\geq0$。它是贝塔（$\\mathrm {B} $）分布在多元维度上的推广，也被称为多元贝塔布(MBD)。在贝叶斯理论中，狄利克雷分布是分类分布和多项式分布的共轭先验分布，因此常被用作先验分布。狄利克雷分布的密度函数为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$f\\left( {{x}_{1}},\\cdots ,{{x}_{k}};{{\\alpha }_{1}},\\cdots ,{{\\alpha }_{k}} \\right)=\\dfrac{1}{\\mathrm {B}\\left( \\alpha  \\right)}\\prod\\limits_{i=1}^{K}{x_{i}^{{{\\alpha }_{i}}-1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "且对于所有$i\\in [1,K]$，满足以下条件："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\left\\{ \\begin{matrix}\n",
    "   \\sum\\limits_{i=1}^{k}{{{x}_{i}}=1}  \\\\\n",
    "   {{x}_{i}}\\ge 0  \\\\\n",
    "   {{\\alpha }_{i}}\\ge 0  \\\\\n",
    "\\end{matrix} \\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "其中归一化常数$\\mathrm {B}$为："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$${\\displaystyle \\mathrm {B} ({\\boldsymbol {\\alpha }})={\\frac {\\prod _{i=1}^{K}\\Gamma (\\alpha _{i})}{\\Gamma \\left(\\sum _{i=1}^{K}\\alpha _{i}\\right)}},\\qquad {\\boldsymbol {\\alpha }}=(\\alpha _{1},\\ldots ,\\alpha _{K})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "狄利克雷分布的**边缘分布**是贝塔分布：\n",
    "$${\\displaystyle X_{i}\\sim \\operatorname {Beta} (\\alpha _{i},\\alpha _{0}-\\alpha _{i})}$$其中，$$\\displaystyle{\\alpha_0 = \\sum_1^k \\alpha_i}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2 类Dirichlet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import Beta, MakePmfFromItems, MakePmfFromDict\n",
    "import numpy\n",
    "\n",
    "class Dirichlet(object):\n",
    "    \"\"\"狄利克雷分布模型。\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, n, conc=1, name=''):\n",
    "        \"\"\"初始化狄利克雷分布\n",
    "        n: 维度\n",
    "        conc: 集中度参数 (数值越小，集中度越高)\n",
    "        name: 实例的名称\n",
    "        \"\"\"\n",
    "        if n < 2:\n",
    "            raise ValueError('狄利克雷分布的维数应当大于或等于2')\n",
    "\n",
    "        self.n = n\n",
    "        self.params = numpy.ones(n, dtype=numpy.float) * conc\n",
    "        self.name = name\n",
    "\n",
    "    def Update(self, data):\n",
    "        \"\"\"更新分布。\n",
    "        data: 观测值构成的列表，与对应参数顺序保持一致。\"\"\"\n",
    "        m = len(data)\n",
    "        self.params[:m] += data\n",
    "\n",
    "    def Random(self):\n",
    "        \"\"\"从分布生成随机变量。gamma抽样。\n",
    "\n",
    "        Returns:归一化向量（列表）\n",
    "        \"\"\"\n",
    "        p = numpy.random.gamma(self.params)\n",
    "        return p / p.sum()\n",
    "\n",
    "    def Likelihood(self, data):\n",
    "        \"\"\"似然函数。\n",
    "        从分布组合中选择一个随机的概率向量。\n",
    "        \n",
    "        Returns: 概率值\n",
    "        \"\"\"\n",
    "        m = len(data)\n",
    "        if self.n < m:\n",
    "            return 0\n",
    "\n",
    "        x = data\n",
    "        p = self.Random()\n",
    "        q = p[:m] ** x\n",
    "        return q.prod()\n",
    "\n",
    "    def LogLikelihood(self, data):\n",
    "        \"\"\"对数似然分布.\n",
    "\n",
    "        Returns: 对数概率值。\n",
    "        \"\"\"\n",
    "        m = len(data)\n",
    "        if self.n < m:\n",
    "            return float('-inf')\n",
    "\n",
    "        x = self.Random()\n",
    "        y = numpy.log(x[:m]) * data\n",
    "        return y.sum()\n",
    "\n",
    "    def MarginalBeta(self, i):\n",
    "        \"\"\"计算第i个元分布的边际分布（Beta分布）.\n",
    "\n",
    "        i: int\n",
    "        Returns: Beta分布\n",
    "        \"\"\"\n",
    "        alpha0 = self.params.sum()\n",
    "        alpha = self.params[i]\n",
    "        # Beta是在tools中定义的一个类\n",
    "        return Beta(alpha, alpha0 - alpha)\n",
    "\n",
    "    def PredictivePmf(self, xs, name=''):\n",
    "        \"\"\"Makes a predictive distribution.\n",
    "\n",
    "        xs: values to go into the Pmf\n",
    "\n",
    "        Returns: Pmf that maps from x to the mean prevalence of x\n",
    "        \"\"\"\n",
    "        alpha0 = self.params.sum()\n",
    "        ps = self.params / alpha0\n",
    "        return MakePmfFromItems(zip(xs, ps), name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Dirichlet类的__init__()方法的初始化功能很简单，只需要指定维度并给出集中度参数即可。狄利克雷分布的边缘分布是Beta分布， Dirichlet类的MarginalBeta（）方法可用于计算随机变量的边缘分布。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3 种群密度的后验分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "狮子的占比的先验分布均值为:0.33。\n",
      "老虎的占比的先验分布均值为:0.33。\n",
      "熊的占比的先验分布均值为:0.33。\n"
     ]
    }
   ],
   "source": [
    "dirichlet = Dirichlet(3)\n",
    "names = ['狮子','老虎','熊']\n",
    "for i in range(3):\n",
    "    beta = dirichlet.MarginalBeta(i)\n",
    "    print(F\"{names[i]}的占比的先验分布均值为:{beta.Mean():.02}。\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "狄利克雷分布是分类分布和多项式分布的共轭先验分布，因此在Update方法中只需将参数简单相加即可。结果如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data = [3,2,1]\n",
    "dirichlet.Update(data)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(6,4))\n",
    "for i in range(3):\n",
    "    beta = dirichlet.MarginalBeta(i)\n",
    "    beta_pmf = beta.MakePmf()\n",
    "    \n",
    "    x,y = zip(*beta_pmf.Items())\n",
    "    plt.plot(x,y,label=names[i])   \n",
    "\n",
    "plt.title(\"简单假设情况下种群密度的后验分布\")\n",
    "plt.xlabel('种群密度')\n",
    "plt.ylabel('概率值')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 分层版本的种群分布"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在，我们将问题升级。前面的例子，我们只假定保护区只有3种动物，这显然不符合现实。现在我们要考虑保护区还有其他动物的情况下，狮子、老虎和熊的占比是多少？\n",
    "这个问题，我们可以分解为通过两个层次：第一个层次，保护区有多少种动物？第二个层次，各类动物的占比是多少？对此，我们需要编写两个层次的Suite对象，最上层的Suite对象代表种群数量，它的各个假设也是Suite对象，代表各个种群的占比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools import Suite\n",
    "class Species(Suite):\n",
    "    \"\"\"种群数量\"\"\"\n",
    "    \n",
    "    def __init__(self, ns, conc=1, iters=1000):\n",
    "        hypos = [Dirichlet(n, conc) for n in ns]\n",
    "        Suite.__init__(self, hypos)\n",
    "        # 不会直接求似然值，而是采用样本抽样，iters为抽样次数\n",
    "        self.iters = iters\n",
    "\n",
    "    def Update(self, data):\n",
    "        \"\"\"更新数据\n",
    "\n",
    "        data: 观测到的动物频率构成的列表。\n",
    "        \"\"\"\n",
    "        # 调用父类中的Update方法，它将调用本类中的Likelihood方法\n",
    "        Suite.Update(self, data)\n",
    "\n",
    "        # 更新下层的Suite对象\n",
    "        for hypo in self.Values():\n",
    "            hypo.Update(data)\n",
    "\n",
    "    def Likelihood(self, data, hypo):\n",
    "        \"\"\"当前假设下的似然函数\n",
    "\n",
    "        hypo: Dirichlet对象\n",
    "        data: 观测到的种群频率列表\n",
    "        \"\"\"\n",
    "        dirichlet = hypo\n",
    "\n",
    "        # draw sample Likelihoods from the hypothetical Dirichlet dist\n",
    "        # and add them up\n",
    "        like = 0\n",
    "        for _ in range(self.iters):\n",
    "            like += dirichlet.Likelihood(data)\n",
    "\n",
    "        # correct for the number of ways the observed species\n",
    "        # might have been chosen from all species\n",
    "        m = len(data)\n",
    "        like *= thinkbayes.BinomialCoef(dirichlet.n, m)\n",
    "\n",
    "        return like\n",
    "\n",
    "    def DistN(self):\n",
    "        \"\"\"Computes the distribution of n.\"\"\"\n",
    "        pmf = thinkbayes.Pmf()\n",
    "        for hypo, prob in self.Items():\n",
    "            pmf.Set(hypo.n, prob)\n",
    "        return pmf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "狄利克雷分布是分类分布和多项式分布的共轭先验分布。这意味着，如果**随机变量**$X$服从分类分布或多项式分布，并且该**分布的参数**$\\mathbf{a}$的先验分布服从狄利克雷分布，则该**参数**$\\mathbf{a}$的后验分布也服从狄利克雷分布。即，如果：\n",
    "$${\\displaystyle {\\begin{array}{rcccl}{\\boldsymbol {\\alpha }}&=&\\left(\\alpha _{1},\\ldots ,\\alpha _{K}\\right)&=&{\\text{比例参数}}\\\\\\mathbf {p} \\mid {\\boldsymbol {\\alpha }}&=&\\left(p_{1},\\ldots ,p_{K}\\right)&\\sim &\\operatorname {Dir} (K,{\\boldsymbol {\\alpha }})\\\\\n",
    "\\mathbb {X} \\mid \\mathbf {p} &=&\\left(\\mathbf {x} _{1},\\ldots ,\\mathbf {x} _{K}\\right)&\\sim &\\operatorname {Cat} (K,\\mathbf {p} )\\end{array}}}$$\n",
    "则以下结论成立：\n",
    "$${\\displaystyle {\\begin{array}{rcccl}\\mathbf {c} &=&\\left(c_{1},\\ldots ,c_{K}\\right)&=&{\\text{各类别出现的次数 }}i\\\\\n",
    "\\mathbf {p} \\mid \\mathbb {X} ,{\\boldsymbol {\\alpha }}&\\sim &\\operatorname {Dir} (K,\\mathbf {c} +{\\boldsymbol {\\alpha }})&=&\\operatorname {Dir} \\left(K,c_{1}+\\alpha _{1},\\ldots ,c_{K}+\\alpha _{K}\\right)\\end{array}}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print'. Did you mean print(self.code, clean_param)? (<ipython-input-5-1895ca9872cd>, line 110)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-1895ca9872cd>\"\u001b[0;36m, line \u001b[0;32m110\u001b[0m\n\u001b[0;31m    print self.code, clean_param\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m Missing parentheses in call to 'print'. Did you mean print(self.code, clean_param)?\n"
     ]
    }
   ],
   "source": [
    "\"\"\"This file contains code used in \"Think Bayes\",\n",
    "by Allen B. Downey, available from greenteapress.com\n",
    "\n",
    "Copyright 2012 Allen B. Downey\n",
    "License: GNU GPLv3 http://www.gnu.org/licenses/gpl.html\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "import thinkplot\n",
    "import numpy\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import shelve\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import thinkbayes\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('error', RuntimeWarning)\n",
    "\n",
    "\n",
    "FORMATS = ['pdf', 'eps', 'png']\n",
    "\n",
    "\n",
    "class Locker(object):\n",
    "    \"\"\"Encapsulates a shelf for storing key-value pairs.\"\"\"\n",
    "\n",
    "    def __init__(self, shelf_file):\n",
    "        self.shelf = shelve.open(shelf_file)\n",
    "\n",
    "    def Close(self):\n",
    "        \"\"\"Closes the shelf.\n",
    "        \"\"\"\n",
    "        self.shelf.close()\n",
    "\n",
    "    def Add(self, key, value):\n",
    "        \"\"\"Adds a key-value pair.\"\"\"\n",
    "        self.shelf[str(key)] = value\n",
    "\n",
    "    def Lookup(self, key):\n",
    "        \"\"\"Looks up a key.\"\"\"\n",
    "        return self.shelf.get(str(key))\n",
    "\n",
    "    def Keys(self):\n",
    "        \"\"\"Returns an iterator of keys.\"\"\"\n",
    "        return self.shelf.iterkeys()\n",
    "\n",
    "    def Read(self):\n",
    "        \"\"\"Returns the contents of the shelf as a map.\"\"\"\n",
    "        return dict(self.shelf)\n",
    "\n",
    "\n",
    "class Subject(object):\n",
    "    \"\"\"Represents a subject from the belly button study.\"\"\"\n",
    "\n",
    "    def __init__(self, code):\n",
    "        \"\"\"\n",
    "        code: string ID\n",
    "        species: sequence of (int count, string species) pairs\n",
    "        \"\"\"\n",
    "        self.code = code\n",
    "        self.species = []\n",
    "        self.suite = None\n",
    "        self.num_reads = None\n",
    "        self.num_species = None\n",
    "        self.total_reads = None\n",
    "        self.total_species = None\n",
    "        self.prev_unseen = None\n",
    "        self.pmf_n = None\n",
    "        self.pmf_q = None\n",
    "        self.pmf_l = None\n",
    "\n",
    "    def Add(self, species, count):\n",
    "        \"\"\"Add a species-count pair.\n",
    "\n",
    "        It is up to the caller to ensure that species names are unique.\n",
    "\n",
    "        species: string species/genus name\n",
    "        count: int number of individuals\n",
    "        \"\"\"\n",
    "        self.species.append((count, species))\n",
    "\n",
    "    def Done(self, reverse=False, clean_param=0):\n",
    "        \"\"\"Called when we are done adding species counts.\n",
    "\n",
    "        reverse: which order to sort in\n",
    "        \"\"\"\n",
    "        if clean_param:\n",
    "            self.Clean(clean_param)\n",
    "\n",
    "        self.species.sort(reverse=reverse)        \n",
    "        counts = self.GetCounts()\n",
    "        self.num_species = len(counts)\n",
    "        self.num_reads = sum(counts)\n",
    "\n",
    "    def Clean(self, clean_param=50):\n",
    "        \"\"\"Identifies and removes bogus data.\n",
    "\n",
    "        clean_param: parameter that controls the number of legit species\n",
    "        \"\"\"\n",
    "        def prob_bogus(k, r):\n",
    "            \"\"\"Compute the probability that a species is bogus.\"\"\"\n",
    "            q = clean_param / r\n",
    "            p = (1-q) ** k\n",
    "            return p\n",
    "\n",
    "        print self.code, clean_param\n",
    "\n",
    "        counts = self.GetCounts()\n",
    "        r = 1.0 * sum(counts)\n",
    "\n",
    "        species_seq = []\n",
    "        for k, species in sorted(self.species):\n",
    "\n",
    "            if random.random() < prob_bogus(k, r):\n",
    "                continue\n",
    "            species_seq.append((k, species))\n",
    "        self.species = species_seq\n",
    "\n",
    "    def GetM(self):\n",
    "        \"\"\"Gets number of observed species.\"\"\"\n",
    "        return len(self.species)\n",
    "        \n",
    "    def GetCounts(self):\n",
    "        \"\"\"Gets the list of species counts\n",
    "\n",
    "        Should be in increasing order, if Sort() has been invoked.\n",
    "        \"\"\"\n",
    "        return [count for count, _ in self.species]\n",
    "\n",
    "    def MakeCdf(self):\n",
    "        \"\"\"Makes a CDF of total prevalence vs rank.\"\"\"\n",
    "        counts = self.GetCounts()\n",
    "        counts.sort(reverse=True)\n",
    "        cdf = thinkbayes.MakeCdfFromItems(enumerate(counts))\n",
    "        return cdf\n",
    "\n",
    "    def GetNames(self):\n",
    "        \"\"\"Gets the names of the seen species.\"\"\"\n",
    "        return [name for _, name in self.species]\n",
    "\n",
    "    def PrintCounts(self):\n",
    "        \"\"\"Prints the counts and species names.\"\"\"\n",
    "        for count, name in reversed(self.species):\n",
    "            print count, name\n",
    "\n",
    "    def GetSpecies(self, index):\n",
    "        \"\"\"Gets the count and name of the indicated species.\n",
    "\n",
    "        Returns: count-species pair\n",
    "        \"\"\"\n",
    "        return self.species[index]\n",
    "\n",
    "    def GetCdf(self):\n",
    "        \"\"\"Returns cumulative prevalence vs number of species.\n",
    "        \"\"\"\n",
    "        counts = self.GetCounts()\n",
    "        items = enumerate(counts)\n",
    "        cdf = thinkbayes.MakeCdfFromItems(items)\n",
    "        return cdf\n",
    "\n",
    "    def GetPrevalences(self):\n",
    "        \"\"\"Returns a sequence of prevalences (normalized counts).\n",
    "        \"\"\"\n",
    "        counts = self.GetCounts()\n",
    "        total = sum(counts)\n",
    "        prevalences = numpy.array(counts, dtype=numpy.float) / total\n",
    "        return prevalences\n",
    "\n",
    "    def Process(self, low=None, high=500, conc=1, iters=100):\n",
    "        \"\"\"Computes the posterior distribution of n and the prevalences.\n",
    "\n",
    "        Sets attribute: self.suite\n",
    "\n",
    "        low: minimum number of species\n",
    "        high: maximum number of species\n",
    "        conc: concentration parameter\n",
    "        iters: number of iterations to use in the estimator\n",
    "        \"\"\"\n",
    "        counts = self.GetCounts()\n",
    "        m = len(counts)\n",
    "        if low is None:\n",
    "            low = max(m, 2)\n",
    "        ns = range(low, high+1)\n",
    "\n",
    "        #start = time.time()    \n",
    "        self.suite = Species5(ns, conc=conc, iters=iters)\n",
    "        self.suite.Update(counts)\n",
    "        #end = time.time()\n",
    "\n",
    "        #print 'Processing time' end-start\n",
    "\n",
    "    def MakePrediction(self, num_sims=100):\n",
    "        \"\"\"Make predictions for the given subject.\n",
    "\n",
    "        Precondition: Process has run\n",
    "\n",
    "        num_sims: how many simulations to run for predictions\n",
    "\n",
    "        Adds attributes\n",
    "        pmf_l: predictive distribution of additional species\n",
    "        \"\"\"\n",
    "        add_reads = self.total_reads - self.num_reads\n",
    "        curves = self.RunSimulations(num_sims, add_reads)\n",
    "        self.pmf_l = self.MakePredictive(curves)\n",
    "\n",
    "    def MakeQuickPrediction(self, num_sims=100):\n",
    "        \"\"\"Make predictions for the given subject.\n",
    "\n",
    "        Precondition: Process has run\n",
    "\n",
    "        num_sims: how many simulations to run for predictions\n",
    "\n",
    "        Adds attribute:\n",
    "        pmf_l: predictive distribution of additional species\n",
    "        \"\"\"\n",
    "        add_reads = self.total_reads - self.num_reads\n",
    "        pmf = thinkbayes.Pmf()\n",
    "        _, seen = self.GetSeenSpecies()\n",
    "\n",
    "        for _ in range(num_sims):\n",
    "            _, observations = self.GenerateObservations(add_reads)\n",
    "            all_seen = seen.union(observations)\n",
    "            l = len(all_seen) - len(seen)\n",
    "            pmf.Incr(l)\n",
    "\n",
    "        pmf.Normalize()\n",
    "        self.pmf_l = pmf\n",
    "\n",
    "    def DistL(self):\n",
    "        \"\"\"Returns the distribution of additional species, l.\n",
    "        \"\"\"\n",
    "        return self.pmf_l\n",
    "\n",
    "    def MakeFigures(self):\n",
    "        \"\"\"Makes figures showing distribution of n and the prevalences.\"\"\"\n",
    "        self.PlotDistN()\n",
    "        self.PlotPrevalences()\n",
    "\n",
    "    def PlotDistN(self):\n",
    "        \"\"\"Plots distribution of n.\"\"\"\n",
    "        pmf = self.suite.DistN()\n",
    "        print '90% CI for N:', pmf.CredibleInterval(90)\n",
    "        pmf.name = self.code\n",
    "\n",
    "        thinkplot.Clf()\n",
    "        thinkplot.PrePlot(num=1)\n",
    "\n",
    "        thinkplot.Pmf(pmf)\n",
    "\n",
    "        root = 'species-ndist-%s' % self.code\n",
    "        thinkplot.Save(root=root,\n",
    "                    xlabel='Number of species',\n",
    "                    ylabel='Prob',\n",
    "                    formats=FORMATS,\n",
    "                    )\n",
    "\n",
    "    def PlotPrevalences(self, num=5):\n",
    "        \"\"\"Plots dist of prevalence for several species.\n",
    "\n",
    "        num: how many species (starting with the highest prevalence)\n",
    "        \"\"\"\n",
    "        thinkplot.Clf()\n",
    "        thinkplot.PrePlot(num=5)\n",
    "\n",
    "        for rank in range(1, num+1):\n",
    "            self.PlotPrevalence(rank)\n",
    "\n",
    "        root = 'species-prev-%s' % self.code\n",
    "        thinkplot.Save(root=root,\n",
    "                    xlabel='Prevalence',\n",
    "                    ylabel='Prob',\n",
    "                    formats=FORMATS,\n",
    "                    axis=[0, 0.3, 0, 1],\n",
    "                    )\n",
    "\n",
    "    def PlotPrevalence(self, rank=1, cdf_flag=True):\n",
    "        \"\"\"Plots dist of prevalence for one species.\n",
    "\n",
    "        rank: rank order of the species to plot.\n",
    "        cdf_flag: whether to plot the CDF\n",
    "        \"\"\"\n",
    "        # convert rank to index\n",
    "        index = self.GetM() - rank\n",
    "\n",
    "        _, mix = self.suite.DistOfPrevalence(index)\n",
    "        count, _ = self.GetSpecies(index)\n",
    "        mix.name = '%d (%d)' % (rank, count)\n",
    "\n",
    "        print '90%% CI for prevalence of species %d:' % rank, \n",
    "        print mix.CredibleInterval(90)\n",
    "\n",
    "        if cdf_flag:\n",
    "            cdf = mix.MakeCdf()\n",
    "            thinkplot.Cdf(cdf)\n",
    "        else:\n",
    "            thinkplot.Pmf(mix)\n",
    "\n",
    "    def PlotMixture(self, rank=1):\n",
    "        \"\"\"Plots dist of prevalence for all n, and the mix.\n",
    "\n",
    "        rank: rank order of the species to plot\n",
    "        \"\"\"\n",
    "        # convert rank to index\n",
    "        index = self.GetM() - rank\n",
    "\n",
    "        print self.GetSpecies(index)\n",
    "        print self.GetCounts()[index]\n",
    "\n",
    "        metapmf, mix = self.suite.DistOfPrevalence(index)\n",
    "\n",
    "        thinkplot.Clf()\n",
    "        for pmf in metapmf.Values():\n",
    "            thinkplot.Pmf(pmf, color='blue', alpha=0.2, linewidth=0.5)\n",
    "\n",
    "        thinkplot.Pmf(mix, color='blue', alpha=0.9, linewidth=2)\n",
    "\n",
    "        root = 'species-mix-%s' % self.code\n",
    "        thinkplot.Save(root=root,\n",
    "                    xlabel='Prevalence',\n",
    "                    ylabel='Prob',\n",
    "                    formats=FORMATS,\n",
    "                    axis=[0, 0.3, 0, 0.3],\n",
    "                    legend=False)\n",
    "\n",
    "    def GetSeenSpecies(self):\n",
    "        \"\"\"Makes a set of the names of seen species.\n",
    "\n",
    "        Returns: number of species, set of string species names\n",
    "        \"\"\"\n",
    "        names = self.GetNames()\n",
    "        m = len(names)\n",
    "        seen = set(SpeciesGenerator(names, m))\n",
    "        return m, seen\n",
    "\n",
    "    def GenerateObservations(self, num_reads):\n",
    "        \"\"\"Generates a series of random observations.\n",
    "\n",
    "        num_reads: number of reads to generate\n",
    "\n",
    "        Returns: number of species, sequence of string species names\n",
    "        \"\"\"\n",
    "        n, prevalences = self.suite.SamplePosterior()\n",
    "\n",
    "        names = self.GetNames()\n",
    "        name_iter = SpeciesGenerator(names, n)\n",
    "\n",
    "        items = zip(name_iter, prevalences)\n",
    "\n",
    "        cdf = thinkbayes.MakeCdfFromItems(items)\n",
    "        observations = cdf.Sample(num_reads)\n",
    "\n",
    "        #for ob in observations:\n",
    "        #    print ob\n",
    "\n",
    "        return n, observations\n",
    "\n",
    "    def Resample(self, num_reads):\n",
    "        \"\"\"Choose a random subset of the data (without replacement).\n",
    "\n",
    "        num_reads: number of reads in the subset\n",
    "        \"\"\"\n",
    "        t = []\n",
    "        for count, species in self.species:\n",
    "            t.extend([species]*count)\n",
    "\n",
    "        random.shuffle(t)\n",
    "        reads = t[:num_reads]\n",
    "\n",
    "        subject = Subject(self.code)\n",
    "        hist = thinkbayes.MakeHistFromList(reads)\n",
    "        for species, count in hist.Items():\n",
    "            subject.Add(species, count)\n",
    "\n",
    "        subject.Done()\n",
    "        return subject\n",
    "\n",
    "    def Match(self, match):\n",
    "        \"\"\"Match up a rarefied subject with a complete subject.\n",
    "\n",
    "        match: complete Subject\n",
    "\n",
    "        Assigns attributes:\n",
    "        total_reads:\n",
    "        total_species:\n",
    "        prev_unseen:\n",
    "        \"\"\"\n",
    "        self.total_reads = match.num_reads\n",
    "        self.total_species = match.num_species\n",
    "\n",
    "        # compute the prevalence of unseen species (at least approximately,\n",
    "        # based on all species counts in match\n",
    "        _, seen = self.GetSeenSpecies()\n",
    "\n",
    "        seen_total = 0.0\n",
    "        unseen_total = 0.0\n",
    "        for count, species in match.species:\n",
    "            if species in seen:\n",
    "                seen_total += count\n",
    "            else:\n",
    "                unseen_total += count\n",
    "\n",
    "        self.prev_unseen = unseen_total / (seen_total + unseen_total)\n",
    "\n",
    "    def RunSimulation(self, num_reads, frac_flag=False, jitter=0.01):\n",
    "        \"\"\"Simulates additional observations and returns a rarefaction curve.\n",
    "\n",
    "        k is the number of additional observations\n",
    "        num_new is the number of new species seen\n",
    "\n",
    "        num_reads: how many new reads to simulate\n",
    "        frac_flag: whether to convert to fraction of species seen\n",
    "        jitter: size of jitter added if frac_flag is true\n",
    "\n",
    "        Returns: list of (k, num_new) pairs\n",
    "        \"\"\"\n",
    "        m, seen = self.GetSeenSpecies()\n",
    "        n, observations = self.GenerateObservations(num_reads)\n",
    "\n",
    "        curve = []\n",
    "        for i, obs in enumerate(observations):\n",
    "            seen.add(obs)\n",
    "\n",
    "            if frac_flag:\n",
    "                frac_seen = len(seen) / float(n)\n",
    "                frac_seen += random.uniform(-jitter, jitter)\n",
    "                curve.append((i+1, frac_seen))\n",
    "            else:\n",
    "                num_new = len(seen) - m\n",
    "                curve.append((i+1, num_new))\n",
    "\n",
    "        return curve\n",
    "\n",
    "    def RunSimulations(self, num_sims, num_reads, frac_flag=False):\n",
    "        \"\"\"Runs simulations and returns a list of curves.\n",
    "\n",
    "        Each curve is a sequence of (k, num_new) pairs.\n",
    "\n",
    "        num_sims: how many simulations to run\n",
    "        num_reads: how many samples to generate in each simulation\n",
    "        frac_flag: whether to convert num_new to fraction of total\n",
    "        \"\"\"\n",
    "        curves = [self.RunSimulation(num_reads, frac_flag) \n",
    "                  for _ in range(num_sims)]\n",
    "        return curves\n",
    "\n",
    "    def MakePredictive(self, curves):\n",
    "        \"\"\"Makes a predictive distribution of additional species.\n",
    "\n",
    "        curves: list of (k, num_new) curves \n",
    "\n",
    "        Returns: Pmf of num_new\n",
    "        \"\"\"\n",
    "        pred = thinkbayes.Pmf(name=self.code)\n",
    "        for curve in curves:\n",
    "            _, last_num_new = curve[-1]\n",
    "            pred.Incr(last_num_new)\n",
    "        pred.Normalize()\n",
    "        return pred\n",
    "\n",
    "\n",
    "def MakeConditionals(curves, ks):\n",
    "    \"\"\"Makes Cdfs of the distribution of num_new conditioned on k.\n",
    "\n",
    "    curves: list of (k, num_new) curves \n",
    "    ks: list of values of k\n",
    "\n",
    "    Returns: list of Cdfs\n",
    "    \"\"\"\n",
    "    joint = MakeJointPredictive(curves)\n",
    "\n",
    "    cdfs = []\n",
    "    for k in ks:\n",
    "        pmf = joint.Conditional(1, 0, k)\n",
    "        pmf.name = 'k=%d' % k\n",
    "        cdf = pmf.MakeCdf()\n",
    "        cdfs.append(cdf)\n",
    "        print '90%% credible interval for %d' % k,\n",
    "        print cdf.CredibleInterval(90)\n",
    "    return cdfs\n",
    "\n",
    "\n",
    "def MakeJointPredictive(curves):\n",
    "    \"\"\"Makes a joint distribution of k and num_new.\n",
    "\n",
    "    curves: list of (k, num_new) curves \n",
    "\n",
    "    Returns: joint Pmf of (k, num_new)\n",
    "    \"\"\"\n",
    "    joint = thinkbayes.Joint()\n",
    "    for curve in curves:\n",
    "        for k, num_new in curve:\n",
    "            joint.Incr((k, num_new))\n",
    "    joint.Normalize()\n",
    "    return joint\n",
    "\n",
    "\n",
    "def MakeFracCdfs(curves, ks):\n",
    "    \"\"\"Makes Cdfs of the fraction of species seen.\n",
    "\n",
    "    curves: list of (k, num_new) curves \n",
    "\n",
    "    Returns: list of Cdfs\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    for curve in curves:\n",
    "        for k, frac in curve:\n",
    "            if k in ks:\n",
    "                d.setdefault(k, []).append(frac)\n",
    "\n",
    "    cdfs = {}\n",
    "    for k, fracs in d.iteritems():\n",
    "        cdf = thinkbayes.MakeCdfFromList(fracs)\n",
    "        cdfs[k] = cdf\n",
    "\n",
    "    return cdfs\n",
    "\n",
    "def SpeciesGenerator(names, num):\n",
    "    \"\"\"Generates a series of names, starting with the given names.\n",
    "\n",
    "    Additional names are 'unseen' plus a serial number.\n",
    "\n",
    "    names: list of strings\n",
    "    num: total number of species names to generate\n",
    "\n",
    "    Returns: string iterator\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    for name in names:\n",
    "        yield name\n",
    "        i += 1\n",
    "\n",
    "    while i < num:\n",
    "        yield 'unseen-%d' % i\n",
    "        i += 1\n",
    "            \n",
    "\n",
    "def ReadRarefactedData(filename='journal.pone.0047712.s001.csv', \n",
    "                       clean_param=0):\n",
    "    \"\"\"Reads a data file and returns a list of Subjects.\n",
    "\n",
    "    Data from http://www.plosone.org/article/\n",
    "    info%3Adoi%2F10.1371%2Fjournal.pone.0047712#s4\n",
    "\n",
    "    filename: string filename to read\n",
    "    clean_param: parameter passed to Clean\n",
    "\n",
    "    Returns: map from code to Subject\n",
    "    \"\"\"\n",
    "    fp = open(filename)\n",
    "    reader = csv.reader(fp)\n",
    "    _ = reader.next()\n",
    "    \n",
    "    subject = Subject('')\n",
    "    subject_map = {}\n",
    "\n",
    "    i = 0\n",
    "    for t in reader:\n",
    "        code = t[0]\n",
    "        if code != subject.code:\n",
    "            # start a new subject\n",
    "            subject = Subject(code)\n",
    "            subject_map[code] = subject\n",
    "\n",
    "        # append a number to the species names so they're unique\n",
    "        species = t[1]\n",
    "        species = '%s-%d' % (species, i)\n",
    "        i += 1\n",
    "\n",
    "        count = int(t[2])\n",
    "        subject.Add(species, count)\n",
    "\n",
    "    for code, subject in subject_map.iteritems():\n",
    "        subject.Done(clean_param=clean_param)\n",
    "\n",
    "    return subject_map\n",
    "\n",
    "\n",
    "def ReadCompleteDataset(filename='BBB_data_from_Rob.csv', clean_param=0):\n",
    "    \"\"\"Reads a data file and returns a list of Subjects.\n",
    "\n",
    "    Data from personal correspondence with Rob Dunn, received 2-7-13.\n",
    "    Converted from xlsx to csv.\n",
    "\n",
    "    filename: string filename to read\n",
    "    clean_param: parameter passed to Clean\n",
    "\n",
    "    Returns: map from code to Subject\n",
    "    \"\"\"\n",
    "    fp = open(filename)\n",
    "    reader = csv.reader(fp)\n",
    "    header = reader.next()\n",
    "    header = reader.next()\n",
    "\n",
    "    subject_codes = header[1:-1]\n",
    "    subject_codes = ['B'+code for code in subject_codes]\n",
    "\n",
    "    # create the subject map\n",
    "    uber_subject = Subject('uber')\n",
    "    subject_map = {}\n",
    "    for code in subject_codes:\n",
    "        subject_map[code] = Subject(code)\n",
    "\n",
    "    # read lines\n",
    "    i = 0\n",
    "    for t in reader:\n",
    "        otu_code = t[0]\n",
    "        if otu_code == '':\n",
    "            continue\n",
    "\n",
    "        # pull out a species name and give it a number\n",
    "        otu_names = t[-1]\n",
    "        taxons = otu_names.split(';')\n",
    "        species = taxons[-1]\n",
    "        species = '%s-%d' % (species, i)\n",
    "        i += 1\n",
    "\n",
    "        counts = [int(x) for x in t[1:-1]]\n",
    "\n",
    "        # print otu_code, species\n",
    "\n",
    "        for code, count in zip(subject_codes, counts):\n",
    "            if count > 0:\n",
    "                subject_map[code].Add(species, count)\n",
    "                uber_subject.Add(species, count)\n",
    "\n",
    "    uber_subject.Done(clean_param=clean_param)\n",
    "    for code, subject in subject_map.iteritems():\n",
    "        subject.Done(clean_param=clean_param)\n",
    "\n",
    "    return subject_map, uber_subject\n",
    "        \n",
    "\n",
    "def JoinSubjects():\n",
    "    \"\"\"Reads both datasets and computers their inner join.\n",
    "\n",
    "    Finds all subjects that appear in both datasets.\n",
    "\n",
    "    For subjects in the rarefacted dataset, looks up the total\n",
    "    number of reads and stores it as total_reads.  num_reads\n",
    "    is normally 400.\n",
    "    \n",
    "    Returns: map from code to Subject\n",
    "    \"\"\"\n",
    "\n",
    "    # read the rarefacted dataset\n",
    "    sampled_subjects = ReadRarefactedData()\n",
    "\n",
    "    # read the complete dataset\n",
    "    all_subjects, _ = ReadCompleteDataset()\n",
    "\n",
    "    for code, subject in sampled_subjects.iteritems():\n",
    "        if code in all_subjects:\n",
    "            match = all_subjects[code]\n",
    "            subject.Match(match)\n",
    "\n",
    "    return sampled_subjects\n",
    "\n",
    "\n",
    "def JitterCurve(curve, dx=0.2, dy=0.3):\n",
    "    \"\"\"Adds random noise to the pairs in a curve.\n",
    "\n",
    "    dx and dy control the amplitude of the noise in each dimension.\n",
    "    \"\"\"\n",
    "    curve = [(x+random.uniform(-dx, dx), \n",
    "              y+random.uniform(-dy, dy)) for x, y in curve]\n",
    "    return curve\n",
    "\n",
    "\n",
    "def OffsetCurve(curve, i, n, dx=0.3, dy=0.3):\n",
    "    \"\"\"Adds random noise to the pairs in a curve.\n",
    "\n",
    "    i is the index of the curve\n",
    "    n is the number of curves\n",
    "\n",
    "    dx and dy control the amplitude of the noise in each dimension.\n",
    "    \"\"\"\n",
    "    xoff = -dx + 2 * dx * i / (n-1)\n",
    "    yoff = -dy + 2 * dy * i / (n-1)\n",
    "    curve = [(x+xoff, y+yoff) for x, y in curve]\n",
    "    return curve\n",
    "\n",
    "\n",
    "def PlotCurves(curves, root='species-rare'):\n",
    "    \"\"\"Plots a set of curves.\n",
    "\n",
    "    curves is a list of curves; each curve is a list of (x, y) pairs.\n",
    "    \"\"\"\n",
    "    thinkplot.Clf()\n",
    "    color = '#225EA8'\n",
    "\n",
    "    n = len(curves)\n",
    "    for i, curve in enumerate(curves):\n",
    "        curve = OffsetCurve(curve, i, n)\n",
    "        xs, ys = zip(*curve)\n",
    "        thinkplot.Plot(xs, ys, color=color, alpha=0.3, linewidth=0.5)\n",
    "\n",
    "    thinkplot.Save(root=root,\n",
    "                xlabel='# samples',\n",
    "                ylabel='# species',\n",
    "                formats=FORMATS,\n",
    "                legend=False)\n",
    "\n",
    "\n",
    "def PlotConditionals(cdfs, root='species-cond'):\n",
    "    \"\"\"Plots cdfs of num_new conditioned on k.\n",
    "\n",
    "    cdfs: list of Cdf\n",
    "    root: string filename root\n",
    "    \"\"\"\n",
    "    thinkplot.Clf()\n",
    "    thinkplot.PrePlot(num=len(cdfs))\n",
    "\n",
    "    thinkplot.Cdfs(cdfs)\n",
    "\n",
    "    thinkplot.Save(root=root,\n",
    "                xlabel='# new species',\n",
    "                ylabel='Prob',\n",
    "                formats=FORMATS)\n",
    "\n",
    "\n",
    "def PlotFracCdfs(cdfs, root='species-frac'):\n",
    "    \"\"\"Plots CDFs of the fraction of species seen.\n",
    "\n",
    "    cdfs: map from k to CDF of fraction of species seen after k samples\n",
    "    \"\"\"\n",
    "    thinkplot.Clf()\n",
    "    color = '#225EA8'\n",
    "\n",
    "    for k, cdf in cdfs.iteritems():\n",
    "        xs, ys = cdf.Render()\n",
    "        ys = [1-y for y in ys]\n",
    "        thinkplot.Plot(xs, ys, color=color, linewidth=1)\n",
    "\n",
    "        x = 0.9\n",
    "        y = 1 - cdf.Prob(x)\n",
    "        pyplot.text(x, y, str(k), fontsize=9, color=color,\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center',\n",
    "                    bbox=dict(facecolor='white', edgecolor='none'))\n",
    "\n",
    "    thinkplot.Save(root=root,\n",
    "                xlabel='Fraction of species seen',\n",
    "                ylabel='Probability',\n",
    "                formats=FORMATS,\n",
    "                legend=False)\n",
    "\n",
    "\n",
    "class Species(thinkbayes.Suite):\n",
    "    \"\"\"Represents hypotheses about the number of species.\"\"\"\n",
    "    \n",
    "    def __init__(self, ns, conc=1, iters=1000):\n",
    "        hypos = [thinkbayes.Dirichlet(n, conc) for n in ns]\n",
    "        thinkbayes.Suite.__init__(self, hypos)\n",
    "        self.iters = iters\n",
    "\n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates the suite based on the data.\n",
    "\n",
    "        data: list of observed frequencies\n",
    "        \"\"\"\n",
    "        # call Update in the parent class, which calls Likelihood\n",
    "        thinkbayes.Suite.Update(self, data)\n",
    "\n",
    "        # update the next level of the hierarchy\n",
    "        for hypo in self.Values():\n",
    "            hypo.Update(data)\n",
    "\n",
    "    def Likelihood(self, data, hypo):\n",
    "        \"\"\"Computes the likelihood of the data under this hypothesis.\n",
    "\n",
    "        hypo: Dirichlet object\n",
    "        data: list of observed frequencies\n",
    "        \"\"\"\n",
    "        dirichlet = hypo\n",
    "\n",
    "        # draw sample Likelihoods from the hypothetical Dirichlet dist\n",
    "        # and add them up\n",
    "        like = 0\n",
    "        for _ in range(self.iters):\n",
    "            like += dirichlet.Likelihood(data)\n",
    "\n",
    "        # correct for the number of ways the observed species\n",
    "        # might have been chosen from all species\n",
    "        m = len(data)\n",
    "        like *= thinkbayes.BinomialCoef(dirichlet.n, m)\n",
    "\n",
    "        return like\n",
    "\n",
    "    def DistN(self):\n",
    "        \"\"\"Computes the distribution of n.\"\"\"\n",
    "        pmf = thinkbayes.Pmf()\n",
    "        for hypo, prob in self.Items():\n",
    "            pmf.Set(hypo.n, prob)\n",
    "        return pmf\n",
    "        \n",
    "\n",
    "class Species2(object):\n",
    "    \"\"\"Represents hypotheses about the number of species.\n",
    "\n",
    "    Combines two layers of the hierarchy into one object.\n",
    "\n",
    "    ns and probs represent the distribution of N\n",
    "\n",
    "    params represents the parameters of the Dirichlet distributions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ns, conc=1, iters=1000):\n",
    "        self.ns = ns\n",
    "        self.conc = conc\n",
    "        self.probs = numpy.ones(len(ns), dtype=numpy.float)\n",
    "        self.params = numpy.ones(self.ns[-1], dtype=numpy.float) * conc\n",
    "        self.iters = iters\n",
    "        self.num_reads = 0\n",
    "        self.m = 0\n",
    "\n",
    "    def Preload(self, data):\n",
    "        \"\"\"Change the initial parameters to fit the data better.\n",
    "\n",
    "        Just an experiment.  Doesn't work.\n",
    "        \"\"\"\n",
    "        m = len(data)\n",
    "        singletons = data.count(1)\n",
    "        num = m - singletons\n",
    "        print m, singletons, num\n",
    "        addend = numpy.ones(num, dtype=numpy.float) * 1\n",
    "        print len(addend)\n",
    "        print len(self.params[singletons:m])\n",
    "        self.params[singletons:m] += addend\n",
    "        print 'Preload', num\n",
    "\n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates the distribution based on data.\n",
    "\n",
    "        data: numpy array of counts\n",
    "        \"\"\"\n",
    "        self.num_reads += sum(data)\n",
    "\n",
    "        like = numpy.zeros(len(self.ns), dtype=numpy.float)\n",
    "        for _ in range(self.iters):\n",
    "            like += self.SampleLikelihood(data)\n",
    "\n",
    "        self.probs *= like\n",
    "        self.probs /= self.probs.sum()\n",
    "\n",
    "        self.m = len(data)\n",
    "        #self.params[:self.m] += data * self.conc\n",
    "        self.params[:self.m] += data\n",
    "\n",
    "    def SampleLikelihood(self, data):\n",
    "        \"\"\"Computes the likelihood of the data for all values of n.\n",
    "\n",
    "        Draws one sample from the distribution of prevalences.\n",
    "\n",
    "        data: sequence of observed counts\n",
    "\n",
    "        Returns: numpy array of m likelihoods\n",
    "        \"\"\"\n",
    "        gammas = numpy.random.gamma(self.params)\n",
    "\n",
    "        m = len(data)\n",
    "        row = gammas[:m]\n",
    "        col = numpy.cumsum(gammas)\n",
    "\n",
    "        log_likes = []\n",
    "        for n in self.ns:\n",
    "            ps = row / col[n-1]\n",
    "            terms = numpy.log(ps) * data\n",
    "            log_like = terms.sum()\n",
    "            log_likes.append(log_like)\n",
    "\n",
    "        log_likes -= numpy.max(log_likes)\n",
    "        likes = numpy.exp(log_likes)\n",
    "\n",
    "        coefs = [thinkbayes.BinomialCoef(n, m) for n in self.ns]\n",
    "        likes *= coefs\n",
    "\n",
    "        return likes\n",
    "\n",
    "    def DistN(self):\n",
    "        \"\"\"Computes the distribution of n.\n",
    "\n",
    "        Returns: new Pmf object\n",
    "        \"\"\"\n",
    "        pmf = thinkbayes.MakePmfFromItems(zip(self.ns, self.probs))\n",
    "        return pmf\n",
    "\n",
    "    def RandomN(self):\n",
    "        \"\"\"Returns a random value of n.\"\"\"\n",
    "        return self.DistN().Random()\n",
    "\n",
    "    def DistQ(self, iters=100):\n",
    "        \"\"\"Computes the distribution of q based on distribution of n.\n",
    "\n",
    "        Returns: pmf of q\n",
    "        \"\"\"\n",
    "        cdf_n = self.DistN().MakeCdf()\n",
    "        sample_n = cdf_n.Sample(iters)\n",
    "\n",
    "        pmf = thinkbayes.Pmf()\n",
    "        for n in sample_n:\n",
    "            q = self.RandomQ(n)\n",
    "            pmf.Incr(q)\n",
    "\n",
    "        pmf.Normalize()\n",
    "        return pmf\n",
    "\n",
    "    def RandomQ(self, n):\n",
    "        \"\"\"Returns a random value of q.\n",
    "\n",
    "        Based on n, self.num_reads and self.conc.\n",
    "\n",
    "        n: number of species\n",
    "\n",
    "        Returns: q\n",
    "        \"\"\"\n",
    "        # generate random prevalences\n",
    "        dirichlet = thinkbayes.Dirichlet(n, conc=self.conc)\n",
    "        prevalences = dirichlet.Random()\n",
    "\n",
    "        # generate a simulated sample\n",
    "        pmf = thinkbayes.MakePmfFromItems(enumerate(prevalences))\n",
    "        cdf = pmf.MakeCdf()\n",
    "        sample = cdf.Sample(self.num_reads)\n",
    "        seen = set(sample)\n",
    "\n",
    "        # add up the prevalence of unseen species\n",
    "        q = 0\n",
    "        for species, prev in enumerate(prevalences):\n",
    "            if species not in seen:\n",
    "                q += prev\n",
    "\n",
    "        return q\n",
    "\n",
    "    def MarginalBeta(self, n, index):\n",
    "        \"\"\"Computes the conditional distribution of the indicated species.\n",
    "        \n",
    "        n: conditional number of species\n",
    "        index: which species\n",
    "\n",
    "        Returns: Beta object representing a distribution of prevalence.\n",
    "        \"\"\"\n",
    "        alpha0 = self.params[:n].sum()\n",
    "        alpha = self.params[index]\n",
    "        return thinkbayes.Beta(alpha, alpha0-alpha)\n",
    "\n",
    "    def DistOfPrevalence(self, index):\n",
    "        \"\"\"Computes the distribution of prevalence for the indicated species.\n",
    "\n",
    "        index: which species\n",
    "\n",
    "        Returns: (metapmf, mix) where metapmf is a MetaPmf and mix is a Pmf\n",
    "        \"\"\"\n",
    "        metapmf = thinkbayes.Pmf()\n",
    "\n",
    "        for n, prob in zip(self.ns, self.probs):\n",
    "            beta = self.MarginalBeta(n, index)\n",
    "            pmf = beta.MakePmf()\n",
    "            metapmf.Set(pmf, prob)\n",
    "\n",
    "        mix = thinkbayes.MakeMixture(metapmf)\n",
    "        return metapmf, mix\n",
    "        \n",
    "    def SamplePosterior(self):\n",
    "        \"\"\"Draws random n and prevalences.\n",
    "\n",
    "        Returns: (n, prevalences)\n",
    "        \"\"\"\n",
    "        n = self.RandomN()\n",
    "        prevalences = self.SamplePrevalences(n)\n",
    "\n",
    "        #print 'Peeking at n_cheat'\n",
    "        #n = n_cheat\n",
    "\n",
    "        return n, prevalences\n",
    "\n",
    "    def SamplePrevalences(self, n):\n",
    "        \"\"\"Draws a sample of prevalences given n.\n",
    "\n",
    "        n: the number of species assumed in the conditional\n",
    "\n",
    "        Returns: numpy array of n prevalences\n",
    "        \"\"\"\n",
    "        if n == 1:\n",
    "            return [1.0]\n",
    "\n",
    "        q_desired = self.RandomQ(n)\n",
    "        q_desired = max(q_desired, 1e-6)\n",
    "\n",
    "        params = self.Unbias(n, self.m, q_desired)\n",
    "\n",
    "        gammas = numpy.random.gamma(params)\n",
    "        gammas /= gammas.sum()\n",
    "        return gammas\n",
    "        \n",
    "    def Unbias(self, n, m, q_desired):\n",
    "        \"\"\"Adjusts the parameters to achieve desired prev_unseen (q).\n",
    "\n",
    "        n: number of species\n",
    "        m: seen species\n",
    "        q_desired: prevalence of unseen species\n",
    "        \"\"\"\n",
    "        params = self.params[:n].copy()\n",
    "\n",
    "        if n == m:\n",
    "            return params\n",
    "        \n",
    "        x = sum(params[:m])\n",
    "        y = sum(params[m:])\n",
    "        a = x + y\n",
    "        #print x, y, a, x/a, y/a\n",
    "\n",
    "        g = q_desired * a / y\n",
    "        f = (a - g * y) / x\n",
    "        params[:m] *= f\n",
    "        params[m:] *= g\n",
    "\n",
    "        return params\n",
    "\n",
    "\n",
    "class Species3(Species2):\n",
    "    \"\"\"Represents hypotheses about the number of species.\"\"\"\n",
    "    \n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates the suite based on the data.\n",
    "\n",
    "        data: list of observations\n",
    "        \"\"\"\n",
    "        # sample the likelihoods and add them up\n",
    "        like = numpy.zeros(len(self.ns), dtype=numpy.float)\n",
    "        for _ in range(self.iters):\n",
    "            like += self.SampleLikelihood(data)\n",
    "\n",
    "        self.probs *= like\n",
    "        self.probs /= self.probs.sum()\n",
    "\n",
    "        m = len(data)\n",
    "        self.params[:m] += data\n",
    "\n",
    "    def SampleLikelihood(self, data):\n",
    "        \"\"\"Computes the likelihood of the data under all hypotheses.\n",
    "\n",
    "        data: list of observations\n",
    "        \"\"\"\n",
    "        # get a random sample\n",
    "        gammas = numpy.random.gamma(self.params)\n",
    "\n",
    "        # row is just the first m elements of gammas\n",
    "        m = len(data)\n",
    "        row = gammas[:m]\n",
    "\n",
    "        # col is the cumulative sum of gammas\n",
    "        col = numpy.cumsum(gammas)[self.ns[0]-1:]\n",
    "\n",
    "        # each row of the array is a set of ps, normalized\n",
    "        # for each hypothetical value of n\n",
    "        array = row / col[:, numpy.newaxis]\n",
    "\n",
    "        # computing the multinomial PDF under a log transform\n",
    "        # take the log of the ps and multiply by the data\n",
    "        terms = numpy.log(array) * data\n",
    "\n",
    "        # add up the rows\n",
    "        log_likes = terms.sum(axis=1)\n",
    "\n",
    "        # before exponentiating, scale into a reasonable range\n",
    "        log_likes -= numpy.max(log_likes)\n",
    "        likes = numpy.exp(log_likes)\n",
    "\n",
    "        # correct for the number of ways we could see m species\n",
    "        # out of a possible n\n",
    "        coefs = [thinkbayes.BinomialCoef(n, m) for n in self.ns]\n",
    "        likes *= coefs\n",
    "\n",
    "        return likes\n",
    "\n",
    "\n",
    "class Species4(Species):\n",
    "    \"\"\"Represents hypotheses about the number of species.\"\"\"\n",
    "    \n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates the suite based on the data.\n",
    "\n",
    "        data: list of observed frequencies\n",
    "        \"\"\"\n",
    "        m = len(data)\n",
    "\n",
    "        # loop through the species and update one at a time\n",
    "        for i in range(m):\n",
    "            one = numpy.zeros(i+1)\n",
    "            one[i] = data[i]\n",
    "            \n",
    "            # call the parent class\n",
    "            Species.Update(self, one)\n",
    "\n",
    "    def Likelihood(self, data, hypo):\n",
    "        \"\"\"Computes the likelihood of the data under this hypothesis.\n",
    "\n",
    "        Note: this only works correctly if we update one species at a time.\n",
    "\n",
    "        hypo: Dirichlet object\n",
    "        data: list of observed frequencies\n",
    "        \"\"\"\n",
    "        dirichlet = hypo\n",
    "        like = 0\n",
    "        for _ in range(self.iters):\n",
    "            like += dirichlet.Likelihood(data)\n",
    "\n",
    "        # correct for the number of unseen species the new one\n",
    "        # could have been\n",
    "        m = len(data)\n",
    "        num_unseen = dirichlet.n - m + 1\n",
    "        like *= num_unseen\n",
    "\n",
    "        return like\n",
    "\n",
    "\n",
    "class Species5(Species2):\n",
    "    \"\"\"Represents hypotheses about the number of species.\n",
    "\n",
    "    Combines two laters of the hierarchy into one object.\n",
    "\n",
    "    ns and probs represent the distribution of N\n",
    "\n",
    "    params represents the parameters of the Dirichlet distributions\n",
    "    \"\"\"\n",
    "    \n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates the suite based on the data.\n",
    "\n",
    "        data: list of observed frequencies in increasing order\n",
    "        \"\"\"\n",
    "        # loop through the species and update one at a time\n",
    "        m = len(data)\n",
    "        for i in range(m):\n",
    "            self.UpdateOne(i+1, data[i])\n",
    "            self.params[i] += data[i]\n",
    "\n",
    "    def UpdateOne(self, i, count):\n",
    "        \"\"\"Updates the suite based on the data.\n",
    "\n",
    "        Evaluates the likelihood for all values of n.\n",
    "\n",
    "        i: which species was observed (1..n)\n",
    "        count: how many were observed\n",
    "        \"\"\"\n",
    "        # how many species have we seen so far\n",
    "        self.m = i\n",
    "\n",
    "        # how many reads have we seen\n",
    "        self.num_reads += count\n",
    "\n",
    "        if self.iters == 0:\n",
    "            return\n",
    "\n",
    "        # sample the likelihoods and add them up\n",
    "        likes = numpy.zeros(len(self.ns), dtype=numpy.float)\n",
    "        for _ in range(self.iters):\n",
    "            likes += self.SampleLikelihood(i, count)\n",
    "\n",
    "        # correct for the number of unseen species the new one\n",
    "        # could have been\n",
    "        unseen_species = [n-i+1 for n in self.ns]\n",
    "        likes *= unseen_species\n",
    "\n",
    "        # multiply the priors by the likelihoods and renormalize\n",
    "        self.probs *= likes\n",
    "        self.probs /= self.probs.sum()\n",
    "\n",
    "    def SampleLikelihood(self, i, count):\n",
    "        \"\"\"Computes the likelihood of the data under all hypotheses.\n",
    "\n",
    "        i: which species was observed\n",
    "        count: how many were observed\n",
    "        \"\"\"\n",
    "        # get a random sample of p\n",
    "        gammas = numpy.random.gamma(self.params)\n",
    "\n",
    "        # sums is the cumulative sum of p, for each value of n\n",
    "        sums = numpy.cumsum(gammas)[self.ns[0]-1:]\n",
    "\n",
    "        # get p for the mth species, for each value of n\n",
    "        ps = gammas[i-1] / sums\n",
    "        log_likes = numpy.log(ps) * count\n",
    "\n",
    "        # before exponentiating, scale into a reasonable range\n",
    "        log_likes -= numpy.max(log_likes)\n",
    "        likes = numpy.exp(log_likes)\n",
    "\n",
    "        return likes\n",
    "\n",
    "\n",
    "def MakePosterior(constructor, data, ns, conc=1, iters=1000):\n",
    "    \"\"\"Makes a suite, updates it and returns the posterior suite.\n",
    "\n",
    "    Prints the elapsed time.\n",
    "\n",
    "    data: observed species and their counts\n",
    "    ns: sequence of hypothetical ns\n",
    "    conc: concentration parameter\n",
    "    iters: how many samples to draw\n",
    "\n",
    "    Returns: posterior suite of the given type\n",
    "    \"\"\"\n",
    "    suite = constructor(ns, conc=conc, iters=iters)\n",
    "\n",
    "    # print constructor.__name__\n",
    "    start = time.time()\n",
    "    suite.Update(data)\n",
    "    end = time.time()\n",
    "    print 'Processing time', end-start\n",
    "\n",
    "    return suite\n",
    "\n",
    "\n",
    "def PlotAllVersions():\n",
    "    \"\"\"Makes a graph of posterior distributions of N.\"\"\"\n",
    "    data = [1, 2, 3]\n",
    "    m = len(data)\n",
    "    n = 20\n",
    "    ns = range(m, n)\n",
    "\n",
    "    for constructor in [Species, Species2, Species3, Species4, Species5]:\n",
    "        suite = MakePosterior(constructor, data, ns)\n",
    "        pmf = suite.DistN()\n",
    "        pmf.name = '%s' % (constructor.__name__)\n",
    "        thinkplot.Pmf(pmf)\n",
    "\n",
    "    thinkplot.Save(root='species3',\n",
    "                xlabel='Number of species',\n",
    "                ylabel='Prob')\n",
    "\n",
    "\n",
    "def PlotMedium():\n",
    "    \"\"\"Makes a graph of posterior distributions of N.\"\"\"\n",
    "    data = [1, 1, 1, 1, 2, 3, 5, 9]\n",
    "    m = len(data)\n",
    "    n = 20\n",
    "    ns = range(m, n)\n",
    "\n",
    "    for constructor in [Species, Species2, Species3, Species4, Species5]:\n",
    "        suite = MakePosterior(constructor, data, ns)\n",
    "        pmf = suite.DistN()\n",
    "        pmf.name = '%s' % (constructor.__name__)\n",
    "        thinkplot.Pmf(pmf)\n",
    "\n",
    "    thinkplot.Show()\n",
    "\n",
    "\n",
    "def SimpleDirichletExample():\n",
    "    \"\"\"Makes a plot showing posterior distributions for three species.\n",
    "\n",
    "    This is the case where we know there are exactly three species.\n",
    "    \"\"\"\n",
    "    thinkplot.Clf()\n",
    "    thinkplot.PrePlot(3)\n",
    "\n",
    "    names = ['lions',  'tigers', 'bears']\n",
    "    data = [3, 2, 1]\n",
    "\n",
    "    dirichlet = thinkbayes.Dirichlet(3)\n",
    "    for i in range(3):\n",
    "        beta = dirichlet.MarginalBeta(i)\n",
    "        print 'mean', names[i], beta.Mean()\n",
    "\n",
    "    dirichlet.Update(data)\n",
    "    for i in range(3):\n",
    "        beta = dirichlet.MarginalBeta(i)\n",
    "        print 'mean', names[i], beta.Mean()\n",
    "\n",
    "        pmf = beta.MakePmf(name=names[i])\n",
    "        thinkplot.Pmf(pmf)\n",
    "\n",
    "    thinkplot.Save(root='species1',\n",
    "                xlabel='Prevalence',\n",
    "                ylabel='Prob',\n",
    "                formats=FORMATS,\n",
    "                )\n",
    "\n",
    "\n",
    "def HierarchicalExample():\n",
    "    \"\"\"Shows the posterior distribution of n for lions, tigers and bears.\n",
    "    \"\"\"\n",
    "    ns = range(3, 30)\n",
    "    suite = Species(ns, iters=8000)\n",
    "\n",
    "    data = [3, 2, 1]\n",
    "    suite.Update(data)\n",
    "\n",
    "    thinkplot.Clf()\n",
    "    thinkplot.PrePlot(num=1)\n",
    "\n",
    "    pmf = suite.DistN()\n",
    "    thinkplot.Pmf(pmf)\n",
    "    thinkplot.Save(root='species2',\n",
    "                xlabel='Number of species',\n",
    "                ylabel='Prob',\n",
    "                formats=FORMATS,\n",
    "                )\n",
    "\n",
    "\n",
    "def CompareHierarchicalExample():\n",
    "    \"\"\"Makes a graph of posterior distributions of N.\"\"\"\n",
    "    data = [3, 2, 1]\n",
    "    m = len(data)\n",
    "    n = 30\n",
    "    ns = range(m, n)\n",
    "\n",
    "    constructors = [Species, Species5]\n",
    "    iters = [1000, 100]\n",
    "\n",
    "    for constructor, iters in zip(constructors, iters):\n",
    "        suite = MakePosterior(constructor, data, ns, iters)\n",
    "        pmf = suite.DistN()\n",
    "        pmf.name = '%s' % (constructor.__name__)\n",
    "        thinkplot.Pmf(pmf)\n",
    "\n",
    "    thinkplot.Show()\n",
    "\n",
    "\n",
    "def ProcessSubjects(codes):\n",
    "    \"\"\"Process subjects with the given codes and plot their posteriors.\n",
    "\n",
    "    code: sequence of string codes\n",
    "    \"\"\"\n",
    "    thinkplot.Clf()\n",
    "    thinkplot.PrePlot(len(codes))\n",
    "\n",
    "    subjects = ReadRarefactedData()\n",
    "    pmfs = []\n",
    "    for code in codes:\n",
    "        subject = subjects[code]\n",
    "\n",
    "        subject.Process()\n",
    "        pmf = subject.suite.DistN()\n",
    "        pmf.name = subject.code\n",
    "        thinkplot.Pmf(pmf)\n",
    "\n",
    "        pmfs.append(pmf)\n",
    "\n",
    "    print 'ProbGreater', thinkbayes.PmfProbGreater(pmfs[0], pmfs[1])\n",
    "    print 'ProbLess', thinkbayes.PmfProbLess(pmfs[0], pmfs[1])\n",
    "\n",
    "    thinkplot.Save(root='species4',\n",
    "                xlabel='Number of species',\n",
    "                ylabel='Prob',\n",
    "                formats=FORMATS,\n",
    "                )\n",
    "\n",
    "\n",
    "def RunSubject(code, conc=1, high=500):\n",
    "    \"\"\"Run the analysis for the subject with the given code.\n",
    "\n",
    "    code: string code\n",
    "    \"\"\"\n",
    "    subjects = JoinSubjects()\n",
    "    subject = subjects[code]\n",
    "\n",
    "    subject.Process(conc=conc, high=high, iters=300)\n",
    "    subject.MakeQuickPrediction()\n",
    "\n",
    "    PrintSummary(subject)\n",
    "    actual_l = subject.total_species - subject.num_species\n",
    "    cdf_l = subject.DistL().MakeCdf()\n",
    "    PrintPrediction(cdf_l, actual_l)\n",
    "\n",
    "    subject.MakeFigures()\n",
    "\n",
    "    num_reads = 400\n",
    "    curves = subject.RunSimulations(100, num_reads)\n",
    "    root = 'species-rare-%s' % subject.code\n",
    "    PlotCurves(curves, root=root)\n",
    "\n",
    "    num_reads = 800\n",
    "    curves = subject.RunSimulations(500, num_reads)\n",
    "    ks = [100, 200, 400, 800]\n",
    "    cdfs = MakeConditionals(curves, ks)\n",
    "    root = 'species-cond-%s' % subject.code\n",
    "    PlotConditionals(cdfs, root=root)\n",
    "\n",
    "    num_reads = 1000\n",
    "    curves = subject.RunSimulations(500, num_reads, frac_flag=True)\n",
    "    ks = [10, 100, 200, 400, 600, 800, 1000]\n",
    "    cdfs = MakeFracCdfs(curves, ks)\n",
    "    root = 'species-frac-%s' % subject.code\n",
    "    PlotFracCdfs(cdfs, root=root)\n",
    "\n",
    "\n",
    "def PrintSummary(subject):\n",
    "    \"\"\"Print a summary of a subject.\n",
    "\n",
    "    subject: Subject\n",
    "    \"\"\"\n",
    "    print subject.code\n",
    "    print 'found %d species in %d reads' % (subject.num_species,\n",
    "                                            subject.num_reads)\n",
    "\n",
    "    print 'total %d species in %d reads' % (subject.total_species,\n",
    "                                            subject.total_reads)\n",
    "\n",
    "    cdf = subject.suite.DistN().MakeCdf()\n",
    "    print 'n'\n",
    "    PrintPrediction(cdf, 'unknown')\n",
    "    \n",
    "\n",
    "def PrintPrediction(cdf, actual):\n",
    "    \"\"\"Print a summary of a prediction.\n",
    "\n",
    "    cdf: predictive distribution\n",
    "    actual: actual value\n",
    "    \"\"\"\n",
    "    median = cdf.Percentile(50)\n",
    "    low, high = cdf.CredibleInterval(75)\n",
    "    \n",
    "    print 'predicted %0.2f (%0.2f %0.2f)' % (median, low, high)\n",
    "    print 'actual', actual\n",
    "\n",
    "\n",
    "def RandomSeed(x):\n",
    "    \"\"\"Initialize random.random and numpy.random.\n",
    "\n",
    "    x: int seed\n",
    "    \"\"\"\n",
    "    random.seed(x)\n",
    "    numpy.random.seed(x)\n",
    "\n",
    "\n",
    "def GenerateFakeSample(n, r, tr, conc=1):\n",
    "    \"\"\"Generates fake data with the given parameters.\n",
    "\n",
    "    n: number of species\n",
    "    r: number of reads in subsample\n",
    "    tr: total number of reads\n",
    "    conc: concentration parameter\n",
    "\n",
    "    Returns: hist of all reads, hist of subsample, prev_unseen\n",
    "    \"\"\"\n",
    "    # generate random prevalences\n",
    "    dirichlet = thinkbayes.Dirichlet(n, conc=conc)\n",
    "    prevalences = dirichlet.Random()\n",
    "    prevalences.sort()\n",
    "\n",
    "    # generate a simulated sample\n",
    "    pmf = thinkbayes.MakePmfFromItems(enumerate(prevalences))\n",
    "    cdf = pmf.MakeCdf()\n",
    "    sample = cdf.Sample(tr)\n",
    "\n",
    "    # collect the species counts\n",
    "    hist = thinkbayes.MakeHistFromList(sample)\n",
    "\n",
    "    # extract a subset of the data\n",
    "    if tr > r:\n",
    "        random.shuffle(sample)\n",
    "        subsample = sample[:r]\n",
    "        subhist = thinkbayes.MakeHistFromList(subsample)\n",
    "    else:\n",
    "        subhist = hist\n",
    "\n",
    "    # add up the prevalence of unseen species\n",
    "    prev_unseen = 0\n",
    "    for species, prev in enumerate(prevalences):\n",
    "        if species not in subhist:\n",
    "            prev_unseen += prev\n",
    "\n",
    "    return hist, subhist, prev_unseen\n",
    "\n",
    "\n",
    "def PlotActualPrevalences():\n",
    "    \"\"\"Makes a plot comparing actual prevalences with a model.\n",
    "    \"\"\"\n",
    "    # read data\n",
    "    subject_map, _ = ReadCompleteDataset()\n",
    "\n",
    "    # for subjects with more than 50 species,\n",
    "    # PMF of max prevalence, and PMF of max prevalence\n",
    "    # generated by a simulation\n",
    "    pmf_actual = thinkbayes.Pmf()\n",
    "    pmf_sim = thinkbayes.Pmf()\n",
    "\n",
    "    # concentration parameter used in the simulation\n",
    "    conc = 0.06\n",
    "\n",
    "    for code, subject in subject_map.iteritems():\n",
    "        prevalences = subject.GetPrevalences()\n",
    "        m = len(prevalences)\n",
    "        if m < 2:\n",
    "            continue\n",
    "\n",
    "        actual_max = max(prevalences)\n",
    "        print code, m, actual_max\n",
    "\n",
    "        # incr the PMFs\n",
    "        if m > 50:\n",
    "            pmf_actual.Incr(actual_max)\n",
    "            pmf_sim.Incr(SimulateMaxPrev(m, conc))\n",
    "\n",
    "    # plot CDFs for the actual and simulated max prevalence\n",
    "    cdf_actual = pmf_actual.MakeCdf(name='actual')\n",
    "    cdf_sim = pmf_sim.MakeCdf(name='sim')\n",
    "\n",
    "    thinkplot.Cdfs([cdf_actual, cdf_sim])\n",
    "    thinkplot.Show()\n",
    "\n",
    "\n",
    "def ScatterPrevalences(ms, actual):\n",
    "    \"\"\"Make a scatter plot of actual prevalences and expected values.\n",
    "\n",
    "    ms: sorted sequence of in m (number of species)\n",
    "    actual: sequence of actual max prevalence\n",
    "    \"\"\"\n",
    "    for conc in [1, 0.5, 0.2, 0.1]:\n",
    "        expected = [ExpectedMaxPrev(m, conc) for m in ms]\n",
    "        thinkplot.Plot(ms, expected)\n",
    "\n",
    "    thinkplot.Scatter(ms, actual)\n",
    "    thinkplot.Show(xscale='log')\n",
    "\n",
    "\n",
    "def SimulateMaxPrev(m, conc=1):\n",
    "    \"\"\"Returns random max prevalence from a Dirichlet distribution.\n",
    "\n",
    "    m: int number of species\n",
    "    conc: concentration parameter of the Dirichlet distribution\n",
    "\n",
    "    Returns: float max of m prevalences\n",
    "    \"\"\"\n",
    "    dirichlet = thinkbayes.Dirichlet(m, conc)\n",
    "    prevalences = dirichlet.Random()\n",
    "    return max(prevalences)\n",
    "        \n",
    "\n",
    "def ExpectedMaxPrev(m, conc=1, iters=100):\n",
    "    \"\"\"Estimate expected max prevalence.\n",
    "\n",
    "    m: number of species\n",
    "    conc: concentration parameter\n",
    "    iters: how many iterations to run\n",
    "\n",
    "    Returns: expected max prevalence\n",
    "    \"\"\"\n",
    "    dirichlet = thinkbayes.Dirichlet(m, conc)\n",
    "\n",
    "    t = []\n",
    "    for _ in range(iters):\n",
    "        prevalences = dirichlet.Random()\n",
    "        t.append(max(prevalences))\n",
    "\n",
    "    return numpy.mean(t)\n",
    "\n",
    "\n",
    "class Calibrator(object):\n",
    "    \"\"\"Encapsulates the calibration process.\"\"\"\n",
    "\n",
    "    def __init__(self, conc=0.1):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.conc = conc\n",
    "\n",
    "        self.ps =  range(10, 100, 10)\n",
    "        self.total_n = numpy.zeros(len(self.ps))\n",
    "        self.total_q = numpy.zeros(len(self.ps))\n",
    "        self.total_l = numpy.zeros(len(self.ps))\n",
    "\n",
    "        self.n_seq = []\n",
    "        self.q_seq = []\n",
    "        self.l_seq = []\n",
    "\n",
    "    def Calibrate(self, num_runs=100, n_low=30, n_high=400, r=400, tr=1200):\n",
    "        \"\"\"Runs calibrations.\n",
    "\n",
    "        num_runs: how many runs\n",
    "        \"\"\"\n",
    "        for seed in range(num_runs):\n",
    "            self.RunCalibration(seed, n_low, n_high, r, tr)\n",
    "\n",
    "        self.total_n *= 100.0 / num_runs\n",
    "        self.total_q *= 100.0 / num_runs\n",
    "        self.total_l *= 100.0 / num_runs\n",
    "\n",
    "    def Validate(self, num_runs=100, clean_param=0):\n",
    "        \"\"\"Runs validations.\n",
    "\n",
    "        num_runs: how many runs\n",
    "        \"\"\"\n",
    "        subject_map, _ = ReadCompleteDataset(clean_param=clean_param)\n",
    "\n",
    "        i = 0\n",
    "        for match in subject_map.itervalues():\n",
    "            if match.num_reads < 400:\n",
    "                continue\n",
    "            num_reads = 100\n",
    "\n",
    "            print 'Validate', match.code\n",
    "            subject = match.Resample(num_reads)\n",
    "            subject.Match(match)\n",
    "\n",
    "            n_actual = None\n",
    "            q_actual = subject.prev_unseen\n",
    "            l_actual = subject.total_species - subject.num_species\n",
    "            self.RunSubject(subject, n_actual, q_actual, l_actual)\n",
    "            \n",
    "            i += 1\n",
    "            if i == num_runs:\n",
    "                break\n",
    "\n",
    "        self.total_n *= 100.0 / num_runs\n",
    "        self.total_q *= 100.0 / num_runs\n",
    "        self.total_l *= 100.0 / num_runs\n",
    "\n",
    "    def PlotN(self, root='species-n'):\n",
    "        \"\"\"Makes a scatter plot of simulated vs actual prev_unseen (q).\n",
    "        \"\"\"\n",
    "        xs, ys = zip(*self.n_seq)\n",
    "        if None in xs:\n",
    "            return\n",
    "\n",
    "        high = max(xs+ys)\n",
    "\n",
    "        thinkplot.Plot([0, high], [0, high], color='gray')\n",
    "        thinkplot.Scatter(xs, ys)\n",
    "        thinkplot.Save(root=root,\n",
    "                       xlabel='Actual n',\n",
    "                       ylabel='Predicted')\n",
    "\n",
    "    def PlotQ(self, root='species-q'):\n",
    "        \"\"\"Makes a scatter plot of simulated vs actual prev_unseen (q).\n",
    "        \"\"\"\n",
    "        thinkplot.Plot([0, 0.2], [0, 0.2], color='gray')\n",
    "        xs, ys = zip(*self.q_seq)\n",
    "        thinkplot.Scatter(xs, ys)\n",
    "        thinkplot.Save(root=root,\n",
    "                       xlabel='Actual q',\n",
    "                       ylabel='Predicted')\n",
    "\n",
    "    def PlotL(self, root='species-n'):\n",
    "        \"\"\"Makes a scatter plot of simulated vs actual l.\n",
    "        \"\"\"\n",
    "        thinkplot.Plot([0, 20], [0, 20], color='gray')\n",
    "        xs, ys = zip(*self.l_seq)\n",
    "        thinkplot.Scatter(xs, ys)\n",
    "        thinkplot.Save(root=root,\n",
    "                       xlabel='Actual l',\n",
    "                       ylabel='Predicted')\n",
    "\n",
    "    def PlotCalibrationCurves(self, root='species5'):\n",
    "        \"\"\"Plots calibration curves\"\"\"\n",
    "        print self.total_n\n",
    "        print self.total_q\n",
    "        print self.total_l\n",
    "\n",
    "        thinkplot.Plot([0, 100], [0, 100], color='gray', alpha=0.2)\n",
    "\n",
    "        if self.total_n[0] >= 0:\n",
    "            thinkplot.Plot(self.ps, self.total_n, label='n')\n",
    "\n",
    "        thinkplot.Plot(self.ps, self.total_q, label='q')\n",
    "        thinkplot.Plot(self.ps, self.total_l, label='l')\n",
    "\n",
    "        thinkplot.Save(root=root,\n",
    "                       axis=[0, 100, 0, 100],\n",
    "                       xlabel='Ideal percentages',\n",
    "                       ylabel='Predictive distributions',\n",
    "                       formats=FORMATS,\n",
    "                       )\n",
    "\n",
    "    def RunCalibration(self, seed, n_low, n_high, r, tr):\n",
    "        \"\"\"Runs a single calibration run.\n",
    "\n",
    "        Generates N and prevalences from a Dirichlet distribution,\n",
    "        then generates simulated data.\n",
    "\n",
    "        Runs analysis to get the posterior distributions.\n",
    "        Generates calibration curves for each posterior distribution.\n",
    "\n",
    "        seed: int random seed\n",
    "        \"\"\"\n",
    "        # generate a random number of species and their prevalences\n",
    "        # (from a Dirichlet distribution with alpha_i = conc for all i)\n",
    "        RandomSeed(seed)\n",
    "        n_actual = random.randrange(n_low, n_high+1)\n",
    "\n",
    "        hist, subhist, q_actual = GenerateFakeSample(\n",
    "            n_actual, \n",
    "            r, \n",
    "            tr, \n",
    "            self.conc)\n",
    "\n",
    "        l_actual = len(hist) - len(subhist)\n",
    "        print 'Run low, high, conc', n_low, n_high, self.conc\n",
    "        print 'Run r, tr', r, tr\n",
    "        print 'Run n, q, l', n_actual, q_actual, l_actual\n",
    "\n",
    "        # extract the data\n",
    "        data = [count for species, count in subhist.Items()]\n",
    "        data.sort()\n",
    "        print 'data', data\n",
    "\n",
    "        # make a Subject and process\n",
    "        subject = Subject('simulated')\n",
    "        subject.num_reads = r\n",
    "        subject.total_reads = tr\n",
    "\n",
    "        for species, count in subhist.Items():\n",
    "            subject.Add(species, count)\n",
    "        subject.Done()\n",
    "\n",
    "        self.RunSubject(subject, n_actual, q_actual, l_actual)\n",
    "\n",
    "    def RunSubject(self, subject, n_actual, q_actual, l_actual):\n",
    "        \"\"\"Runs the analysis for a subject.\n",
    "\n",
    "        subject: Subject\n",
    "        n_actual: number of species\n",
    "        q_actual: prevalence of unseen species\n",
    "        l_actual: number of new species\n",
    "        \"\"\"\n",
    "        # process and make prediction\n",
    "        subject.Process(conc=self.conc, iters=100)\n",
    "        subject.MakeQuickPrediction()\n",
    "\n",
    "        # extract the posterior suite\n",
    "        suite = subject.suite\n",
    "\n",
    "        # check the distribution of n\n",
    "        pmf_n = suite.DistN() \n",
    "        print 'n'\n",
    "        self.total_n += self.CheckDistribution(pmf_n, n_actual, self.n_seq)\n",
    "\n",
    "        # check the distribution of q\n",
    "        pmf_q = suite.DistQ()\n",
    "        print 'q'\n",
    "        self.total_q += self.CheckDistribution(pmf_q, q_actual, self.q_seq)\n",
    "\n",
    "        # check the distribution of additional species\n",
    "        pmf_l = subject.DistL()\n",
    "        print 'l'\n",
    "        self.total_l += self.CheckDistribution(pmf_l, l_actual, self.l_seq)\n",
    "\n",
    "    def CheckDistribution(self, pmf, actual, seq):\n",
    "        \"\"\"Checks a predictive distribution and returns a score vector.\n",
    "\n",
    "        pmf: predictive distribution\n",
    "        actual: actual value\n",
    "        seq: which sequence to append (actual, mean) onto\n",
    "        \"\"\"\n",
    "        mean = pmf.Mean()\n",
    "        seq.append((actual, mean))\n",
    "\n",
    "        cdf = pmf.MakeCdf()\n",
    "        PrintPrediction(cdf, actual)\n",
    "\n",
    "        sv = ScoreVector(cdf, self.ps, actual)\n",
    "        return sv\n",
    "\n",
    "\n",
    "def ScoreVector(cdf, ps, actual):\n",
    "    \"\"\"Checks whether the actual value falls in each credible interval.\n",
    "    \n",
    "    cdf: predictive distribution\n",
    "    ps: percentages to check (0-100)\n",
    "    actual: actual value\n",
    "\n",
    "    Returns: numpy array of 0, 0.5, or 1\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for p in ps:\n",
    "        low, high = cdf.CredibleInterval(p)\n",
    "        score = Score(low, high, actual)\n",
    "        scores.append(score)\n",
    "\n",
    "    return numpy.array(scores)\n",
    "\n",
    "\n",
    "def Score(low, high, n):\n",
    "    \"\"\"Score whether the actual value falls in the range.\n",
    "\n",
    "    Hitting the posts counts as 0.5, -1 is invalid.\n",
    "\n",
    "    low: low end of range\n",
    "    high: high end of range\n",
    "    n: actual value\n",
    "\n",
    "    Returns: -1, 0, 0.5 or 1\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        return -1\n",
    "    if low < n < high:\n",
    "        return 1\n",
    "    if n == low or n == high:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def FakeSubject(n=300, conc=0.1, num_reads=400, prevalences=None):\n",
    "    \"\"\"Makes a fake Subject.\n",
    "    \n",
    "    If prevalences is provided, n and conc are ignored.\n",
    "\n",
    "    n: number of species\n",
    "    conc: concentration parameter\n",
    "    num_reads: number of reads\n",
    "    prevalences: numpy array of prevalences (overrides n and conc)\n",
    "    \"\"\"\n",
    "    # generate random prevalences\n",
    "    if prevalences is None:\n",
    "        dirichlet = thinkbayes.Dirichlet(n, conc=conc)\n",
    "        prevalences = dirichlet.Random()\n",
    "        prevalences.sort()\n",
    "\n",
    "    # generate a simulated sample\n",
    "    pmf = thinkbayes.MakePmfFromItems(enumerate(prevalences))\n",
    "    cdf = pmf.MakeCdf()\n",
    "    sample = cdf.Sample(num_reads)\n",
    "\n",
    "    # collect the species counts\n",
    "    hist = thinkbayes.MakeHistFromList(sample)\n",
    "\n",
    "    # extract the data\n",
    "    data = [count for species, count in hist.Items()]\n",
    "    data.sort()\n",
    "\n",
    "    # make a Subject and process\n",
    "    subject = Subject('simulated')\n",
    "\n",
    "    for species, count in hist.Items():\n",
    "        subject.Add(species, count)\n",
    "    subject.Done()\n",
    "\n",
    "    return subject\n",
    "\n",
    "\n",
    "def PlotSubjectCdf(code=None, clean_param=0):\n",
    "    \"\"\"Checks whether the Dirichlet model can replicate the data.\n",
    "    \"\"\"\n",
    "    subject_map, uber_subject = ReadCompleteDataset(clean_param=clean_param)\n",
    "\n",
    "    if code is None:\n",
    "        subjects = subject_map.values()\n",
    "        subject = random.choice(subjects)\n",
    "        code = subject.code\n",
    "    elif code == 'uber':\n",
    "        subject = uber_subject\n",
    "    else:\n",
    "        subject = subject_map[code]\n",
    "\n",
    "    print subject.code\n",
    "\n",
    "    m = subject.GetM()\n",
    "\n",
    "    subject.Process(high=m, conc=0.1, iters=0)\n",
    "    print subject.suite.params[:m]\n",
    "\n",
    "    # plot the cdf\n",
    "    options = dict(linewidth=3, color='blue', alpha=0.5)\n",
    "    cdf = subject.MakeCdf()\n",
    "    thinkplot.Cdf(cdf, **options)\n",
    "\n",
    "    options = dict(linewidth=1, color='green', alpha=0.5)\n",
    "\n",
    "    # generate fake subjects and plot their CDFs\n",
    "    for _ in range(10):\n",
    "        prevalences = subject.suite.SamplePrevalences(m)\n",
    "        fake = FakeSubject(prevalences=prevalences)\n",
    "        cdf = fake.MakeCdf()\n",
    "        thinkplot.Cdf(cdf, **options)\n",
    "\n",
    "    root = 'species-cdf-%s' % code\n",
    "    thinkplot.Save(root=root,\n",
    "                   xlabel='rank',\n",
    "                   ylabel='CDF',\n",
    "                   xscale='log',\n",
    "                   formats=FORMATS,\n",
    "                   )\n",
    "\n",
    "\n",
    "def RunCalibration(flag='cal', num_runs=100, clean_param=50):\n",
    "    \"\"\"Runs either the calibration or validation process.\n",
    "\n",
    "    flag: string 'cal' or 'val'\n",
    "    num_runs: how many runs\n",
    "    clean_param: parameter used for data cleaning\n",
    "    \"\"\"\n",
    "    cal = Calibrator(conc=0.1)\n",
    "\n",
    "    if flag == 'val':\n",
    "        cal.Validate(num_runs=num_runs, clean_param=clean_param)\n",
    "    else:\n",
    "        cal.Calibrate(num_runs=num_runs)\n",
    "\n",
    "    cal.PlotN(root='species-n-%s' % flag)\n",
    "    cal.PlotQ(root='species-q-%s' % flag)\n",
    "    cal.PlotL(root='species-l-%s' % flag)\n",
    "    cal.PlotCalibrationCurves(root='species5-%s' % flag)\n",
    "\n",
    "\n",
    "def RunTests():\n",
    "    \"\"\"Runs calibration code and generates some figures.\"\"\"\n",
    "    RunCalibration(flag='val')\n",
    "    RunCalibration(flag='cal')\n",
    "\n",
    "    PlotSubjectCdf('B1558.G', clean_param=50)\n",
    "    PlotSubjectCdf(None)\n",
    "\n",
    "\n",
    "def main(script):\n",
    "    RandomSeed(17)\n",
    "    RunSubject('B1242', conc=1, high=100)\n",
    "\n",
    "    RandomSeed(17)\n",
    "    SimpleDirichletExample()\n",
    "\n",
    "    RandomSeed(17)\n",
    "    HierarchicalExample()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(*sys.argv)\n",
    "\"\"\"This file contains code used in \"Think Bayes\",\n",
    "by Allen B. Downey, available from greenteapress.com\n",
    "\n",
    "Copyright 2012 Allen B. Downey\n",
    "License: GNU GPLv3 http://www.gnu.org/licenses/gpl.html\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "import thinkplot\n",
    "import numpy\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import shelve\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import thinkbayes\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('error', RuntimeWarning)\n",
    "\n",
    "\n",
    "FORMATS = ['pdf', 'eps', 'png']\n",
    "\n",
    "\n",
    "class Locker(object):\n",
    "    \"\"\"Encapsulates a shelf for storing key-value pairs.\"\"\"\n",
    "\n",
    "    def __init__(self, shelf_file):\n",
    "        self.shelf = shelve.open(shelf_file)\n",
    "\n",
    "    def Close(self):\n",
    "        \"\"\"Closes the shelf.\n",
    "        \"\"\"\n",
    "        self.shelf.close()\n",
    "\n",
    "    def Add(self, key, value):\n",
    "        \"\"\"Adds a key-value pair.\"\"\"\n",
    "        self.shelf[str(key)] = value\n",
    "\n",
    "    def Lookup(self, key):\n",
    "        \"\"\"Looks up a key.\"\"\"\n",
    "        return self.shelf.get(str(key))\n",
    "\n",
    "    def Keys(self):\n",
    "        \"\"\"Returns an iterator of keys.\"\"\"\n",
    "        return self.shelf.iterkeys()\n",
    "\n",
    "    def Read(self):\n",
    "        \"\"\"Returns the contents of the shelf as a map.\"\"\"\n",
    "        return dict(self.shelf)\n",
    "\n",
    "\n",
    "class Subject(object):\n",
    "    \"\"\"Represents a subject from the belly button study.\"\"\"\n",
    "\n",
    "    def __init__(self, code):\n",
    "        \"\"\"\n",
    "        code: string ID\n",
    "        species: sequence of (int count, string species) pairs\n",
    "        \"\"\"\n",
    "        self.code = code\n",
    "        self.species = []\n",
    "        self.suite = None\n",
    "        self.num_reads = None\n",
    "        self.num_species = None\n",
    "        self.total_reads = None\n",
    "        self.total_species = None\n",
    "        self.prev_unseen = None\n",
    "        self.pmf_n = None\n",
    "        self.pmf_q = None\n",
    "        self.pmf_l = None\n",
    "\n",
    "    def Add(self, species, count):\n",
    "        \"\"\"Add a species-count pair.\n",
    "\n",
    "        It is up to the caller to ensure that species names are unique.\n",
    "\n",
    "        species: string species/genus name\n",
    "        count: int number of individuals\n",
    "        \"\"\"\n",
    "        self.species.append((count, species))\n",
    "\n",
    "    def Done(self, reverse=False, clean_param=0):\n",
    "        \"\"\"Called when we are done adding species counts.\n",
    "\n",
    "        reverse: which order to sort in\n",
    "        \"\"\"\n",
    "        if clean_param:\n",
    "            self.Clean(clean_param)\n",
    "\n",
    "        self.species.sort(reverse=reverse)        \n",
    "        counts = self.GetCounts()\n",
    "        self.num_species = len(counts)\n",
    "        self.num_reads = sum(counts)\n",
    "\n",
    "    def Clean(self, clean_param=50):\n",
    "        \"\"\"Identifies and removes bogus data.\n",
    "\n",
    "        clean_param: parameter that controls the number of legit species\n",
    "        \"\"\"\n",
    "        def prob_bogus(k, r):\n",
    "            \"\"\"Compute the probability that a species is bogus.\"\"\"\n",
    "            q = clean_param / r\n",
    "            p = (1-q) ** k\n",
    "            return p\n",
    "\n",
    "        print self.code, clean_param\n",
    "\n",
    "        counts = self.GetCounts()\n",
    "        r = 1.0 * sum(counts)\n",
    "\n",
    "        species_seq = []\n",
    "        for k, species in sorted(self.species):\n",
    "\n",
    "            if random.random() < prob_bogus(k, r):\n",
    "                continue\n",
    "            species_seq.append((k, species))\n",
    "        self.species = species_seq\n",
    "\n",
    "    def GetM(self):\n",
    "        \"\"\"Gets number of observed species.\"\"\"\n",
    "        return len(self.species)\n",
    "        \n",
    "    def GetCounts(self):\n",
    "        \"\"\"Gets the list of species counts\n",
    "\n",
    "        Should be in increasing order, if Sort() has been invoked.\n",
    "        \"\"\"\n",
    "        return [count for count, _ in self.species]\n",
    "\n",
    "    def MakeCdf(self):\n",
    "        \"\"\"Makes a CDF of total prevalence vs rank.\"\"\"\n",
    "        counts = self.GetCounts()\n",
    "        counts.sort(reverse=True)\n",
    "        cdf = thinkbayes.MakeCdfFromItems(enumerate(counts))\n",
    "        return cdf\n",
    "\n",
    "    def GetNames(self):\n",
    "        \"\"\"Gets the names of the seen species.\"\"\"\n",
    "        return [name for _, name in self.species]\n",
    "\n",
    "    def PrintCounts(self):\n",
    "        \"\"\"Prints the counts and species names.\"\"\"\n",
    "        for count, name in reversed(self.species):\n",
    "            print count, name\n",
    "\n",
    "    def GetSpecies(self, index):\n",
    "        \"\"\"Gets the count and name of the indicated species.\n",
    "\n",
    "        Returns: count-species pair\n",
    "        \"\"\"\n",
    "        return self.species[index]\n",
    "\n",
    "    def GetCdf(self):\n",
    "        \"\"\"Returns cumulative prevalence vs number of species.\n",
    "        \"\"\"\n",
    "        counts = self.GetCounts()\n",
    "        items = enumerate(counts)\n",
    "        cdf = thinkbayes.MakeCdfFromItems(items)\n",
    "        return cdf\n",
    "\n",
    "    def GetPrevalences(self):\n",
    "        \"\"\"Returns a sequence of prevalences (normalized counts).\n",
    "        \"\"\"\n",
    "        counts = self.GetCounts()\n",
    "        total = sum(counts)\n",
    "        prevalences = numpy.array(counts, dtype=numpy.float) / total\n",
    "        return prevalences\n",
    "\n",
    "    def Process(self, low=None, high=500, conc=1, iters=100):\n",
    "        \"\"\"Computes the posterior distribution of n and the prevalences.\n",
    "\n",
    "        Sets attribute: self.suite\n",
    "\n",
    "        low: minimum number of species\n",
    "        high: maximum number of species\n",
    "        conc: concentration parameter\n",
    "        iters: number of iterations to use in the estimator\n",
    "        \"\"\"\n",
    "        counts = self.GetCounts()\n",
    "        m = len(counts)\n",
    "        if low is None:\n",
    "            low = max(m, 2)\n",
    "        ns = range(low, high+1)\n",
    "\n",
    "        #start = time.time()    \n",
    "        self.suite = Species5(ns, conc=conc, iters=iters)\n",
    "        self.suite.Update(counts)\n",
    "        #end = time.time()\n",
    "\n",
    "        #print 'Processing time' end-start\n",
    "\n",
    "    def MakePrediction(self, num_sims=100):\n",
    "        \"\"\"Make predictions for the given subject.\n",
    "\n",
    "        Precondition: Process has run\n",
    "\n",
    "        num_sims: how many simulations to run for predictions\n",
    "\n",
    "        Adds attributes\n",
    "        pmf_l: predictive distribution of additional species\n",
    "        \"\"\"\n",
    "        add_reads = self.total_reads - self.num_reads\n",
    "        curves = self.RunSimulations(num_sims, add_reads)\n",
    "        self.pmf_l = self.MakePredictive(curves)\n",
    "\n",
    "    def MakeQuickPrediction(self, num_sims=100):\n",
    "        \"\"\"Make predictions for the given subject.\n",
    "\n",
    "        Precondition: Process has run\n",
    "\n",
    "        num_sims: how many simulations to run for predictions\n",
    "\n",
    "        Adds attribute:\n",
    "        pmf_l: predictive distribution of additional species\n",
    "        \"\"\"\n",
    "        add_reads = self.total_reads - self.num_reads\n",
    "        pmf = thinkbayes.Pmf()\n",
    "        _, seen = self.GetSeenSpecies()\n",
    "\n",
    "        for _ in range(num_sims):\n",
    "            _, observations = self.GenerateObservations(add_reads)\n",
    "            all_seen = seen.union(observations)\n",
    "            l = len(all_seen) - len(seen)\n",
    "            pmf.Incr(l)\n",
    "\n",
    "        pmf.Normalize()\n",
    "        self.pmf_l = pmf\n",
    "\n",
    "    def DistL(self):\n",
    "        \"\"\"Returns the distribution of additional species, l.\n",
    "        \"\"\"\n",
    "        return self.pmf_l\n",
    "\n",
    "    def MakeFigures(self):\n",
    "        \"\"\"Makes figures showing distribution of n and the prevalences.\"\"\"\n",
    "        self.PlotDistN()\n",
    "        self.PlotPrevalences()\n",
    "\n",
    "    def PlotDistN(self):\n",
    "        \"\"\"Plots distribution of n.\"\"\"\n",
    "        pmf = self.suite.DistN()\n",
    "        print '90% CI for N:', pmf.CredibleInterval(90)\n",
    "        pmf.name = self.code\n",
    "\n",
    "        thinkplot.Clf()\n",
    "        thinkplot.PrePlot(num=1)\n",
    "\n",
    "        thinkplot.Pmf(pmf)\n",
    "\n",
    "        root = 'species-ndist-%s' % self.code\n",
    "        thinkplot.Save(root=root,\n",
    "                    xlabel='Number of species',\n",
    "                    ylabel='Prob',\n",
    "                    formats=FORMATS,\n",
    "                    )\n",
    "\n",
    "    def PlotPrevalences(self, num=5):\n",
    "        \"\"\"Plots dist of prevalence for several species.\n",
    "\n",
    "        num: how many species (starting with the highest prevalence)\n",
    "        \"\"\"\n",
    "        thinkplot.Clf()\n",
    "        thinkplot.PrePlot(num=5)\n",
    "\n",
    "        for rank in range(1, num+1):\n",
    "            self.PlotPrevalence(rank)\n",
    "\n",
    "        root = 'species-prev-%s' % self.code\n",
    "        thinkplot.Save(root=root,\n",
    "                    xlabel='Prevalence',\n",
    "                    ylabel='Prob',\n",
    "                    formats=FORMATS,\n",
    "                    axis=[0, 0.3, 0, 1],\n",
    "                    )\n",
    "\n",
    "    def PlotPrevalence(self, rank=1, cdf_flag=True):\n",
    "        \"\"\"Plots dist of prevalence for one species.\n",
    "\n",
    "        rank: rank order of the species to plot.\n",
    "        cdf_flag: whether to plot the CDF\n",
    "        \"\"\"\n",
    "        # convert rank to index\n",
    "        index = self.GetM() - rank\n",
    "\n",
    "        _, mix = self.suite.DistOfPrevalence(index)\n",
    "        count, _ = self.GetSpecies(index)\n",
    "        mix.name = '%d (%d)' % (rank, count)\n",
    "\n",
    "        print '90%% CI for prevalence of species %d:' % rank, \n",
    "        print mix.CredibleInterval(90)\n",
    "\n",
    "        if cdf_flag:\n",
    "            cdf = mix.MakeCdf()\n",
    "            thinkplot.Cdf(cdf)\n",
    "        else:\n",
    "            thinkplot.Pmf(mix)\n",
    "\n",
    "    def PlotMixture(self, rank=1):\n",
    "        \"\"\"Plots dist of prevalence for all n, and the mix.\n",
    "\n",
    "        rank: rank order of the species to plot\n",
    "        \"\"\"\n",
    "        # convert rank to index\n",
    "        index = self.GetM() - rank\n",
    "\n",
    "        print self.GetSpecies(index)\n",
    "        print self.GetCounts()[index]\n",
    "\n",
    "        metapmf, mix = self.suite.DistOfPrevalence(index)\n",
    "\n",
    "        thinkplot.Clf()\n",
    "        for pmf in metapmf.Values():\n",
    "            thinkplot.Pmf(pmf, color='blue', alpha=0.2, linewidth=0.5)\n",
    "\n",
    "        thinkplot.Pmf(mix, color='blue', alpha=0.9, linewidth=2)\n",
    "\n",
    "        root = 'species-mix-%s' % self.code\n",
    "        thinkplot.Save(root=root,\n",
    "                    xlabel='Prevalence',\n",
    "                    ylabel='Prob',\n",
    "                    formats=FORMATS,\n",
    "                    axis=[0, 0.3, 0, 0.3],\n",
    "                    legend=False)\n",
    "\n",
    "    def GetSeenSpecies(self):\n",
    "        \"\"\"Makes a set of the names of seen species.\n",
    "\n",
    "        Returns: number of species, set of string species names\n",
    "        \"\"\"\n",
    "        names = self.GetNames()\n",
    "        m = len(names)\n",
    "        seen = set(SpeciesGenerator(names, m))\n",
    "        return m, seen\n",
    "\n",
    "    def GenerateObservations(self, num_reads):\n",
    "        \"\"\"Generates a series of random observations.\n",
    "\n",
    "        num_reads: number of reads to generate\n",
    "\n",
    "        Returns: number of species, sequence of string species names\n",
    "        \"\"\"\n",
    "        n, prevalences = self.suite.SamplePosterior()\n",
    "\n",
    "        names = self.GetNames()\n",
    "        name_iter = SpeciesGenerator(names, n)\n",
    "\n",
    "        items = zip(name_iter, prevalences)\n",
    "\n",
    "        cdf = thinkbayes.MakeCdfFromItems(items)\n",
    "        observations = cdf.Sample(num_reads)\n",
    "\n",
    "        #for ob in observations:\n",
    "        #    print ob\n",
    "\n",
    "        return n, observations\n",
    "\n",
    "    def Resample(self, num_reads):\n",
    "        \"\"\"Choose a random subset of the data (without replacement).\n",
    "\n",
    "        num_reads: number of reads in the subset\n",
    "        \"\"\"\n",
    "        t = []\n",
    "        for count, species in self.species:\n",
    "            t.extend([species]*count)\n",
    "\n",
    "        random.shuffle(t)\n",
    "        reads = t[:num_reads]\n",
    "\n",
    "        subject = Subject(self.code)\n",
    "        hist = thinkbayes.MakeHistFromList(reads)\n",
    "        for species, count in hist.Items():\n",
    "            subject.Add(species, count)\n",
    "\n",
    "        subject.Done()\n",
    "        return subject\n",
    "\n",
    "    def Match(self, match):\n",
    "        \"\"\"Match up a rarefied subject with a complete subject.\n",
    "\n",
    "        match: complete Subject\n",
    "\n",
    "        Assigns attributes:\n",
    "        total_reads:\n",
    "        total_species:\n",
    "        prev_unseen:\n",
    "        \"\"\"\n",
    "        self.total_reads = match.num_reads\n",
    "        self.total_species = match.num_species\n",
    "\n",
    "        # compute the prevalence of unseen species (at least approximately,\n",
    "        # based on all species counts in match\n",
    "        _, seen = self.GetSeenSpecies()\n",
    "\n",
    "        seen_total = 0.0\n",
    "        unseen_total = 0.0\n",
    "        for count, species in match.species:\n",
    "            if species in seen:\n",
    "                seen_total += count\n",
    "            else:\n",
    "                unseen_total += count\n",
    "\n",
    "        self.prev_unseen = unseen_total / (seen_total + unseen_total)\n",
    "\n",
    "    def RunSimulation(self, num_reads, frac_flag=False, jitter=0.01):\n",
    "        \"\"\"Simulates additional observations and returns a rarefaction curve.\n",
    "\n",
    "        k is the number of additional observations\n",
    "        num_new is the number of new species seen\n",
    "\n",
    "        num_reads: how many new reads to simulate\n",
    "        frac_flag: whether to convert to fraction of species seen\n",
    "        jitter: size of jitter added if frac_flag is true\n",
    "\n",
    "        Returns: list of (k, num_new) pairs\n",
    "        \"\"\"\n",
    "        m, seen = self.GetSeenSpecies()\n",
    "        n, observations = self.GenerateObservations(num_reads)\n",
    "\n",
    "        curve = []\n",
    "        for i, obs in enumerate(observations):\n",
    "            seen.add(obs)\n",
    "\n",
    "            if frac_flag:\n",
    "                frac_seen = len(seen) / float(n)\n",
    "                frac_seen += random.uniform(-jitter, jitter)\n",
    "                curve.append((i+1, frac_seen))\n",
    "            else:\n",
    "                num_new = len(seen) - m\n",
    "                curve.append((i+1, num_new))\n",
    "\n",
    "        return curve\n",
    "\n",
    "    def RunSimulations(self, num_sims, num_reads, frac_flag=False):\n",
    "        \"\"\"Runs simulations and returns a list of curves.\n",
    "\n",
    "        Each curve is a sequence of (k, num_new) pairs.\n",
    "\n",
    "        num_sims: how many simulations to run\n",
    "        num_reads: how many samples to generate in each simulation\n",
    "        frac_flag: whether to convert num_new to fraction of total\n",
    "        \"\"\"\n",
    "        curves = [self.RunSimulation(num_reads, frac_flag) \n",
    "                  for _ in range(num_sims)]\n",
    "        return curves\n",
    "\n",
    "    def MakePredictive(self, curves):\n",
    "        \"\"\"Makes a predictive distribution of additional species.\n",
    "\n",
    "        curves: list of (k, num_new) curves \n",
    "\n",
    "        Returns: Pmf of num_new\n",
    "        \"\"\"\n",
    "        pred = thinkbayes.Pmf(name=self.code)\n",
    "        for curve in curves:\n",
    "            _, last_num_new = curve[-1]\n",
    "            pred.Incr(last_num_new)\n",
    "        pred.Normalize()\n",
    "        return pred\n",
    "\n",
    "\n",
    "def MakeConditionals(curves, ks):\n",
    "    \"\"\"Makes Cdfs of the distribution of num_new conditioned on k.\n",
    "\n",
    "    curves: list of (k, num_new) curves \n",
    "    ks: list of values of k\n",
    "\n",
    "    Returns: list of Cdfs\n",
    "    \"\"\"\n",
    "    joint = MakeJointPredictive(curves)\n",
    "\n",
    "    cdfs = []\n",
    "    for k in ks:\n",
    "        pmf = joint.Conditional(1, 0, k)\n",
    "        pmf.name = 'k=%d' % k\n",
    "        cdf = pmf.MakeCdf()\n",
    "        cdfs.append(cdf)\n",
    "        print '90%% credible interval for %d' % k,\n",
    "        print cdf.CredibleInterval(90)\n",
    "    return cdfs\n",
    "\n",
    "\n",
    "def MakeJointPredictive(curves):\n",
    "    \"\"\"Makes a joint distribution of k and num_new.\n",
    "\n",
    "    curves: list of (k, num_new) curves \n",
    "\n",
    "    Returns: joint Pmf of (k, num_new)\n",
    "    \"\"\"\n",
    "    joint = thinkbayes.Joint()\n",
    "    for curve in curves:\n",
    "        for k, num_new in curve:\n",
    "            joint.Incr((k, num_new))\n",
    "    joint.Normalize()\n",
    "    return joint\n",
    "\n",
    "\n",
    "def MakeFracCdfs(curves, ks):\n",
    "    \"\"\"Makes Cdfs of the fraction of species seen.\n",
    "\n",
    "    curves: list of (k, num_new) curves \n",
    "\n",
    "    Returns: list of Cdfs\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    for curve in curves:\n",
    "        for k, frac in curve:\n",
    "            if k in ks:\n",
    "                d.setdefault(k, []).append(frac)\n",
    "\n",
    "    cdfs = {}\n",
    "    for k, fracs in d.iteritems():\n",
    "        cdf = thinkbayes.MakeCdfFromList(fracs)\n",
    "        cdfs[k] = cdf\n",
    "\n",
    "    return cdfs\n",
    "\n",
    "def SpeciesGenerator(names, num):\n",
    "    \"\"\"Generates a series of names, starting with the given names.\n",
    "\n",
    "    Additional names are 'unseen' plus a serial number.\n",
    "\n",
    "    names: list of strings\n",
    "    num: total number of species names to generate\n",
    "\n",
    "    Returns: string iterator\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    for name in names:\n",
    "        yield name\n",
    "        i += 1\n",
    "\n",
    "    while i < num:\n",
    "        yield 'unseen-%d' % i\n",
    "        i += 1\n",
    "            \n",
    "\n",
    "def ReadRarefactedData(filename='journal.pone.0047712.s001.csv', \n",
    "                       clean_param=0):\n",
    "    \"\"\"Reads a data file and returns a list of Subjects.\n",
    "\n",
    "    Data from http://www.plosone.org/article/\n",
    "    info%3Adoi%2F10.1371%2Fjournal.pone.0047712#s4\n",
    "\n",
    "    filename: string filename to read\n",
    "    clean_param: parameter passed to Clean\n",
    "\n",
    "    Returns: map from code to Subject\n",
    "    \"\"\"\n",
    "    fp = open(filename)\n",
    "    reader = csv.reader(fp)\n",
    "    _ = reader.next()\n",
    "    \n",
    "    subject = Subject('')\n",
    "    subject_map = {}\n",
    "\n",
    "    i = 0\n",
    "    for t in reader:\n",
    "        code = t[0]\n",
    "        if code != subject.code:\n",
    "            # start a new subject\n",
    "            subject = Subject(code)\n",
    "            subject_map[code] = subject\n",
    "\n",
    "        # append a number to the species names so they're unique\n",
    "        species = t[1]\n",
    "        species = '%s-%d' % (species, i)\n",
    "        i += 1\n",
    "\n",
    "        count = int(t[2])\n",
    "        subject.Add(species, count)\n",
    "\n",
    "    for code, subject in subject_map.iteritems():\n",
    "        subject.Done(clean_param=clean_param)\n",
    "\n",
    "    return subject_map\n",
    "\n",
    "\n",
    "def ReadCompleteDataset(filename='BBB_data_from_Rob.csv', clean_param=0):\n",
    "    \"\"\"Reads a data file and returns a list of Subjects.\n",
    "\n",
    "    Data from personal correspondence with Rob Dunn, received 2-7-13.\n",
    "    Converted from xlsx to csv.\n",
    "\n",
    "    filename: string filename to read\n",
    "    clean_param: parameter passed to Clean\n",
    "\n",
    "    Returns: map from code to Subject\n",
    "    \"\"\"\n",
    "    fp = open(filename)\n",
    "    reader = csv.reader(fp)\n",
    "    header = reader.next()\n",
    "    header = reader.next()\n",
    "\n",
    "    subject_codes = header[1:-1]\n",
    "    subject_codes = ['B'+code for code in subject_codes]\n",
    "\n",
    "    # create the subject map\n",
    "    uber_subject = Subject('uber')\n",
    "    subject_map = {}\n",
    "    for code in subject_codes:\n",
    "        subject_map[code] = Subject(code)\n",
    "\n",
    "    # read lines\n",
    "    i = 0\n",
    "    for t in reader:\n",
    "        otu_code = t[0]\n",
    "        if otu_code == '':\n",
    "            continue\n",
    "\n",
    "        # pull out a species name and give it a number\n",
    "        otu_names = t[-1]\n",
    "        taxons = otu_names.split(';')\n",
    "        species = taxons[-1]\n",
    "        species = '%s-%d' % (species, i)\n",
    "        i += 1\n",
    "\n",
    "        counts = [int(x) for x in t[1:-1]]\n",
    "\n",
    "        # print otu_code, species\n",
    "\n",
    "        for code, count in zip(subject_codes, counts):\n",
    "            if count > 0:\n",
    "                subject_map[code].Add(species, count)\n",
    "                uber_subject.Add(species, count)\n",
    "\n",
    "    uber_subject.Done(clean_param=clean_param)\n",
    "    for code, subject in subject_map.iteritems():\n",
    "        subject.Done(clean_param=clean_param)\n",
    "\n",
    "    return subject_map, uber_subject\n",
    "        \n",
    "\n",
    "def JoinSubjects():\n",
    "    \"\"\"Reads both datasets and computers their inner join.\n",
    "\n",
    "    Finds all subjects that appear in both datasets.\n",
    "\n",
    "    For subjects in the rarefacted dataset, looks up the total\n",
    "    number of reads and stores it as total_reads.  num_reads\n",
    "    is normally 400.\n",
    "    \n",
    "    Returns: map from code to Subject\n",
    "    \"\"\"\n",
    "\n",
    "    # read the rarefacted dataset\n",
    "    sampled_subjects = ReadRarefactedData()\n",
    "\n",
    "    # read the complete dataset\n",
    "    all_subjects, _ = ReadCompleteDataset()\n",
    "\n",
    "    for code, subject in sampled_subjects.iteritems():\n",
    "        if code in all_subjects:\n",
    "            match = all_subjects[code]\n",
    "            subject.Match(match)\n",
    "\n",
    "    return sampled_subjects\n",
    "\n",
    "\n",
    "def JitterCurve(curve, dx=0.2, dy=0.3):\n",
    "    \"\"\"Adds random noise to the pairs in a curve.\n",
    "\n",
    "    dx and dy control the amplitude of the noise in each dimension.\n",
    "    \"\"\"\n",
    "    curve = [(x+random.uniform(-dx, dx), \n",
    "              y+random.uniform(-dy, dy)) for x, y in curve]\n",
    "    return curve\n",
    "\n",
    "\n",
    "def OffsetCurve(curve, i, n, dx=0.3, dy=0.3):\n",
    "    \"\"\"Adds random noise to the pairs in a curve.\n",
    "\n",
    "    i is the index of the curve\n",
    "    n is the number of curves\n",
    "\n",
    "    dx and dy control the amplitude of the noise in each dimension.\n",
    "    \"\"\"\n",
    "    xoff = -dx + 2 * dx * i / (n-1)\n",
    "    yoff = -dy + 2 * dy * i / (n-1)\n",
    "    curve = [(x+xoff, y+yoff) for x, y in curve]\n",
    "    return curve\n",
    "\n",
    "\n",
    "def PlotCurves(curves, root='species-rare'):\n",
    "    \"\"\"Plots a set of curves.\n",
    "\n",
    "    curves is a list of curves; each curve is a list of (x, y) pairs.\n",
    "    \"\"\"\n",
    "    thinkplot.Clf()\n",
    "    color = '#225EA8'\n",
    "\n",
    "    n = len(curves)\n",
    "    for i, curve in enumerate(curves):\n",
    "        curve = OffsetCurve(curve, i, n)\n",
    "        xs, ys = zip(*curve)\n",
    "        thinkplot.Plot(xs, ys, color=color, alpha=0.3, linewidth=0.5)\n",
    "\n",
    "    thinkplot.Save(root=root,\n",
    "                xlabel='# samples',\n",
    "                ylabel='# species',\n",
    "                formats=FORMATS,\n",
    "                legend=False)\n",
    "\n",
    "\n",
    "def PlotConditionals(cdfs, root='species-cond'):\n",
    "    \"\"\"Plots cdfs of num_new conditioned on k.\n",
    "\n",
    "    cdfs: list of Cdf\n",
    "    root: string filename root\n",
    "    \"\"\"\n",
    "    thinkplot.Clf()\n",
    "    thinkplot.PrePlot(num=len(cdfs))\n",
    "\n",
    "    thinkplot.Cdfs(cdfs)\n",
    "\n",
    "    thinkplot.Save(root=root,\n",
    "                xlabel='# new species',\n",
    "                ylabel='Prob',\n",
    "                formats=FORMATS)\n",
    "\n",
    "\n",
    "def PlotFracCdfs(cdfs, root='species-frac'):\n",
    "    \"\"\"Plots CDFs of the fraction of species seen.\n",
    "\n",
    "    cdfs: map from k to CDF of fraction of species seen after k samples\n",
    "    \"\"\"\n",
    "    thinkplot.Clf()\n",
    "    color = '#225EA8'\n",
    "\n",
    "    for k, cdf in cdfs.iteritems():\n",
    "        xs, ys = cdf.Render()\n",
    "        ys = [1-y for y in ys]\n",
    "        thinkplot.Plot(xs, ys, color=color, linewidth=1)\n",
    "\n",
    "        x = 0.9\n",
    "        y = 1 - cdf.Prob(x)\n",
    "        pyplot.text(x, y, str(k), fontsize=9, color=color,\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center',\n",
    "                    bbox=dict(facecolor='white', edgecolor='none'))\n",
    "\n",
    "    thinkplot.Save(root=root,\n",
    "                xlabel='Fraction of species seen',\n",
    "                ylabel='Probability',\n",
    "                formats=FORMATS,\n",
    "                legend=False)\n",
    "\n",
    "\n",
    "class Species(thinkbayes.Suite):\n",
    "    \"\"\"Represents hypotheses about the number of species.\"\"\"\n",
    "    \n",
    "    def __init__(self, ns, conc=1, iters=1000):\n",
    "        hypos = [thinkbayes.Dirichlet(n, conc) for n in ns]\n",
    "        thinkbayes.Suite.__init__(self, hypos)\n",
    "        self.iters = iters\n",
    "\n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates the suite based on the data.\n",
    "\n",
    "        data: list of observed frequencies\n",
    "        \"\"\"\n",
    "        # call Update in the parent class, which calls Likelihood\n",
    "        thinkbayes.Suite.Update(self, data)\n",
    "\n",
    "        # update the next level of the hierarchy\n",
    "        for hypo in self.Values():\n",
    "            hypo.Update(data)\n",
    "\n",
    "    def Likelihood(self, data, hypo):\n",
    "        \"\"\"Computes the likelihood of the data under this hypothesis.\n",
    "\n",
    "        hypo: Dirichlet object\n",
    "        data: list of observed frequencies\n",
    "        \"\"\"\n",
    "        dirichlet = hypo\n",
    "\n",
    "        # draw sample Likelihoods from the hypothetical Dirichlet dist\n",
    "        # and add them up\n",
    "        like = 0\n",
    "        for _ in range(self.iters):\n",
    "            like += dirichlet.Likelihood(data)\n",
    "\n",
    "        # correct for the number of ways the observed species\n",
    "        # might have been chosen from all species\n",
    "        m = len(data)\n",
    "        like *= thinkbayes.BinomialCoef(dirichlet.n, m)\n",
    "\n",
    "        return like\n",
    "\n",
    "    def DistN(self):\n",
    "        \"\"\"Computes the distribution of n.\"\"\"\n",
    "        pmf = thinkbayes.Pmf()\n",
    "        for hypo, prob in self.Items():\n",
    "            pmf.Set(hypo.n, prob)\n",
    "        return pmf\n",
    "        \n",
    "\n",
    "class Species2(object):\n",
    "    \"\"\"Represents hypotheses about the number of species.\n",
    "\n",
    "    Combines two layers of the hierarchy into one object.\n",
    "\n",
    "    ns and probs represent the distribution of N\n",
    "\n",
    "    params represents the parameters of the Dirichlet distributions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ns, conc=1, iters=1000):\n",
    "        self.ns = ns\n",
    "        self.conc = conc\n",
    "        self.probs = numpy.ones(len(ns), dtype=numpy.float)\n",
    "        self.params = numpy.ones(self.ns[-1], dtype=numpy.float) * conc\n",
    "        self.iters = iters\n",
    "        self.num_reads = 0\n",
    "        self.m = 0\n",
    "\n",
    "    def Preload(self, data):\n",
    "        \"\"\"Change the initial parameters to fit the data better.\n",
    "\n",
    "        Just an experiment.  Doesn't work.\n",
    "        \"\"\"\n",
    "        m = len(data)\n",
    "        singletons = data.count(1)\n",
    "        num = m - singletons\n",
    "        print m, singletons, num\n",
    "        addend = numpy.ones(num, dtype=numpy.float) * 1\n",
    "        print len(addend)\n",
    "        print len(self.params[singletons:m])\n",
    "        self.params[singletons:m] += addend\n",
    "        print 'Preload', num\n",
    "\n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates the distribution based on data.\n",
    "\n",
    "        data: numpy array of counts\n",
    "        \"\"\"\n",
    "        self.num_reads += sum(data)\n",
    "\n",
    "        like = numpy.zeros(len(self.ns), dtype=numpy.float)\n",
    "        for _ in range(self.iters):\n",
    "            like += self.SampleLikelihood(data)\n",
    "\n",
    "        self.probs *= like\n",
    "        self.probs /= self.probs.sum()\n",
    "\n",
    "        self.m = len(data)\n",
    "        #self.params[:self.m] += data * self.conc\n",
    "        self.params[:self.m] += data\n",
    "\n",
    "    def SampleLikelihood(self, data):\n",
    "        \"\"\"Computes the likelihood of the data for all values of n.\n",
    "\n",
    "        Draws one sample from the distribution of prevalences.\n",
    "\n",
    "        data: sequence of observed counts\n",
    "\n",
    "        Returns: numpy array of m likelihoods\n",
    "        \"\"\"\n",
    "        gammas = numpy.random.gamma(self.params)\n",
    "\n",
    "        m = len(data)\n",
    "        row = gammas[:m]\n",
    "        col = numpy.cumsum(gammas)\n",
    "\n",
    "        log_likes = []\n",
    "        for n in self.ns:\n",
    "            ps = row / col[n-1]\n",
    "            terms = numpy.log(ps) * data\n",
    "            log_like = terms.sum()\n",
    "            log_likes.append(log_like)\n",
    "\n",
    "        log_likes -= numpy.max(log_likes)\n",
    "        likes = numpy.exp(log_likes)\n",
    "\n",
    "        coefs = [thinkbayes.BinomialCoef(n, m) for n in self.ns]\n",
    "        likes *= coefs\n",
    "\n",
    "        return likes\n",
    "\n",
    "    def DistN(self):\n",
    "        \"\"\"Computes the distribution of n.\n",
    "\n",
    "        Returns: new Pmf object\n",
    "        \"\"\"\n",
    "        pmf = thinkbayes.MakePmfFromItems(zip(self.ns, self.probs))\n",
    "        return pmf\n",
    "\n",
    "    def RandomN(self):\n",
    "        \"\"\"Returns a random value of n.\"\"\"\n",
    "        return self.DistN().Random()\n",
    "\n",
    "    def DistQ(self, iters=100):\n",
    "        \"\"\"Computes the distribution of q based on distribution of n.\n",
    "\n",
    "        Returns: pmf of q\n",
    "        \"\"\"\n",
    "        cdf_n = self.DistN().MakeCdf()\n",
    "        sample_n = cdf_n.Sample(iters)\n",
    "\n",
    "        pmf = thinkbayes.Pmf()\n",
    "        for n in sample_n:\n",
    "            q = self.RandomQ(n)\n",
    "            pmf.Incr(q)\n",
    "\n",
    "        pmf.Normalize()\n",
    "        return pmf\n",
    "\n",
    "    def RandomQ(self, n):\n",
    "        \"\"\"Returns a random value of q.\n",
    "\n",
    "        Based on n, self.num_reads and self.conc.\n",
    "\n",
    "        n: number of species\n",
    "\n",
    "        Returns: q\n",
    "        \"\"\"\n",
    "        # generate random prevalences\n",
    "        dirichlet = thinkbayes.Dirichlet(n, conc=self.conc)\n",
    "        prevalences = dirichlet.Random()\n",
    "\n",
    "        # generate a simulated sample\n",
    "        pmf = thinkbayes.MakePmfFromItems(enumerate(prevalences))\n",
    "        cdf = pmf.MakeCdf()\n",
    "        sample = cdf.Sample(self.num_reads)\n",
    "        seen = set(sample)\n",
    "\n",
    "        # add up the prevalence of unseen species\n",
    "        q = 0\n",
    "        for species, prev in enumerate(prevalences):\n",
    "            if species not in seen:\n",
    "                q += prev\n",
    "\n",
    "        return q\n",
    "\n",
    "    def MarginalBeta(self, n, index):\n",
    "        \"\"\"Computes the conditional distribution of the indicated species.\n",
    "        \n",
    "        n: conditional number of species\n",
    "        index: which species\n",
    "\n",
    "        Returns: Beta object representing a distribution of prevalence.\n",
    "        \"\"\"\n",
    "        alpha0 = self.params[:n].sum()\n",
    "        alpha = self.params[index]\n",
    "        return thinkbayes.Beta(alpha, alpha0-alpha)\n",
    "\n",
    "    def DistOfPrevalence(self, index):\n",
    "        \"\"\"Computes the distribution of prevalence for the indicated species.\n",
    "\n",
    "        index: which species\n",
    "\n",
    "        Returns: (metapmf, mix) where metapmf is a MetaPmf and mix is a Pmf\n",
    "        \"\"\"\n",
    "        metapmf = thinkbayes.Pmf()\n",
    "\n",
    "        for n, prob in zip(self.ns, self.probs):\n",
    "            beta = self.MarginalBeta(n, index)\n",
    "            pmf = beta.MakePmf()\n",
    "            metapmf.Set(pmf, prob)\n",
    "\n",
    "        mix = thinkbayes.MakeMixture(metapmf)\n",
    "        return metapmf, mix\n",
    "        \n",
    "    def SamplePosterior(self):\n",
    "        \"\"\"Draws random n and prevalences.\n",
    "\n",
    "        Returns: (n, prevalences)\n",
    "        \"\"\"\n",
    "        n = self.RandomN()\n",
    "        prevalences = self.SamplePrevalences(n)\n",
    "\n",
    "        #print 'Peeking at n_cheat'\n",
    "        #n = n_cheat\n",
    "\n",
    "        return n, prevalences\n",
    "\n",
    "    def SamplePrevalences(self, n):\n",
    "        \"\"\"Draws a sample of prevalences given n.\n",
    "\n",
    "        n: the number of species assumed in the conditional\n",
    "\n",
    "        Returns: numpy array of n prevalences\n",
    "        \"\"\"\n",
    "        if n == 1:\n",
    "            return [1.0]\n",
    "\n",
    "        q_desired = self.RandomQ(n)\n",
    "        q_desired = max(q_desired, 1e-6)\n",
    "\n",
    "        params = self.Unbias(n, self.m, q_desired)\n",
    "\n",
    "        gammas = numpy.random.gamma(params)\n",
    "        gammas /= gammas.sum()\n",
    "        return gammas\n",
    "        \n",
    "    def Unbias(self, n, m, q_desired):\n",
    "        \"\"\"Adjusts the parameters to achieve desired prev_unseen (q).\n",
    "\n",
    "        n: number of species\n",
    "        m: seen species\n",
    "        q_desired: prevalence of unseen species\n",
    "        \"\"\"\n",
    "        params = self.params[:n].copy()\n",
    "\n",
    "        if n == m:\n",
    "            return params\n",
    "        \n",
    "        x = sum(params[:m])\n",
    "        y = sum(params[m:])\n",
    "        a = x + y\n",
    "        #print x, y, a, x/a, y/a\n",
    "\n",
    "        g = q_desired * a / y\n",
    "        f = (a - g * y) / x\n",
    "        params[:m] *= f\n",
    "        params[m:] *= g\n",
    "\n",
    "        return params\n",
    "\n",
    "\n",
    "class Species3(Species2):\n",
    "    \"\"\"Represents hypotheses about the number of species.\"\"\"\n",
    "    \n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates the suite based on the data.\n",
    "\n",
    "        data: list of observations\n",
    "        \"\"\"\n",
    "        # sample the likelihoods and add them up\n",
    "        like = numpy.zeros(len(self.ns), dtype=numpy.float)\n",
    "        for _ in range(self.iters):\n",
    "            like += self.SampleLikelihood(data)\n",
    "\n",
    "        self.probs *= like\n",
    "        self.probs /= self.probs.sum()\n",
    "\n",
    "        m = len(data)\n",
    "        self.params[:m] += data\n",
    "\n",
    "    def SampleLikelihood(self, data):\n",
    "        \"\"\"Computes the likelihood of the data under all hypotheses.\n",
    "\n",
    "        data: list of observations\n",
    "        \"\"\"\n",
    "        # get a random sample\n",
    "        gammas = numpy.random.gamma(self.params)\n",
    "\n",
    "        # row is just the first m elements of gammas\n",
    "        m = len(data)\n",
    "        row = gammas[:m]\n",
    "\n",
    "        # col is the cumulative sum of gammas\n",
    "        col = numpy.cumsum(gammas)[self.ns[0]-1:]\n",
    "\n",
    "        # each row of the array is a set of ps, normalized\n",
    "        # for each hypothetical value of n\n",
    "        array = row / col[:, numpy.newaxis]\n",
    "\n",
    "        # computing the multinomial PDF under a log transform\n",
    "        # take the log of the ps and multiply by the data\n",
    "        terms = numpy.log(array) * data\n",
    "\n",
    "        # add up the rows\n",
    "        log_likes = terms.sum(axis=1)\n",
    "\n",
    "        # before exponentiating, scale into a reasonable range\n",
    "        log_likes -= numpy.max(log_likes)\n",
    "        likes = numpy.exp(log_likes)\n",
    "\n",
    "        # correct for the number of ways we could see m species\n",
    "        # out of a possible n\n",
    "        coefs = [thinkbayes.BinomialCoef(n, m) for n in self.ns]\n",
    "        likes *= coefs\n",
    "\n",
    "        return likes\n",
    "\n",
    "\n",
    "class Species4(Species):\n",
    "    \"\"\"Represents hypotheses about the number of species.\"\"\"\n",
    "    \n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates the suite based on the data.\n",
    "\n",
    "        data: list of observed frequencies\n",
    "        \"\"\"\n",
    "        m = len(data)\n",
    "\n",
    "        # loop through the species and update one at a time\n",
    "        for i in range(m):\n",
    "            one = numpy.zeros(i+1)\n",
    "            one[i] = data[i]\n",
    "            \n",
    "            # call the parent class\n",
    "            Species.Update(self, one)\n",
    "\n",
    "    def Likelihood(self, data, hypo):\n",
    "        \"\"\"Computes the likelihood of the data under this hypothesis.\n",
    "\n",
    "        Note: this only works correctly if we update one species at a time.\n",
    "\n",
    "        hypo: Dirichlet object\n",
    "        data: list of observed frequencies\n",
    "        \"\"\"\n",
    "        dirichlet = hypo\n",
    "        like = 0\n",
    "        for _ in range(self.iters):\n",
    "            like += dirichlet.Likelihood(data)\n",
    "\n",
    "        # correct for the number of unseen species the new one\n",
    "        # could have been\n",
    "        m = len(data)\n",
    "        num_unseen = dirichlet.n - m + 1\n",
    "        like *= num_unseen\n",
    "\n",
    "        return like\n",
    "\n",
    "\n",
    "class Species5(Species2):\n",
    "    \"\"\"Represents hypotheses about the number of species.\n",
    "\n",
    "    Combines two laters of the hierarchy into one object.\n",
    "\n",
    "    ns and probs represent the distribution of N\n",
    "\n",
    "    params represents the parameters of the Dirichlet distributions\n",
    "    \"\"\"\n",
    "    \n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates the suite based on the data.\n",
    "\n",
    "        data: list of observed frequencies in increasing order\n",
    "        \"\"\"\n",
    "        # loop through the species and update one at a time\n",
    "        m = len(data)\n",
    "        for i in range(m):\n",
    "            self.UpdateOne(i+1, data[i])\n",
    "            self.params[i] += data[i]\n",
    "\n",
    "    def UpdateOne(self, i, count):\n",
    "        \"\"\"Updates the suite based on the data.\n",
    "\n",
    "        Evaluates the likelihood for all values of n.\n",
    "\n",
    "        i: which species was observed (1..n)\n",
    "        count: how many were observed\n",
    "        \"\"\"\n",
    "        # how many species have we seen so far\n",
    "        self.m = i\n",
    "\n",
    "        # how many reads have we seen\n",
    "        self.num_reads += count\n",
    "\n",
    "        if self.iters == 0:\n",
    "            return\n",
    "\n",
    "        # sample the likelihoods and add them up\n",
    "        likes = numpy.zeros(len(self.ns), dtype=numpy.float)\n",
    "        for _ in range(self.iters):\n",
    "            likes += self.SampleLikelihood(i, count)\n",
    "\n",
    "        # correct for the number of unseen species the new one\n",
    "        # could have been\n",
    "        unseen_species = [n-i+1 for n in self.ns]\n",
    "        likes *= unseen_species\n",
    "\n",
    "        # multiply the priors by the likelihoods and renormalize\n",
    "        self.probs *= likes\n",
    "        self.probs /= self.probs.sum()\n",
    "\n",
    "    def SampleLikelihood(self, i, count):\n",
    "        \"\"\"Computes the likelihood of the data under all hypotheses.\n",
    "\n",
    "        i: which species was observed\n",
    "        count: how many were observed\n",
    "        \"\"\"\n",
    "        # get a random sample of p\n",
    "        gammas = numpy.random.gamma(self.params)\n",
    "\n",
    "        # sums is the cumulative sum of p, for each value of n\n",
    "        sums = numpy.cumsum(gammas)[self.ns[0]-1:]\n",
    "\n",
    "        # get p for the mth species, for each value of n\n",
    "        ps = gammas[i-1] / sums\n",
    "        log_likes = numpy.log(ps) * count\n",
    "\n",
    "        # before exponentiating, scale into a reasonable range\n",
    "        log_likes -= numpy.max(log_likes)\n",
    "        likes = numpy.exp(log_likes)\n",
    "\n",
    "        return likes\n",
    "\n",
    "\n",
    "def MakePosterior(constructor, data, ns, conc=1, iters=1000):\n",
    "    \"\"\"Makes a suite, updates it and returns the posterior suite.\n",
    "\n",
    "    Prints the elapsed time.\n",
    "\n",
    "    data: observed species and their counts\n",
    "    ns: sequence of hypothetical ns\n",
    "    conc: concentration parameter\n",
    "    iters: how many samples to draw\n",
    "\n",
    "    Returns: posterior suite of the given type\n",
    "    \"\"\"\n",
    "    suite = constructor(ns, conc=conc, iters=iters)\n",
    "\n",
    "    # print constructor.__name__\n",
    "    start = time.time()\n",
    "    suite.Update(data)\n",
    "    end = time.time()\n",
    "    print 'Processing time', end-start\n",
    "\n",
    "    return suite\n",
    "\n",
    "\n",
    "def PlotAllVersions():\n",
    "    \"\"\"Makes a graph of posterior distributions of N.\"\"\"\n",
    "    data = [1, 2, 3]\n",
    "    m = len(data)\n",
    "    n = 20\n",
    "    ns = range(m, n)\n",
    "\n",
    "    for constructor in [Species, Species2, Species3, Species4, Species5]:\n",
    "        suite = MakePosterior(constructor, data, ns)\n",
    "        pmf = suite.DistN()\n",
    "        pmf.name = '%s' % (constructor.__name__)\n",
    "        thinkplot.Pmf(pmf)\n",
    "\n",
    "    thinkplot.Save(root='species3',\n",
    "                xlabel='Number of species',\n",
    "                ylabel='Prob')\n",
    "\n",
    "\n",
    "def PlotMedium():\n",
    "    \"\"\"Makes a graph of posterior distributions of N.\"\"\"\n",
    "    data = [1, 1, 1, 1, 2, 3, 5, 9]\n",
    "    m = len(data)\n",
    "    n = 20\n",
    "    ns = range(m, n)\n",
    "\n",
    "    for constructor in [Species, Species2, Species3, Species4, Species5]:\n",
    "        suite = MakePosterior(constructor, data, ns)\n",
    "        pmf = suite.DistN()\n",
    "        pmf.name = '%s' % (constructor.__name__)\n",
    "        thinkplot.Pmf(pmf)\n",
    "\n",
    "    thinkplot.Show()\n",
    "\n",
    "\n",
    "def SimpleDirichletExample():\n",
    "    \"\"\"Makes a plot showing posterior distributions for three species.\n",
    "\n",
    "    This is the case where we know there are exactly three species.\n",
    "    \"\"\"\n",
    "    thinkplot.Clf()\n",
    "    thinkplot.PrePlot(3)\n",
    "\n",
    "    names = ['lions',  'tigers', 'bears']\n",
    "    data = [3, 2, 1]\n",
    "\n",
    "    dirichlet = thinkbayes.Dirichlet(3)\n",
    "    for i in range(3):\n",
    "        beta = dirichlet.MarginalBeta(i)\n",
    "        print 'mean', names[i], beta.Mean()\n",
    "\n",
    "    dirichlet.Update(data)\n",
    "    for i in range(3):\n",
    "        beta = dirichlet.MarginalBeta(i)\n",
    "        print 'mean', names[i], beta.Mean()\n",
    "\n",
    "        pmf = beta.MakePmf(name=names[i])\n",
    "        thinkplot.Pmf(pmf)\n",
    "\n",
    "    thinkplot.Save(root='species1',\n",
    "                xlabel='Prevalence',\n",
    "                ylabel='Prob',\n",
    "                formats=FORMATS,\n",
    "                )\n",
    "\n",
    "\n",
    "def HierarchicalExample():\n",
    "    \"\"\"Shows the posterior distribution of n for lions, tigers and bears.\n",
    "    \"\"\"\n",
    "    ns = range(3, 30)\n",
    "    suite = Species(ns, iters=8000)\n",
    "\n",
    "    data = [3, 2, 1]\n",
    "    suite.Update(data)\n",
    "\n",
    "    thinkplot.Clf()\n",
    "    thinkplot.PrePlot(num=1)\n",
    "\n",
    "    pmf = suite.DistN()\n",
    "    thinkplot.Pmf(pmf)\n",
    "    thinkplot.Save(root='species2',\n",
    "                xlabel='Number of species',\n",
    "                ylabel='Prob',\n",
    "                formats=FORMATS,\n",
    "                )\n",
    "\n",
    "\n",
    "def CompareHierarchicalExample():\n",
    "    \"\"\"Makes a graph of posterior distributions of N.\"\"\"\n",
    "    data = [3, 2, 1]\n",
    "    m = len(data)\n",
    "    n = 30\n",
    "    ns = range(m, n)\n",
    "\n",
    "    constructors = [Species, Species5]\n",
    "    iters = [1000, 100]\n",
    "\n",
    "    for constructor, iters in zip(constructors, iters):\n",
    "        suite = MakePosterior(constructor, data, ns, iters)\n",
    "        pmf = suite.DistN()\n",
    "        pmf.name = '%s' % (constructor.__name__)\n",
    "        thinkplot.Pmf(pmf)\n",
    "\n",
    "    thinkplot.Show()\n",
    "\n",
    "\n",
    "def ProcessSubjects(codes):\n",
    "    \"\"\"Process subjects with the given codes and plot their posteriors.\n",
    "\n",
    "    code: sequence of string codes\n",
    "    \"\"\"\n",
    "    thinkplot.Clf()\n",
    "    thinkplot.PrePlot(len(codes))\n",
    "\n",
    "    subjects = ReadRarefactedData()\n",
    "    pmfs = []\n",
    "    for code in codes:\n",
    "        subject = subjects[code]\n",
    "\n",
    "        subject.Process()\n",
    "        pmf = subject.suite.DistN()\n",
    "        pmf.name = subject.code\n",
    "        thinkplot.Pmf(pmf)\n",
    "\n",
    "        pmfs.append(pmf)\n",
    "\n",
    "    print 'ProbGreater', thinkbayes.PmfProbGreater(pmfs[0], pmfs[1])\n",
    "    print 'ProbLess', thinkbayes.PmfProbLess(pmfs[0], pmfs[1])\n",
    "\n",
    "    thinkplot.Save(root='species4',\n",
    "                xlabel='Number of species',\n",
    "                ylabel='Prob',\n",
    "                formats=FORMATS,\n",
    "                )\n",
    "\n",
    "\n",
    "def RunSubject(code, conc=1, high=500):\n",
    "    \"\"\"Run the analysis for the subject with the given code.\n",
    "\n",
    "    code: string code\n",
    "    \"\"\"\n",
    "    subjects = JoinSubjects()\n",
    "    subject = subjects[code]\n",
    "\n",
    "    subject.Process(conc=conc, high=high, iters=300)\n",
    "    subject.MakeQuickPrediction()\n",
    "\n",
    "    PrintSummary(subject)\n",
    "    actual_l = subject.total_species - subject.num_species\n",
    "    cdf_l = subject.DistL().MakeCdf()\n",
    "    PrintPrediction(cdf_l, actual_l)\n",
    "\n",
    "    subject.MakeFigures()\n",
    "\n",
    "    num_reads = 400\n",
    "    curves = subject.RunSimulations(100, num_reads)\n",
    "    root = 'species-rare-%s' % subject.code\n",
    "    PlotCurves(curves, root=root)\n",
    "\n",
    "    num_reads = 800\n",
    "    curves = subject.RunSimulations(500, num_reads)\n",
    "    ks = [100, 200, 400, 800]\n",
    "    cdfs = MakeConditionals(curves, ks)\n",
    "    root = 'species-cond-%s' % subject.code\n",
    "    PlotConditionals(cdfs, root=root)\n",
    "\n",
    "    num_reads = 1000\n",
    "    curves = subject.RunSimulations(500, num_reads, frac_flag=True)\n",
    "    ks = [10, 100, 200, 400, 600, 800, 1000]\n",
    "    cdfs = MakeFracCdfs(curves, ks)\n",
    "    root = 'species-frac-%s' % subject.code\n",
    "    PlotFracCdfs(cdfs, root=root)\n",
    "\n",
    "\n",
    "def PrintSummary(subject):\n",
    "    \"\"\"Print a summary of a subject.\n",
    "\n",
    "    subject: Subject\n",
    "    \"\"\"\n",
    "    print subject.code\n",
    "    print 'found %d species in %d reads' % (subject.num_species,\n",
    "                                            subject.num_reads)\n",
    "\n",
    "    print 'total %d species in %d reads' % (subject.total_species,\n",
    "                                            subject.total_reads)\n",
    "\n",
    "    cdf = subject.suite.DistN().MakeCdf()\n",
    "    print 'n'\n",
    "    PrintPrediction(cdf, 'unknown')\n",
    "    \n",
    "\n",
    "def PrintPrediction(cdf, actual):\n",
    "    \"\"\"Print a summary of a prediction.\n",
    "\n",
    "    cdf: predictive distribution\n",
    "    actual: actual value\n",
    "    \"\"\"\n",
    "    median = cdf.Percentile(50)\n",
    "    low, high = cdf.CredibleInterval(75)\n",
    "    \n",
    "    print 'predicted %0.2f (%0.2f %0.2f)' % (median, low, high)\n",
    "    print 'actual', actual\n",
    "\n",
    "\n",
    "def RandomSeed(x):\n",
    "    \"\"\"Initialize random.random and numpy.random.\n",
    "\n",
    "    x: int seed\n",
    "    \"\"\"\n",
    "    random.seed(x)\n",
    "    numpy.random.seed(x)\n",
    "\n",
    "\n",
    "def GenerateFakeSample(n, r, tr, conc=1):\n",
    "    \"\"\"Generates fake data with the given parameters.\n",
    "\n",
    "    n: number of species\n",
    "    r: number of reads in subsample\n",
    "    tr: total number of reads\n",
    "    conc: concentration parameter\n",
    "\n",
    "    Returns: hist of all reads, hist of subsample, prev_unseen\n",
    "    \"\"\"\n",
    "    # generate random prevalences\n",
    "    dirichlet = thinkbayes.Dirichlet(n, conc=conc)\n",
    "    prevalences = dirichlet.Random()\n",
    "    prevalences.sort()\n",
    "\n",
    "    # generate a simulated sample\n",
    "    pmf = thinkbayes.MakePmfFromItems(enumerate(prevalences))\n",
    "    cdf = pmf.MakeCdf()\n",
    "    sample = cdf.Sample(tr)\n",
    "\n",
    "    # collect the species counts\n",
    "    hist = thinkbayes.MakeHistFromList(sample)\n",
    "\n",
    "    # extract a subset of the data\n",
    "    if tr > r:\n",
    "        random.shuffle(sample)\n",
    "        subsample = sample[:r]\n",
    "        subhist = thinkbayes.MakeHistFromList(subsample)\n",
    "    else:\n",
    "        subhist = hist\n",
    "\n",
    "    # add up the prevalence of unseen species\n",
    "    prev_unseen = 0\n",
    "    for species, prev in enumerate(prevalences):\n",
    "        if species not in subhist:\n",
    "            prev_unseen += prev\n",
    "\n",
    "    return hist, subhist, prev_unseen\n",
    "\n",
    "\n",
    "def PlotActualPrevalences():\n",
    "    \"\"\"Makes a plot comparing actual prevalences with a model.\n",
    "    \"\"\"\n",
    "    # read data\n",
    "    subject_map, _ = ReadCompleteDataset()\n",
    "\n",
    "    # for subjects with more than 50 species,\n",
    "    # PMF of max prevalence, and PMF of max prevalence\n",
    "    # generated by a simulation\n",
    "    pmf_actual = thinkbayes.Pmf()\n",
    "    pmf_sim = thinkbayes.Pmf()\n",
    "\n",
    "    # concentration parameter used in the simulation\n",
    "    conc = 0.06\n",
    "\n",
    "    for code, subject in subject_map.iteritems():\n",
    "        prevalences = subject.GetPrevalences()\n",
    "        m = len(prevalences)\n",
    "        if m < 2:\n",
    "            continue\n",
    "\n",
    "        actual_max = max(prevalences)\n",
    "        print code, m, actual_max\n",
    "\n",
    "        # incr the PMFs\n",
    "        if m > 50:\n",
    "            pmf_actual.Incr(actual_max)\n",
    "            pmf_sim.Incr(SimulateMaxPrev(m, conc))\n",
    "\n",
    "    # plot CDFs for the actual and simulated max prevalence\n",
    "    cdf_actual = pmf_actual.MakeCdf(name='actual')\n",
    "    cdf_sim = pmf_sim.MakeCdf(name='sim')\n",
    "\n",
    "    thinkplot.Cdfs([cdf_actual, cdf_sim])\n",
    "    thinkplot.Show()\n",
    "\n",
    "\n",
    "def ScatterPrevalences(ms, actual):\n",
    "    \"\"\"Make a scatter plot of actual prevalences and expected values.\n",
    "\n",
    "    ms: sorted sequence of in m (number of species)\n",
    "    actual: sequence of actual max prevalence\n",
    "    \"\"\"\n",
    "    for conc in [1, 0.5, 0.2, 0.1]:\n",
    "        expected = [ExpectedMaxPrev(m, conc) for m in ms]\n",
    "        thinkplot.Plot(ms, expected)\n",
    "\n",
    "    thinkplot.Scatter(ms, actual)\n",
    "    thinkplot.Show(xscale='log')\n",
    "\n",
    "\n",
    "def SimulateMaxPrev(m, conc=1):\n",
    "    \"\"\"Returns random max prevalence from a Dirichlet distribution.\n",
    "\n",
    "    m: int number of species\n",
    "    conc: concentration parameter of the Dirichlet distribution\n",
    "\n",
    "    Returns: float max of m prevalences\n",
    "    \"\"\"\n",
    "    dirichlet = thinkbayes.Dirichlet(m, conc)\n",
    "    prevalences = dirichlet.Random()\n",
    "    return max(prevalences)\n",
    "        \n",
    "\n",
    "def ExpectedMaxPrev(m, conc=1, iters=100):\n",
    "    \"\"\"Estimate expected max prevalence.\n",
    "\n",
    "    m: number of species\n",
    "    conc: concentration parameter\n",
    "    iters: how many iterations to run\n",
    "\n",
    "    Returns: expected max prevalence\n",
    "    \"\"\"\n",
    "    dirichlet = thinkbayes.Dirichlet(m, conc)\n",
    "\n",
    "    t = []\n",
    "    for _ in range(iters):\n",
    "        prevalences = dirichlet.Random()\n",
    "        t.append(max(prevalences))\n",
    "\n",
    "    return numpy.mean(t)\n",
    "\n",
    "\n",
    "class Calibrator(object):\n",
    "    \"\"\"Encapsulates the calibration process.\"\"\"\n",
    "\n",
    "    def __init__(self, conc=0.1):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.conc = conc\n",
    "\n",
    "        self.ps =  range(10, 100, 10)\n",
    "        self.total_n = numpy.zeros(len(self.ps))\n",
    "        self.total_q = numpy.zeros(len(self.ps))\n",
    "        self.total_l = numpy.zeros(len(self.ps))\n",
    "\n",
    "        self.n_seq = []\n",
    "        self.q_seq = []\n",
    "        self.l_seq = []\n",
    "\n",
    "    def Calibrate(self, num_runs=100, n_low=30, n_high=400, r=400, tr=1200):\n",
    "        \"\"\"Runs calibrations.\n",
    "\n",
    "        num_runs: how many runs\n",
    "        \"\"\"\n",
    "        for seed in range(num_runs):\n",
    "            self.RunCalibration(seed, n_low, n_high, r, tr)\n",
    "\n",
    "        self.total_n *= 100.0 / num_runs\n",
    "        self.total_q *= 100.0 / num_runs\n",
    "        self.total_l *= 100.0 / num_runs\n",
    "\n",
    "    def Validate(self, num_runs=100, clean_param=0):\n",
    "        \"\"\"Runs validations.\n",
    "\n",
    "        num_runs: how many runs\n",
    "        \"\"\"\n",
    "        subject_map, _ = ReadCompleteDataset(clean_param=clean_param)\n",
    "\n",
    "        i = 0\n",
    "        for match in subject_map.itervalues():\n",
    "            if match.num_reads < 400:\n",
    "                continue\n",
    "            num_reads = 100\n",
    "\n",
    "            print 'Validate', match.code\n",
    "            subject = match.Resample(num_reads)\n",
    "            subject.Match(match)\n",
    "\n",
    "            n_actual = None\n",
    "            q_actual = subject.prev_unseen\n",
    "            l_actual = subject.total_species - subject.num_species\n",
    "            self.RunSubject(subject, n_actual, q_actual, l_actual)\n",
    "            \n",
    "            i += 1\n",
    "            if i == num_runs:\n",
    "                break\n",
    "\n",
    "        self.total_n *= 100.0 / num_runs\n",
    "        self.total_q *= 100.0 / num_runs\n",
    "        self.total_l *= 100.0 / num_runs\n",
    "\n",
    "    def PlotN(self, root='species-n'):\n",
    "        \"\"\"Makes a scatter plot of simulated vs actual prev_unseen (q).\n",
    "        \"\"\"\n",
    "        xs, ys = zip(*self.n_seq)\n",
    "        if None in xs:\n",
    "            return\n",
    "\n",
    "        high = max(xs+ys)\n",
    "\n",
    "        thinkplot.Plot([0, high], [0, high], color='gray')\n",
    "        thinkplot.Scatter(xs, ys)\n",
    "        thinkplot.Save(root=root,\n",
    "                       xlabel='Actual n',\n",
    "                       ylabel='Predicted')\n",
    "\n",
    "    def PlotQ(self, root='species-q'):\n",
    "        \"\"\"Makes a scatter plot of simulated vs actual prev_unseen (q).\n",
    "        \"\"\"\n",
    "        thinkplot.Plot([0, 0.2], [0, 0.2], color='gray')\n",
    "        xs, ys = zip(*self.q_seq)\n",
    "        thinkplot.Scatter(xs, ys)\n",
    "        thinkplot.Save(root=root,\n",
    "                       xlabel='Actual q',\n",
    "                       ylabel='Predicted')\n",
    "\n",
    "    def PlotL(self, root='species-n'):\n",
    "        \"\"\"Makes a scatter plot of simulated vs actual l.\n",
    "        \"\"\"\n",
    "        thinkplot.Plot([0, 20], [0, 20], color='gray')\n",
    "        xs, ys = zip(*self.l_seq)\n",
    "        thinkplot.Scatter(xs, ys)\n",
    "        thinkplot.Save(root=root,\n",
    "                       xlabel='Actual l',\n",
    "                       ylabel='Predicted')\n",
    "\n",
    "    def PlotCalibrationCurves(self, root='species5'):\n",
    "        \"\"\"Plots calibration curves\"\"\"\n",
    "        print self.total_n\n",
    "        print self.total_q\n",
    "        print self.total_l\n",
    "\n",
    "        thinkplot.Plot([0, 100], [0, 100], color='gray', alpha=0.2)\n",
    "\n",
    "        if self.total_n[0] >= 0:\n",
    "            thinkplot.Plot(self.ps, self.total_n, label='n')\n",
    "\n",
    "        thinkplot.Plot(self.ps, self.total_q, label='q')\n",
    "        thinkplot.Plot(self.ps, self.total_l, label='l')\n",
    "\n",
    "        thinkplot.Save(root=root,\n",
    "                       axis=[0, 100, 0, 100],\n",
    "                       xlabel='Ideal percentages',\n",
    "                       ylabel='Predictive distributions',\n",
    "                       formats=FORMATS,\n",
    "                       )\n",
    "\n",
    "    def RunCalibration(self, seed, n_low, n_high, r, tr):\n",
    "        \"\"\"Runs a single calibration run.\n",
    "\n",
    "        Generates N and prevalences from a Dirichlet distribution,\n",
    "        then generates simulated data.\n",
    "\n",
    "        Runs analysis to get the posterior distributions.\n",
    "        Generates calibration curves for each posterior distribution.\n",
    "\n",
    "        seed: int random seed\n",
    "        \"\"\"\n",
    "        # generate a random number of species and their prevalences\n",
    "        # (from a Dirichlet distribution with alpha_i = conc for all i)\n",
    "        RandomSeed(seed)\n",
    "        n_actual = random.randrange(n_low, n_high+1)\n",
    "\n",
    "        hist, subhist, q_actual = GenerateFakeSample(\n",
    "            n_actual, \n",
    "            r, \n",
    "            tr, \n",
    "            self.conc)\n",
    "\n",
    "        l_actual = len(hist) - len(subhist)\n",
    "        print 'Run low, high, conc', n_low, n_high, self.conc\n",
    "        print 'Run r, tr', r, tr\n",
    "        print 'Run n, q, l', n_actual, q_actual, l_actual\n",
    "\n",
    "        # extract the data\n",
    "        data = [count for species, count in subhist.Items()]\n",
    "        data.sort()\n",
    "        print 'data', data\n",
    "\n",
    "        # make a Subject and process\n",
    "        subject = Subject('simulated')\n",
    "        subject.num_reads = r\n",
    "        subject.total_reads = tr\n",
    "\n",
    "        for species, count in subhist.Items():\n",
    "            subject.Add(species, count)\n",
    "        subject.Done()\n",
    "\n",
    "        self.RunSubject(subject, n_actual, q_actual, l_actual)\n",
    "\n",
    "    def RunSubject(self, subject, n_actual, q_actual, l_actual):\n",
    "        \"\"\"Runs the analysis for a subject.\n",
    "\n",
    "        subject: Subject\n",
    "        n_actual: number of species\n",
    "        q_actual: prevalence of unseen species\n",
    "        l_actual: number of new species\n",
    "        \"\"\"\n",
    "        # process and make prediction\n",
    "        subject.Process(conc=self.conc, iters=100)\n",
    "        subject.MakeQuickPrediction()\n",
    "\n",
    "        # extract the posterior suite\n",
    "        suite = subject.suite\n",
    "\n",
    "        # check the distribution of n\n",
    "        pmf_n = suite.DistN() \n",
    "        print 'n'\n",
    "        self.total_n += self.CheckDistribution(pmf_n, n_actual, self.n_seq)\n",
    "\n",
    "        # check the distribution of q\n",
    "        pmf_q = suite.DistQ()\n",
    "        print 'q'\n",
    "        self.total_q += self.CheckDistribution(pmf_q, q_actual, self.q_seq)\n",
    "\n",
    "        # check the distribution of additional species\n",
    "        pmf_l = subject.DistL()\n",
    "        print 'l'\n",
    "        self.total_l += self.CheckDistribution(pmf_l, l_actual, self.l_seq)\n",
    "\n",
    "    def CheckDistribution(self, pmf, actual, seq):\n",
    "        \"\"\"Checks a predictive distribution and returns a score vector.\n",
    "\n",
    "        pmf: predictive distribution\n",
    "        actual: actual value\n",
    "        seq: which sequence to append (actual, mean) onto\n",
    "        \"\"\"\n",
    "        mean = pmf.Mean()\n",
    "        seq.append((actual, mean))\n",
    "\n",
    "        cdf = pmf.MakeCdf()\n",
    "        PrintPrediction(cdf, actual)\n",
    "\n",
    "        sv = ScoreVector(cdf, self.ps, actual)\n",
    "        return sv\n",
    "\n",
    "\n",
    "def ScoreVector(cdf, ps, actual):\n",
    "    \"\"\"Checks whether the actual value falls in each credible interval.\n",
    "    \n",
    "    cdf: predictive distribution\n",
    "    ps: percentages to check (0-100)\n",
    "    actual: actual value\n",
    "\n",
    "    Returns: numpy array of 0, 0.5, or 1\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for p in ps:\n",
    "        low, high = cdf.CredibleInterval(p)\n",
    "        score = Score(low, high, actual)\n",
    "        scores.append(score)\n",
    "\n",
    "    return numpy.array(scores)\n",
    "\n",
    "\n",
    "def Score(low, high, n):\n",
    "    \"\"\"Score whether the actual value falls in the range.\n",
    "\n",
    "    Hitting the posts counts as 0.5, -1 is invalid.\n",
    "\n",
    "    low: low end of range\n",
    "    high: high end of range\n",
    "    n: actual value\n",
    "\n",
    "    Returns: -1, 0, 0.5 or 1\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        return -1\n",
    "    if low < n < high:\n",
    "        return 1\n",
    "    if n == low or n == high:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def FakeSubject(n=300, conc=0.1, num_reads=400, prevalences=None):\n",
    "    \"\"\"Makes a fake Subject.\n",
    "    \n",
    "    If prevalences is provided, n and conc are ignored.\n",
    "\n",
    "    n: number of species\n",
    "    conc: concentration parameter\n",
    "    num_reads: number of reads\n",
    "    prevalences: numpy array of prevalences (overrides n and conc)\n",
    "    \"\"\"\n",
    "    # generate random prevalences\n",
    "    if prevalences is None:\n",
    "        dirichlet = thinkbayes.Dirichlet(n, conc=conc)\n",
    "        prevalences = dirichlet.Random()\n",
    "        prevalences.sort()\n",
    "\n",
    "    # generate a simulated sample\n",
    "    pmf = thinkbayes.MakePmfFromItems(enumerate(prevalences))\n",
    "    cdf = pmf.MakeCdf()\n",
    "    sample = cdf.Sample(num_reads)\n",
    "\n",
    "    # collect the species counts\n",
    "    hist = thinkbayes.MakeHistFromList(sample)\n",
    "\n",
    "    # extract the data\n",
    "    data = [count for species, count in hist.Items()]\n",
    "    data.sort()\n",
    "\n",
    "    # make a Subject and process\n",
    "    subject = Subject('simulated')\n",
    "\n",
    "    for species, count in hist.Items():\n",
    "        subject.Add(species, count)\n",
    "    subject.Done()\n",
    "\n",
    "    return subject\n",
    "\n",
    "\n",
    "def PlotSubjectCdf(code=None, clean_param=0):\n",
    "    \"\"\"Checks whether the Dirichlet model can replicate the data.\n",
    "    \"\"\"\n",
    "    subject_map, uber_subject = ReadCompleteDataset(clean_param=clean_param)\n",
    "\n",
    "    if code is None:\n",
    "        subjects = subject_map.values()\n",
    "        subject = random.choice(subjects)\n",
    "        code = subject.code\n",
    "    elif code == 'uber':\n",
    "        subject = uber_subject\n",
    "    else:\n",
    "        subject = subject_map[code]\n",
    "\n",
    "    print subject.code\n",
    "\n",
    "    m = subject.GetM()\n",
    "\n",
    "    subject.Process(high=m, conc=0.1, iters=0)\n",
    "    print subject.suite.params[:m]\n",
    "\n",
    "    # plot the cdf\n",
    "    options = dict(linewidth=3, color='blue', alpha=0.5)\n",
    "    cdf = subject.MakeCdf()\n",
    "    thinkplot.Cdf(cdf, **options)\n",
    "\n",
    "    options = dict(linewidth=1, color='green', alpha=0.5)\n",
    "\n",
    "    # generate fake subjects and plot their CDFs\n",
    "    for _ in range(10):\n",
    "        prevalences = subject.suite.SamplePrevalences(m)\n",
    "        fake = FakeSubject(prevalences=prevalences)\n",
    "        cdf = fake.MakeCdf()\n",
    "        thinkplot.Cdf(cdf, **options)\n",
    "\n",
    "    root = 'species-cdf-%s' % code\n",
    "    thinkplot.Save(root=root,\n",
    "                   xlabel='rank',\n",
    "                   ylabel='CDF',\n",
    "                   xscale='log',\n",
    "                   formats=FORMATS,\n",
    "                   )\n",
    "\n",
    "\n",
    "def RunCalibration(flag='cal', num_runs=100, clean_param=50):\n",
    "    \"\"\"Runs either the calibration or validation process.\n",
    "\n",
    "    flag: string 'cal' or 'val'\n",
    "    num_runs: how many runs\n",
    "    clean_param: parameter used for data cleaning\n",
    "    \"\"\"\n",
    "    cal = Calibrator(conc=0.1)\n",
    "\n",
    "    if flag == 'val':\n",
    "        cal.Validate(num_runs=num_runs, clean_param=clean_param)\n",
    "    else:\n",
    "        cal.Calibrate(num_runs=num_runs)\n",
    "\n",
    "    cal.PlotN(root='species-n-%s' % flag)\n",
    "    cal.PlotQ(root='species-q-%s' % flag)\n",
    "    cal.PlotL(root='species-l-%s' % flag)\n",
    "    cal.PlotCalibrationCurves(root='species5-%s' % flag)\n",
    "\n",
    "\n",
    "def RunTests():\n",
    "    \"\"\"Runs calibration code and generates some figures.\"\"\"\n",
    "    RunCalibration(flag='val')\n",
    "    RunCalibration(flag='cal')\n",
    "\n",
    "    PlotSubjectCdf('B1558.G', clean_param=50)\n",
    "    PlotSubjectCdf(None)\n",
    "\n",
    "\n",
    "def main(script):\n",
    "    RandomSeed(17)\n",
    "    RunSubject('B1242', conc=1, high=100)\n",
    "\n",
    "    RandomSeed(17)\n",
    "    SimpleDirichletExample()\n",
    "\n",
    "    RandomSeed(17)\n",
    "    HierarchicalExample()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(*sys.argv)\n",
    "\"\"\"This file contains code used in \"Think Bayes\",\n",
    "by Allen B. Downey, available from greenteapress.com\n",
    "\n",
    "Copyright 2012 Allen B. Downey\n",
    "License: GNU GPLv3 http://www.gnu.org/licenses/gpl.html\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as pyplot\n",
    "import thinkplot\n",
    "import numpy\n",
    "\n",
    "import csv\n",
    "import random\n",
    "import shelve\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import thinkbayes\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter('error', RuntimeWarning)\n",
    "\n",
    "\n",
    "FORMATS = ['pdf', 'eps', 'png']\n",
    "\n",
    "\n",
    "class Locker(object):\n",
    "    \"\"\"Encapsulates a shelf for storing key-value pairs.\"\"\"\n",
    "\n",
    "    def __init__(self, shelf_file):\n",
    "        self.shelf = shelve.open(shelf_file)\n",
    "\n",
    "    def Close(self):\n",
    "        \"\"\"Closes the shelf.\n",
    "        \"\"\"\n",
    "        self.shelf.close()\n",
    "\n",
    "    def Add(self, key, value):\n",
    "        \"\"\"Adds a key-value pair.\"\"\"\n",
    "        self.shelf[str(key)] = value\n",
    "\n",
    "    def Lookup(self, key):\n",
    "        \"\"\"Looks up a key.\"\"\"\n",
    "        return self.shelf.get(str(key))\n",
    "\n",
    "    def Keys(self):\n",
    "        \"\"\"Returns an iterator of keys.\"\"\"\n",
    "        return self.shelf.iterkeys()\n",
    "\n",
    "    def Read(self):\n",
    "        \"\"\"Returns the contents of the shelf as a map.\"\"\"\n",
    "        return dict(self.shelf)\n",
    "\n",
    "\n",
    "class Subject(object):\n",
    "    \"\"\"Represents a subject from the belly button study.\"\"\"\n",
    "\n",
    "    def __init__(self, code):\n",
    "        \"\"\"\n",
    "        code: string ID\n",
    "        species: sequence of (int count, string species) pairs\n",
    "        \"\"\"\n",
    "        self.code = code\n",
    "        self.species = []\n",
    "        self.suite = None\n",
    "        self.num_reads = None\n",
    "        self.num_species = None\n",
    "        self.total_reads = None\n",
    "        self.total_species = None\n",
    "        self.prev_unseen = None\n",
    "        self.pmf_n = None\n",
    "        self.pmf_q = None\n",
    "        self.pmf_l = None\n",
    "\n",
    "    def Add(self, species, count):\n",
    "        \"\"\"Add a species-count pair.\n",
    "\n",
    "        It is up to the caller to ensure that species names are unique.\n",
    "\n",
    "        species: string species/genus name\n",
    "        count: int number of individuals\n",
    "        \"\"\"\n",
    "        self.species.append((count, species))\n",
    "\n",
    "    def Done(self, reverse=False, clean_param=0):\n",
    "        \"\"\"Called when we are done adding species counts.\n",
    "\n",
    "        reverse: which order to sort in\n",
    "        \"\"\"\n",
    "        if clean_param:\n",
    "            self.Clean(clean_param)\n",
    "\n",
    "        self.species.sort(reverse=reverse)        \n",
    "        counts = self.GetCounts()\n",
    "        self.num_species = len(counts)\n",
    "        self.num_reads = sum(counts)\n",
    "\n",
    "    def Clean(self, clean_param=50):\n",
    "        \"\"\"Identifies and removes bogus data.\n",
    "\n",
    "        clean_param: parameter that controls the number of legit species\n",
    "        \"\"\"\n",
    "        def prob_bogus(k, r):\n",
    "            \"\"\"Compute the probability that a species is bogus.\"\"\"\n",
    "            q = clean_param / r\n",
    "            p = (1-q) ** k\n",
    "            return p\n",
    "\n",
    "        print self.code, clean_param\n",
    "\n",
    "        counts = self.GetCounts()\n",
    "        r = 1.0 * sum(counts)\n",
    "\n",
    "        species_seq = []\n",
    "        for k, species in sorted(self.species):\n",
    "\n",
    "            if random.random() < prob_bogus(k, r):\n",
    "                continue\n",
    "            species_seq.append((k, species))\n",
    "        self.species = species_seq\n",
    "\n",
    "    def GetM(self):\n",
    "        \"\"\"Gets number of observed species.\"\"\"\n",
    "        return len(self.species)\n",
    "        \n",
    "    def GetCounts(self):\n",
    "        \"\"\"Gets the list of species counts\n",
    "\n",
    "        Should be in increasing order, if Sort() has been invoked.\n",
    "        \"\"\"\n",
    "        return [count for count, _ in self.species]\n",
    "\n",
    "    def MakeCdf(self):\n",
    "        \"\"\"Makes a CDF of total prevalence vs rank.\"\"\"\n",
    "        counts = self.GetCounts()\n",
    "        counts.sort(reverse=True)\n",
    "        cdf = thinkbayes.MakeCdfFromItems(enumerate(counts))\n",
    "        return cdf\n",
    "\n",
    "    def GetNames(self):\n",
    "        \"\"\"Gets the names of the seen species.\"\"\"\n",
    "        return [name for _, name in self.species]\n",
    "\n",
    "    def PrintCounts(self):\n",
    "        \"\"\"Prints the counts and species names.\"\"\"\n",
    "        for count, name in reversed(self.species):\n",
    "            print count, name\n",
    "\n",
    "    def GetSpecies(self, index):\n",
    "        \"\"\"Gets the count and name of the indicated species.\n",
    "\n",
    "        Returns: count-species pair\n",
    "        \"\"\"\n",
    "        return self.species[index]\n",
    "\n",
    "    def GetCdf(self):\n",
    "        \"\"\"Returns cumulative prevalence vs number of species.\n",
    "        \"\"\"\n",
    "        counts = self.GetCounts()\n",
    "        items = enumerate(counts)\n",
    "        cdf = thinkbayes.MakeCdfFromItems(items)\n",
    "        return cdf\n",
    "\n",
    "    def GetPrevalences(self):\n",
    "        \"\"\"Returns a sequence of prevalences (normalized counts).\n",
    "        \"\"\"\n",
    "        counts = self.GetCounts()\n",
    "        total = sum(counts)\n",
    "        prevalences = numpy.array(counts, dtype=numpy.float) / total\n",
    "        return prevalences\n",
    "\n",
    "    def Process(self, low=None, high=500, conc=1, iters=100):\n",
    "        \"\"\"Computes the posterior distribution of n and the prevalences.\n",
    "\n",
    "        Sets attribute: self.suite\n",
    "\n",
    "        low: minimum number of species\n",
    "        high: maximum number of species\n",
    "        conc: concentration parameter\n",
    "        iters: number of iterations to use in the estimator\n",
    "        \"\"\"\n",
    "        counts = self.GetCounts()\n",
    "        m = len(counts)\n",
    "        if low is None:\n",
    "            low = max(m, 2)\n",
    "        ns = range(low, high+1)\n",
    "\n",
    "        #start = time.time()    \n",
    "        self.suite = Species5(ns, conc=conc, iters=iters)\n",
    "        self.suite.Update(counts)\n",
    "        #end = time.time()\n",
    "\n",
    "        #print 'Processing time' end-start\n",
    "\n",
    "    def MakePrediction(self, num_sims=100):\n",
    "        \"\"\"Make predictions for the given subject.\n",
    "\n",
    "        Precondition: Process has run\n",
    "\n",
    "        num_sims: how many simulations to run for predictions\n",
    "\n",
    "        Adds attributes\n",
    "        pmf_l: predictive distribution of additional species\n",
    "        \"\"\"\n",
    "        add_reads = self.total_reads - self.num_reads\n",
    "        curves = self.RunSimulations(num_sims, add_reads)\n",
    "        self.pmf_l = self.MakePredictive(curves)\n",
    "\n",
    "    def MakeQuickPrediction(self, num_sims=100):\n",
    "        \"\"\"Make predictions for the given subject.\n",
    "\n",
    "        Precondition: Process has run\n",
    "\n",
    "        num_sims: how many simulations to run for predictions\n",
    "\n",
    "        Adds attribute:\n",
    "        pmf_l: predictive distribution of additional species\n",
    "        \"\"\"\n",
    "        add_reads = self.total_reads - self.num_reads\n",
    "        pmf = thinkbayes.Pmf()\n",
    "        _, seen = self.GetSeenSpecies()\n",
    "\n",
    "        for _ in range(num_sims):\n",
    "            _, observations = self.GenerateObservations(add_reads)\n",
    "            all_seen = seen.union(observations)\n",
    "            l = len(all_seen) - len(seen)\n",
    "            pmf.Incr(l)\n",
    "\n",
    "        pmf.Normalize()\n",
    "        self.pmf_l = pmf\n",
    "\n",
    "    def DistL(self):\n",
    "        \"\"\"Returns the distribution of additional species, l.\n",
    "        \"\"\"\n",
    "        return self.pmf_l\n",
    "\n",
    "    def MakeFigures(self):\n",
    "        \"\"\"Makes figures showing distribution of n and the prevalences.\"\"\"\n",
    "        self.PlotDistN()\n",
    "        self.PlotPrevalences()\n",
    "\n",
    "    def PlotDistN(self):\n",
    "        \"\"\"Plots distribution of n.\"\"\"\n",
    "        pmf = self.suite.DistN()\n",
    "        print '90% CI for N:', pmf.CredibleInterval(90)\n",
    "        pmf.name = self.code\n",
    "\n",
    "        thinkplot.Clf()\n",
    "        thinkplot.PrePlot(num=1)\n",
    "\n",
    "        thinkplot.Pmf(pmf)\n",
    "\n",
    "        root = 'species-ndist-%s' % self.code\n",
    "        thinkplot.Save(root=root,\n",
    "                    xlabel='Number of species',\n",
    "                    ylabel='Prob',\n",
    "                    formats=FORMATS,\n",
    "                    )\n",
    "\n",
    "    def PlotPrevalences(self, num=5):\n",
    "        \"\"\"Plots dist of prevalence for several species.\n",
    "\n",
    "        num: how many species (starting with the highest prevalence)\n",
    "        \"\"\"\n",
    "        thinkplot.Clf()\n",
    "        thinkplot.PrePlot(num=5)\n",
    "\n",
    "        for rank in range(1, num+1):\n",
    "            self.PlotPrevalence(rank)\n",
    "\n",
    "        root = 'species-prev-%s' % self.code\n",
    "        thinkplot.Save(root=root,\n",
    "                    xlabel='Prevalence',\n",
    "                    ylabel='Prob',\n",
    "                    formats=FORMATS,\n",
    "                    axis=[0, 0.3, 0, 1],\n",
    "                    )\n",
    "\n",
    "    def PlotPrevalence(self, rank=1, cdf_flag=True):\n",
    "        \"\"\"Plots dist of prevalence for one species.\n",
    "\n",
    "        rank: rank order of the species to plot.\n",
    "        cdf_flag: whether to plot the CDF\n",
    "        \"\"\"\n",
    "        # convert rank to index\n",
    "        index = self.GetM() - rank\n",
    "\n",
    "        _, mix = self.suite.DistOfPrevalence(index)\n",
    "        count, _ = self.GetSpecies(index)\n",
    "        mix.name = '%d (%d)' % (rank, count)\n",
    "\n",
    "        print '90%% CI for prevalence of species %d:' % rank, \n",
    "        print mix.CredibleInterval(90)\n",
    "\n",
    "        if cdf_flag:\n",
    "            cdf = mix.MakeCdf()\n",
    "            thinkplot.Cdf(cdf)\n",
    "        else:\n",
    "            thinkplot.Pmf(mix)\n",
    "\n",
    "    def PlotMixture(self, rank=1):\n",
    "        \"\"\"Plots dist of prevalence for all n, and the mix.\n",
    "\n",
    "        rank: rank order of the species to plot\n",
    "        \"\"\"\n",
    "        # convert rank to index\n",
    "        index = self.GetM() - rank\n",
    "\n",
    "        print self.GetSpecies(index)\n",
    "        print self.GetCounts()[index]\n",
    "\n",
    "        metapmf, mix = self.suite.DistOfPrevalence(index)\n",
    "\n",
    "        thinkplot.Clf()\n",
    "        for pmf in metapmf.Values():\n",
    "            thinkplot.Pmf(pmf, color='blue', alpha=0.2, linewidth=0.5)\n",
    "\n",
    "        thinkplot.Pmf(mix, color='blue', alpha=0.9, linewidth=2)\n",
    "\n",
    "        root = 'species-mix-%s' % self.code\n",
    "        thinkplot.Save(root=root,\n",
    "                    xlabel='Prevalence',\n",
    "                    ylabel='Prob',\n",
    "                    formats=FORMATS,\n",
    "                    axis=[0, 0.3, 0, 0.3],\n",
    "                    legend=False)\n",
    "\n",
    "    def GetSeenSpecies(self):\n",
    "        \"\"\"Makes a set of the names of seen species.\n",
    "\n",
    "        Returns: number of species, set of string species names\n",
    "        \"\"\"\n",
    "        names = self.GetNames()\n",
    "        m = len(names)\n",
    "        seen = set(SpeciesGenerator(names, m))\n",
    "        return m, seen\n",
    "\n",
    "    def GenerateObservations(self, num_reads):\n",
    "        \"\"\"Generates a series of random observations.\n",
    "\n",
    "        num_reads: number of reads to generate\n",
    "\n",
    "        Returns: number of species, sequence of string species names\n",
    "        \"\"\"\n",
    "        n, prevalences = self.suite.SamplePosterior()\n",
    "\n",
    "        names = self.GetNames()\n",
    "        name_iter = SpeciesGenerator(names, n)\n",
    "\n",
    "        items = zip(name_iter, prevalences)\n",
    "\n",
    "        cdf = thinkbayes.MakeCdfFromItems(items)\n",
    "        observations = cdf.Sample(num_reads)\n",
    "\n",
    "        #for ob in observations:\n",
    "        #    print ob\n",
    "\n",
    "        return n, observations\n",
    "\n",
    "    def Resample(self, num_reads):\n",
    "        \"\"\"Choose a random subset of the data (without replacement).\n",
    "\n",
    "        num_reads: number of reads in the subset\n",
    "        \"\"\"\n",
    "        t = []\n",
    "        for count, species in self.species:\n",
    "            t.extend([species]*count)\n",
    "\n",
    "        random.shuffle(t)\n",
    "        reads = t[:num_reads]\n",
    "\n",
    "        subject = Subject(self.code)\n",
    "        hist = thinkbayes.MakeHistFromList(reads)\n",
    "        for species, count in hist.Items():\n",
    "            subject.Add(species, count)\n",
    "\n",
    "        subject.Done()\n",
    "        return subject\n",
    "\n",
    "    def Match(self, match):\n",
    "        \"\"\"Match up a rarefied subject with a complete subject.\n",
    "\n",
    "        match: complete Subject\n",
    "\n",
    "        Assigns attributes:\n",
    "        total_reads:\n",
    "        total_species:\n",
    "        prev_unseen:\n",
    "        \"\"\"\n",
    "        self.total_reads = match.num_reads\n",
    "        self.total_species = match.num_species\n",
    "\n",
    "        # compute the prevalence of unseen species (at least approximately,\n",
    "        # based on all species counts in match\n",
    "        _, seen = self.GetSeenSpecies()\n",
    "\n",
    "        seen_total = 0.0\n",
    "        unseen_total = 0.0\n",
    "        for count, species in match.species:\n",
    "            if species in seen:\n",
    "                seen_total += count\n",
    "            else:\n",
    "                unseen_total += count\n",
    "\n",
    "        self.prev_unseen = unseen_total / (seen_total + unseen_total)\n",
    "\n",
    "    def RunSimulation(self, num_reads, frac_flag=False, jitter=0.01):\n",
    "        \"\"\"Simulates additional observations and returns a rarefaction curve.\n",
    "\n",
    "        k is the number of additional observations\n",
    "        num_new is the number of new species seen\n",
    "\n",
    "        num_reads: how many new reads to simulate\n",
    "        frac_flag: whether to convert to fraction of species seen\n",
    "        jitter: size of jitter added if frac_flag is true\n",
    "\n",
    "        Returns: list of (k, num_new) pairs\n",
    "        \"\"\"\n",
    "        m, seen = self.GetSeenSpecies()\n",
    "        n, observations = self.GenerateObservations(num_reads)\n",
    "\n",
    "        curve = []\n",
    "        for i, obs in enumerate(observations):\n",
    "            seen.add(obs)\n",
    "\n",
    "            if frac_flag:\n",
    "                frac_seen = len(seen) / float(n)\n",
    "                frac_seen += random.uniform(-jitter, jitter)\n",
    "                curve.append((i+1, frac_seen))\n",
    "            else:\n",
    "                num_new = len(seen) - m\n",
    "                curve.append((i+1, num_new))\n",
    "\n",
    "        return curve\n",
    "\n",
    "    def RunSimulations(self, num_sims, num_reads, frac_flag=False):\n",
    "        \"\"\"Runs simulations and returns a list of curves.\n",
    "\n",
    "        Each curve is a sequence of (k, num_new) pairs.\n",
    "\n",
    "        num_sims: how many simulations to run\n",
    "        num_reads: how many samples to generate in each simulation\n",
    "        frac_flag: whether to convert num_new to fraction of total\n",
    "        \"\"\"\n",
    "        curves = [self.RunSimulation(num_reads, frac_flag) \n",
    "                  for _ in range(num_sims)]\n",
    "        return curves\n",
    "\n",
    "    def MakePredictive(self, curves):\n",
    "        \"\"\"Makes a predictive distribution of additional species.\n",
    "\n",
    "        curves: list of (k, num_new) curves \n",
    "\n",
    "        Returns: Pmf of num_new\n",
    "        \"\"\"\n",
    "        pred = thinkbayes.Pmf(name=self.code)\n",
    "        for curve in curves:\n",
    "            _, last_num_new = curve[-1]\n",
    "            pred.Incr(last_num_new)\n",
    "        pred.Normalize()\n",
    "        return pred\n",
    "\n",
    "\n",
    "def MakeConditionals(curves, ks):\n",
    "    \"\"\"Makes Cdfs of the distribution of num_new conditioned on k.\n",
    "\n",
    "    curves: list of (k, num_new) curves \n",
    "    ks: list of values of k\n",
    "\n",
    "    Returns: list of Cdfs\n",
    "    \"\"\"\n",
    "    joint = MakeJointPredictive(curves)\n",
    "\n",
    "    cdfs = []\n",
    "    for k in ks:\n",
    "        pmf = joint.Conditional(1, 0, k)\n",
    "        pmf.name = 'k=%d' % k\n",
    "        cdf = pmf.MakeCdf()\n",
    "        cdfs.append(cdf)\n",
    "        print '90%% credible interval for %d' % k,\n",
    "        print cdf.CredibleInterval(90)\n",
    "    return cdfs\n",
    "\n",
    "\n",
    "def MakeJointPredictive(curves):\n",
    "    \"\"\"Makes a joint distribution of k and num_new.\n",
    "\n",
    "    curves: list of (k, num_new) curves \n",
    "\n",
    "    Returns: joint Pmf of (k, num_new)\n",
    "    \"\"\"\n",
    "    joint = thinkbayes.Joint()\n",
    "    for curve in curves:\n",
    "        for k, num_new in curve:\n",
    "            joint.Incr((k, num_new))\n",
    "    joint.Normalize()\n",
    "    return joint\n",
    "\n",
    "\n",
    "def MakeFracCdfs(curves, ks):\n",
    "    \"\"\"Makes Cdfs of the fraction of species seen.\n",
    "\n",
    "    curves: list of (k, num_new) curves \n",
    "\n",
    "    Returns: list of Cdfs\n",
    "    \"\"\"\n",
    "    d = {}\n",
    "    for curve in curves:\n",
    "        for k, frac in curve:\n",
    "            if k in ks:\n",
    "                d.setdefault(k, []).append(frac)\n",
    "\n",
    "    cdfs = {}\n",
    "    for k, fracs in d.iteritems():\n",
    "        cdf = thinkbayes.MakeCdfFromList(fracs)\n",
    "        cdfs[k] = cdf\n",
    "\n",
    "    return cdfs\n",
    "\n",
    "def SpeciesGenerator(names, num):\n",
    "    \"\"\"Generates a series of names, starting with the given names.\n",
    "\n",
    "    Additional names are 'unseen' plus a serial number.\n",
    "\n",
    "    names: list of strings\n",
    "    num: total number of species names to generate\n",
    "\n",
    "    Returns: string iterator\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    for name in names:\n",
    "        yield name\n",
    "        i += 1\n",
    "\n",
    "    while i < num:\n",
    "        yield 'unseen-%d' % i\n",
    "        i += 1\n",
    "            \n",
    "\n",
    "def ReadRarefactedData(filename='journal.pone.0047712.s001.csv', \n",
    "                       clean_param=0):\n",
    "    \"\"\"Reads a data file and returns a list of Subjects.\n",
    "\n",
    "    Data from http://www.plosone.org/article/\n",
    "    info%3Adoi%2F10.1371%2Fjournal.pone.0047712#s4\n",
    "\n",
    "    filename: string filename to read\n",
    "    clean_param: parameter passed to Clean\n",
    "\n",
    "    Returns: map from code to Subject\n",
    "    \"\"\"\n",
    "    fp = open(filename)\n",
    "    reader = csv.reader(fp)\n",
    "    _ = reader.next()\n",
    "    \n",
    "    subject = Subject('')\n",
    "    subject_map = {}\n",
    "\n",
    "    i = 0\n",
    "    for t in reader:\n",
    "        code = t[0]\n",
    "        if code != subject.code:\n",
    "            # start a new subject\n",
    "            subject = Subject(code)\n",
    "            subject_map[code] = subject\n",
    "\n",
    "        # append a number to the species names so they're unique\n",
    "        species = t[1]\n",
    "        species = '%s-%d' % (species, i)\n",
    "        i += 1\n",
    "\n",
    "        count = int(t[2])\n",
    "        subject.Add(species, count)\n",
    "\n",
    "    for code, subject in subject_map.iteritems():\n",
    "        subject.Done(clean_param=clean_param)\n",
    "\n",
    "    return subject_map\n",
    "\n",
    "\n",
    "def ReadCompleteDataset(filename='BBB_data_from_Rob.csv', clean_param=0):\n",
    "    \"\"\"Reads a data file and returns a list of Subjects.\n",
    "\n",
    "    Data from personal correspondence with Rob Dunn, received 2-7-13.\n",
    "    Converted from xlsx to csv.\n",
    "\n",
    "    filename: string filename to read\n",
    "    clean_param: parameter passed to Clean\n",
    "\n",
    "    Returns: map from code to Subject\n",
    "    \"\"\"\n",
    "    fp = open(filename)\n",
    "    reader = csv.reader(fp)\n",
    "    header = reader.next()\n",
    "    header = reader.next()\n",
    "\n",
    "    subject_codes = header[1:-1]\n",
    "    subject_codes = ['B'+code for code in subject_codes]\n",
    "\n",
    "    # create the subject map\n",
    "    uber_subject = Subject('uber')\n",
    "    subject_map = {}\n",
    "    for code in subject_codes:\n",
    "        subject_map[code] = Subject(code)\n",
    "\n",
    "    # read lines\n",
    "    i = 0\n",
    "    for t in reader:\n",
    "        otu_code = t[0]\n",
    "        if otu_code == '':\n",
    "            continue\n",
    "\n",
    "        # pull out a species name and give it a number\n",
    "        otu_names = t[-1]\n",
    "        taxons = otu_names.split(';')\n",
    "        species = taxons[-1]\n",
    "        species = '%s-%d' % (species, i)\n",
    "        i += 1\n",
    "\n",
    "        counts = [int(x) for x in t[1:-1]]\n",
    "\n",
    "        # print otu_code, species\n",
    "\n",
    "        for code, count in zip(subject_codes, counts):\n",
    "            if count > 0:\n",
    "                subject_map[code].Add(species, count)\n",
    "                uber_subject.Add(species, count)\n",
    "\n",
    "    uber_subject.Done(clean_param=clean_param)\n",
    "    for code, subject in subject_map.iteritems():\n",
    "        subject.Done(clean_param=clean_param)\n",
    "\n",
    "    return subject_map, uber_subject\n",
    "        \n",
    "\n",
    "def JoinSubjects():\n",
    "    \"\"\"Reads both datasets and computers their inner join.\n",
    "\n",
    "    Finds all subjects that appear in both datasets.\n",
    "\n",
    "    For subjects in the rarefacted dataset, looks up the total\n",
    "    number of reads and stores it as total_reads.  num_reads\n",
    "    is normally 400.\n",
    "    \n",
    "    Returns: map from code to Subject\n",
    "    \"\"\"\n",
    "\n",
    "    # read the rarefacted dataset\n",
    "    sampled_subjects = ReadRarefactedData()\n",
    "\n",
    "    # read the complete dataset\n",
    "    all_subjects, _ = ReadCompleteDataset()\n",
    "\n",
    "    for code, subject in sampled_subjects.iteritems():\n",
    "        if code in all_subjects:\n",
    "            match = all_subjects[code]\n",
    "            subject.Match(match)\n",
    "\n",
    "    return sampled_subjects\n",
    "\n",
    "\n",
    "def JitterCurve(curve, dx=0.2, dy=0.3):\n",
    "    \"\"\"Adds random noise to the pairs in a curve.\n",
    "\n",
    "    dx and dy control the amplitude of the noise in each dimension.\n",
    "    \"\"\"\n",
    "    curve = [(x+random.uniform(-dx, dx), \n",
    "              y+random.uniform(-dy, dy)) for x, y in curve]\n",
    "    return curve\n",
    "\n",
    "\n",
    "def OffsetCurve(curve, i, n, dx=0.3, dy=0.3):\n",
    "    \"\"\"Adds random noise to the pairs in a curve.\n",
    "\n",
    "    i is the index of the curve\n",
    "    n is the number of curves\n",
    "\n",
    "    dx and dy control the amplitude of the noise in each dimension.\n",
    "    \"\"\"\n",
    "    xoff = -dx + 2 * dx * i / (n-1)\n",
    "    yoff = -dy + 2 * dy * i / (n-1)\n",
    "    curve = [(x+xoff, y+yoff) for x, y in curve]\n",
    "    return curve\n",
    "\n",
    "\n",
    "def PlotCurves(curves, root='species-rare'):\n",
    "    \"\"\"Plots a set of curves.\n",
    "\n",
    "    curves is a list of curves; each curve is a list of (x, y) pairs.\n",
    "    \"\"\"\n",
    "    thinkplot.Clf()\n",
    "    color = '#225EA8'\n",
    "\n",
    "    n = len(curves)\n",
    "    for i, curve in enumerate(curves):\n",
    "        curve = OffsetCurve(curve, i, n)\n",
    "        xs, ys = zip(*curve)\n",
    "        thinkplot.Plot(xs, ys, color=color, alpha=0.3, linewidth=0.5)\n",
    "\n",
    "    thinkplot.Save(root=root,\n",
    "                xlabel='# samples',\n",
    "                ylabel='# species',\n",
    "                formats=FORMATS,\n",
    "                legend=False)\n",
    "\n",
    "\n",
    "def PlotConditionals(cdfs, root='species-cond'):\n",
    "    \"\"\"Plots cdfs of num_new conditioned on k.\n",
    "\n",
    "    cdfs: list of Cdf\n",
    "    root: string filename root\n",
    "    \"\"\"\n",
    "    thinkplot.Clf()\n",
    "    thinkplot.PrePlot(num=len(cdfs))\n",
    "\n",
    "    thinkplot.Cdfs(cdfs)\n",
    "\n",
    "    thinkplot.Save(root=root,\n",
    "                xlabel='# new species',\n",
    "                ylabel='Prob',\n",
    "                formats=FORMATS)\n",
    "\n",
    "\n",
    "def PlotFracCdfs(cdfs, root='species-frac'):\n",
    "    \"\"\"Plots CDFs of the fraction of species seen.\n",
    "\n",
    "    cdfs: map from k to CDF of fraction of species seen after k samples\n",
    "    \"\"\"\n",
    "    thinkplot.Clf()\n",
    "    color = '#225EA8'\n",
    "\n",
    "    for k, cdf in cdfs.iteritems():\n",
    "        xs, ys = cdf.Render()\n",
    "        ys = [1-y for y in ys]\n",
    "        thinkplot.Plot(xs, ys, color=color, linewidth=1)\n",
    "\n",
    "        x = 0.9\n",
    "        y = 1 - cdf.Prob(x)\n",
    "        pyplot.text(x, y, str(k), fontsize=9, color=color,\n",
    "                    horizontalalignment='center',\n",
    "                    verticalalignment='center',\n",
    "                    bbox=dict(facecolor='white', edgecolor='none'))\n",
    "\n",
    "    thinkplot.Save(root=root,\n",
    "                xlabel='Fraction of species seen',\n",
    "                ylabel='Probability',\n",
    "                formats=FORMATS,\n",
    "                legend=False)\n",
    "\n",
    "\n",
    "class Species(thinkbayes.Suite):\n",
    "    \"\"\"Represents hypotheses about the number of species.\"\"\"\n",
    "    \n",
    "    def __init__(self, ns, conc=1, iters=1000):\n",
    "        hypos = [thinkbayes.Dirichlet(n, conc) for n in ns]\n",
    "        thinkbayes.Suite.__init__(self, hypos)\n",
    "        self.iters = iters\n",
    "\n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates the suite based on the data.\n",
    "\n",
    "        data: list of observed frequencies\n",
    "        \"\"\"\n",
    "        # call Update in the parent class, which calls Likelihood\n",
    "        thinkbayes.Suite.Update(self, data)\n",
    "\n",
    "        # update the next level of the hierarchy\n",
    "        for hypo in self.Values():\n",
    "            hypo.Update(data)\n",
    "\n",
    "    def Likelihood(self, data, hypo):\n",
    "        \"\"\"Computes the likelihood of the data under this hypothesis.\n",
    "\n",
    "        hypo: Dirichlet object\n",
    "        data: list of observed frequencies\n",
    "        \"\"\"\n",
    "        dirichlet = hypo\n",
    "\n",
    "        # draw sample Likelihoods from the hypothetical Dirichlet dist\n",
    "        # and add them up\n",
    "        like = 0\n",
    "        for _ in range(self.iters):\n",
    "            like += dirichlet.Likelihood(data)\n",
    "\n",
    "        # correct for the number of ways the observed species\n",
    "        # might have been chosen from all species\n",
    "        m = len(data)\n",
    "        like *= thinkbayes.BinomialCoef(dirichlet.n, m)\n",
    "\n",
    "        return like\n",
    "\n",
    "    def DistN(self):\n",
    "        \"\"\"Computes the distribution of n.\"\"\"\n",
    "        pmf = thinkbayes.Pmf()\n",
    "        for hypo, prob in self.Items():\n",
    "            pmf.Set(hypo.n, prob)\n",
    "        return pmf\n",
    "        \n",
    "\n",
    "class Species2(object):\n",
    "    \"\"\"Represents hypotheses about the number of species.\n",
    "\n",
    "    Combines two layers of the hierarchy into one object.\n",
    "\n",
    "    ns and probs represent the distribution of N\n",
    "\n",
    "    params represents the parameters of the Dirichlet distributions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ns, conc=1, iters=1000):\n",
    "        self.ns = ns\n",
    "        self.conc = conc\n",
    "        self.probs = numpy.ones(len(ns), dtype=numpy.float)\n",
    "        self.params = numpy.ones(self.ns[-1], dtype=numpy.float) * conc\n",
    "        self.iters = iters\n",
    "        self.num_reads = 0\n",
    "        self.m = 0\n",
    "\n",
    "    def Preload(self, data):\n",
    "        \"\"\"Change the initial parameters to fit the data better.\n",
    "\n",
    "        Just an experiment.  Doesn't work.\n",
    "        \"\"\"\n",
    "        m = len(data)\n",
    "        singletons = data.count(1)\n",
    "        num = m - singletons\n",
    "        print m, singletons, num\n",
    "        addend = numpy.ones(num, dtype=numpy.float) * 1\n",
    "        print len(addend)\n",
    "        print len(self.params[singletons:m])\n",
    "        self.params[singletons:m] += addend\n",
    "        print 'Preload', num\n",
    "\n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates the distribution based on data.\n",
    "\n",
    "        data: numpy array of counts\n",
    "        \"\"\"\n",
    "        self.num_reads += sum(data)\n",
    "\n",
    "        like = numpy.zeros(len(self.ns), dtype=numpy.float)\n",
    "        for _ in range(self.iters):\n",
    "            like += self.SampleLikelihood(data)\n",
    "\n",
    "        self.probs *= like\n",
    "        self.probs /= self.probs.sum()\n",
    "\n",
    "        self.m = len(data)\n",
    "        #self.params[:self.m] += data * self.conc\n",
    "        self.params[:self.m] += data\n",
    "\n",
    "    def SampleLikelihood(self, data):\n",
    "        \"\"\"Computes the likelihood of the data for all values of n.\n",
    "\n",
    "        Draws one sample from the distribution of prevalences.\n",
    "\n",
    "        data: sequence of observed counts\n",
    "\n",
    "        Returns: numpy array of m likelihoods\n",
    "        \"\"\"\n",
    "        gammas = numpy.random.gamma(self.params)\n",
    "\n",
    "        m = len(data)\n",
    "        row = gammas[:m]\n",
    "        col = numpy.cumsum(gammas)\n",
    "\n",
    "        log_likes = []\n",
    "        for n in self.ns:\n",
    "            ps = row / col[n-1]\n",
    "            terms = numpy.log(ps) * data\n",
    "            log_like = terms.sum()\n",
    "            log_likes.append(log_like)\n",
    "\n",
    "        log_likes -= numpy.max(log_likes)\n",
    "        likes = numpy.exp(log_likes)\n",
    "\n",
    "        coefs = [thinkbayes.BinomialCoef(n, m) for n in self.ns]\n",
    "        likes *= coefs\n",
    "\n",
    "        return likes\n",
    "\n",
    "    def DistN(self):\n",
    "        \"\"\"Computes the distribution of n.\n",
    "\n",
    "        Returns: new Pmf object\n",
    "        \"\"\"\n",
    "        pmf = thinkbayes.MakePmfFromItems(zip(self.ns, self.probs))\n",
    "        return pmf\n",
    "\n",
    "    def RandomN(self):\n",
    "        \"\"\"Returns a random value of n.\"\"\"\n",
    "        return self.DistN().Random()\n",
    "\n",
    "    def DistQ(self, iters=100):\n",
    "        \"\"\"Computes the distribution of q based on distribution of n.\n",
    "\n",
    "        Returns: pmf of q\n",
    "        \"\"\"\n",
    "        cdf_n = self.DistN().MakeCdf()\n",
    "        sample_n = cdf_n.Sample(iters)\n",
    "\n",
    "        pmf = thinkbayes.Pmf()\n",
    "        for n in sample_n:\n",
    "            q = self.RandomQ(n)\n",
    "            pmf.Incr(q)\n",
    "\n",
    "        pmf.Normalize()\n",
    "        return pmf\n",
    "\n",
    "    def RandomQ(self, n):\n",
    "        \"\"\"Returns a random value of q.\n",
    "\n",
    "        Based on n, self.num_reads and self.conc.\n",
    "\n",
    "        n: number of species\n",
    "\n",
    "        Returns: q\n",
    "        \"\"\"\n",
    "        # generate random prevalences\n",
    "        dirichlet = thinkbayes.Dirichlet(n, conc=self.conc)\n",
    "        prevalences = dirichlet.Random()\n",
    "\n",
    "        # generate a simulated sample\n",
    "        pmf = thinkbayes.MakePmfFromItems(enumerate(prevalences))\n",
    "        cdf = pmf.MakeCdf()\n",
    "        sample = cdf.Sample(self.num_reads)\n",
    "        seen = set(sample)\n",
    "\n",
    "        # add up the prevalence of unseen species\n",
    "        q = 0\n",
    "        for species, prev in enumerate(prevalences):\n",
    "            if species not in seen:\n",
    "                q += prev\n",
    "\n",
    "        return q\n",
    "\n",
    "    def MarginalBeta(self, n, index):\n",
    "        \"\"\"Computes the conditional distribution of the indicated species.\n",
    "        \n",
    "        n: conditional number of species\n",
    "        index: which species\n",
    "\n",
    "        Returns: Beta object representing a distribution of prevalence.\n",
    "        \"\"\"\n",
    "        alpha0 = self.params[:n].sum()\n",
    "        alpha = self.params[index]\n",
    "        return thinkbayes.Beta(alpha, alpha0-alpha)\n",
    "\n",
    "    def DistOfPrevalence(self, index):\n",
    "        \"\"\"Computes the distribution of prevalence for the indicated species.\n",
    "\n",
    "        index: which species\n",
    "\n",
    "        Returns: (metapmf, mix) where metapmf is a MetaPmf and mix is a Pmf\n",
    "        \"\"\"\n",
    "        metapmf = thinkbayes.Pmf()\n",
    "\n",
    "        for n, prob in zip(self.ns, self.probs):\n",
    "            beta = self.MarginalBeta(n, index)\n",
    "            pmf = beta.MakePmf()\n",
    "            metapmf.Set(pmf, prob)\n",
    "\n",
    "        mix = thinkbayes.MakeMixture(metapmf)\n",
    "        return metapmf, mix\n",
    "        \n",
    "    def SamplePosterior(self):\n",
    "        \"\"\"Draws random n and prevalences.\n",
    "\n",
    "        Returns: (n, prevalences)\n",
    "        \"\"\"\n",
    "        n = self.RandomN()\n",
    "        prevalences = self.SamplePrevalences(n)\n",
    "\n",
    "        #print 'Peeking at n_cheat'\n",
    "        #n = n_cheat\n",
    "\n",
    "        return n, prevalences\n",
    "\n",
    "    def SamplePrevalences(self, n):\n",
    "        \"\"\"Draws a sample of prevalences given n.\n",
    "\n",
    "        n: the number of species assumed in the conditional\n",
    "\n",
    "        Returns: numpy array of n prevalences\n",
    "        \"\"\"\n",
    "        if n == 1:\n",
    "            return [1.0]\n",
    "\n",
    "        q_desired = self.RandomQ(n)\n",
    "        q_desired = max(q_desired, 1e-6)\n",
    "\n",
    "        params = self.Unbias(n, self.m, q_desired)\n",
    "\n",
    "        gammas = numpy.random.gamma(params)\n",
    "        gammas /= gammas.sum()\n",
    "        return gammas\n",
    "        \n",
    "    def Unbias(self, n, m, q_desired):\n",
    "        \"\"\"Adjusts the parameters to achieve desired prev_unseen (q).\n",
    "\n",
    "        n: number of species\n",
    "        m: seen species\n",
    "        q_desired: prevalence of unseen species\n",
    "        \"\"\"\n",
    "        params = self.params[:n].copy()\n",
    "\n",
    "        if n == m:\n",
    "            return params\n",
    "        \n",
    "        x = sum(params[:m])\n",
    "        y = sum(params[m:])\n",
    "        a = x + y\n",
    "        #print x, y, a, x/a, y/a\n",
    "\n",
    "        g = q_desired * a / y\n",
    "        f = (a - g * y) / x\n",
    "        params[:m] *= f\n",
    "        params[m:] *= g\n",
    "\n",
    "        return params\n",
    "\n",
    "\n",
    "class Species3(Species2):\n",
    "    \"\"\"Represents hypotheses about the number of species.\"\"\"\n",
    "    \n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates the suite based on the data.\n",
    "\n",
    "        data: list of observations\n",
    "        \"\"\"\n",
    "        # sample the likelihoods and add them up\n",
    "        like = numpy.zeros(len(self.ns), dtype=numpy.float)\n",
    "        for _ in range(self.iters):\n",
    "            like += self.SampleLikelihood(data)\n",
    "\n",
    "        self.probs *= like\n",
    "        self.probs /= self.probs.sum()\n",
    "\n",
    "        m = len(data)\n",
    "        self.params[:m] += data\n",
    "\n",
    "    def SampleLikelihood(self, data):\n",
    "        \"\"\"Computes the likelihood of the data under all hypotheses.\n",
    "\n",
    "        data: list of observations\n",
    "        \"\"\"\n",
    "        # get a random sample\n",
    "        gammas = numpy.random.gamma(self.params)\n",
    "\n",
    "        # row is just the first m elements of gammas\n",
    "        m = len(data)\n",
    "        row = gammas[:m]\n",
    "\n",
    "        # col is the cumulative sum of gammas\n",
    "        col = numpy.cumsum(gammas)[self.ns[0]-1:]\n",
    "\n",
    "        # each row of the array is a set of ps, normalized\n",
    "        # for each hypothetical value of n\n",
    "        array = row / col[:, numpy.newaxis]\n",
    "\n",
    "        # computing the multinomial PDF under a log transform\n",
    "        # take the log of the ps and multiply by the data\n",
    "        terms = numpy.log(array) * data\n",
    "\n",
    "        # add up the rows\n",
    "        log_likes = terms.sum(axis=1)\n",
    "\n",
    "        # before exponentiating, scale into a reasonable range\n",
    "        log_likes -= numpy.max(log_likes)\n",
    "        likes = numpy.exp(log_likes)\n",
    "\n",
    "        # correct for the number of ways we could see m species\n",
    "        # out of a possible n\n",
    "        coefs = [thinkbayes.BinomialCoef(n, m) for n in self.ns]\n",
    "        likes *= coefs\n",
    "\n",
    "        return likes\n",
    "\n",
    "\n",
    "class Species4(Species):\n",
    "    \"\"\"Represents hypotheses about the number of species.\"\"\"\n",
    "    \n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates the suite based on the data.\n",
    "\n",
    "        data: list of observed frequencies\n",
    "        \"\"\"\n",
    "        m = len(data)\n",
    "\n",
    "        # loop through the species and update one at a time\n",
    "        for i in range(m):\n",
    "            one = numpy.zeros(i+1)\n",
    "            one[i] = data[i]\n",
    "            \n",
    "            # call the parent class\n",
    "            Species.Update(self, one)\n",
    "\n",
    "    def Likelihood(self, data, hypo):\n",
    "        \"\"\"Computes the likelihood of the data under this hypothesis.\n",
    "\n",
    "        Note: this only works correctly if we update one species at a time.\n",
    "\n",
    "        hypo: Dirichlet object\n",
    "        data: list of observed frequencies\n",
    "        \"\"\"\n",
    "        dirichlet = hypo\n",
    "        like = 0\n",
    "        for _ in range(self.iters):\n",
    "            like += dirichlet.Likelihood(data)\n",
    "\n",
    "        # correct for the number of unseen species the new one\n",
    "        # could have been\n",
    "        m = len(data)\n",
    "        num_unseen = dirichlet.n - m + 1\n",
    "        like *= num_unseen\n",
    "\n",
    "        return like\n",
    "\n",
    "\n",
    "class Species5(Species2):\n",
    "    \"\"\"Represents hypotheses about the number of species.\n",
    "\n",
    "    Combines two laters of the hierarchy into one object.\n",
    "\n",
    "    ns and probs represent the distribution of N\n",
    "\n",
    "    params represents the parameters of the Dirichlet distributions\n",
    "    \"\"\"\n",
    "    \n",
    "    def Update(self, data):\n",
    "        \"\"\"Updates the suite based on the data.\n",
    "\n",
    "        data: list of observed frequencies in increasing order\n",
    "        \"\"\"\n",
    "        # loop through the species and update one at a time\n",
    "        m = len(data)\n",
    "        for i in range(m):\n",
    "            self.UpdateOne(i+1, data[i])\n",
    "            self.params[i] += data[i]\n",
    "\n",
    "    def UpdateOne(self, i, count):\n",
    "        \"\"\"Updates the suite based on the data.\n",
    "\n",
    "        Evaluates the likelihood for all values of n.\n",
    "\n",
    "        i: which species was observed (1..n)\n",
    "        count: how many were observed\n",
    "        \"\"\"\n",
    "        # how many species have we seen so far\n",
    "        self.m = i\n",
    "\n",
    "        # how many reads have we seen\n",
    "        self.num_reads += count\n",
    "\n",
    "        if self.iters == 0:\n",
    "            return\n",
    "\n",
    "        # sample the likelihoods and add them up\n",
    "        likes = numpy.zeros(len(self.ns), dtype=numpy.float)\n",
    "        for _ in range(self.iters):\n",
    "            likes += self.SampleLikelihood(i, count)\n",
    "\n",
    "        # correct for the number of unseen species the new one\n",
    "        # could have been\n",
    "        unseen_species = [n-i+1 for n in self.ns]\n",
    "        likes *= unseen_species\n",
    "\n",
    "        # multiply the priors by the likelihoods and renormalize\n",
    "        self.probs *= likes\n",
    "        self.probs /= self.probs.sum()\n",
    "\n",
    "    def SampleLikelihood(self, i, count):\n",
    "        \"\"\"Computes the likelihood of the data under all hypotheses.\n",
    "\n",
    "        i: which species was observed\n",
    "        count: how many were observed\n",
    "        \"\"\"\n",
    "        # get a random sample of p\n",
    "        gammas = numpy.random.gamma(self.params)\n",
    "\n",
    "        # sums is the cumulative sum of p, for each value of n\n",
    "        sums = numpy.cumsum(gammas)[self.ns[0]-1:]\n",
    "\n",
    "        # get p for the mth species, for each value of n\n",
    "        ps = gammas[i-1] / sums\n",
    "        log_likes = numpy.log(ps) * count\n",
    "\n",
    "        # before exponentiating, scale into a reasonable range\n",
    "        log_likes -= numpy.max(log_likes)\n",
    "        likes = numpy.exp(log_likes)\n",
    "\n",
    "        return likes\n",
    "\n",
    "\n",
    "def MakePosterior(constructor, data, ns, conc=1, iters=1000):\n",
    "    \"\"\"Makes a suite, updates it and returns the posterior suite.\n",
    "\n",
    "    Prints the elapsed time.\n",
    "\n",
    "    data: observed species and their counts\n",
    "    ns: sequence of hypothetical ns\n",
    "    conc: concentration parameter\n",
    "    iters: how many samples to draw\n",
    "\n",
    "    Returns: posterior suite of the given type\n",
    "    \"\"\"\n",
    "    suite = constructor(ns, conc=conc, iters=iters)\n",
    "\n",
    "    # print constructor.__name__\n",
    "    start = time.time()\n",
    "    suite.Update(data)\n",
    "    end = time.time()\n",
    "    print 'Processing time', end-start\n",
    "\n",
    "    return suite\n",
    "\n",
    "\n",
    "def PlotAllVersions():\n",
    "    \"\"\"Makes a graph of posterior distributions of N.\"\"\"\n",
    "    data = [1, 2, 3]\n",
    "    m = len(data)\n",
    "    n = 20\n",
    "    ns = range(m, n)\n",
    "\n",
    "    for constructor in [Species, Species2, Species3, Species4, Species5]:\n",
    "        suite = MakePosterior(constructor, data, ns)\n",
    "        pmf = suite.DistN()\n",
    "        pmf.name = '%s' % (constructor.__name__)\n",
    "        thinkplot.Pmf(pmf)\n",
    "\n",
    "    thinkplot.Save(root='species3',\n",
    "                xlabel='Number of species',\n",
    "                ylabel='Prob')\n",
    "\n",
    "\n",
    "def PlotMedium():\n",
    "    \"\"\"Makes a graph of posterior distributions of N.\"\"\"\n",
    "    data = [1, 1, 1, 1, 2, 3, 5, 9]\n",
    "    m = len(data)\n",
    "    n = 20\n",
    "    ns = range(m, n)\n",
    "\n",
    "    for constructor in [Species, Species2, Species3, Species4, Species5]:\n",
    "        suite = MakePosterior(constructor, data, ns)\n",
    "        pmf = suite.DistN()\n",
    "        pmf.name = '%s' % (constructor.__name__)\n",
    "        thinkplot.Pmf(pmf)\n",
    "\n",
    "    thinkplot.Show()\n",
    "\n",
    "\n",
    "def SimpleDirichletExample():\n",
    "    \"\"\"Makes a plot showing posterior distributions for three species.\n",
    "\n",
    "    This is the case where we know there are exactly three species.\n",
    "    \"\"\"\n",
    "    thinkplot.Clf()\n",
    "    thinkplot.PrePlot(3)\n",
    "\n",
    "    names = ['lions',  'tigers', 'bears']\n",
    "    data = [3, 2, 1]\n",
    "\n",
    "    dirichlet = thinkbayes.Dirichlet(3)\n",
    "    for i in range(3):\n",
    "        beta = dirichlet.MarginalBeta(i)\n",
    "        print 'mean', names[i], beta.Mean()\n",
    "\n",
    "    dirichlet.Update(data)\n",
    "    for i in range(3):\n",
    "        beta = dirichlet.MarginalBeta(i)\n",
    "        print 'mean', names[i], beta.Mean()\n",
    "\n",
    "        pmf = beta.MakePmf(name=names[i])\n",
    "        thinkplot.Pmf(pmf)\n",
    "\n",
    "    thinkplot.Save(root='species1',\n",
    "                xlabel='Prevalence',\n",
    "                ylabel='Prob',\n",
    "                formats=FORMATS,\n",
    "                )\n",
    "\n",
    "\n",
    "def HierarchicalExample():\n",
    "    \"\"\"Shows the posterior distribution of n for lions, tigers and bears.\n",
    "    \"\"\"\n",
    "    ns = range(3, 30)\n",
    "    suite = Species(ns, iters=8000)\n",
    "\n",
    "    data = [3, 2, 1]\n",
    "    suite.Update(data)\n",
    "\n",
    "    thinkplot.Clf()\n",
    "    thinkplot.PrePlot(num=1)\n",
    "\n",
    "    pmf = suite.DistN()\n",
    "    thinkplot.Pmf(pmf)\n",
    "    thinkplot.Save(root='species2',\n",
    "                xlabel='Number of species',\n",
    "                ylabel='Prob',\n",
    "                formats=FORMATS,\n",
    "                )\n",
    "\n",
    "\n",
    "def CompareHierarchicalExample():\n",
    "    \"\"\"Makes a graph of posterior distributions of N.\"\"\"\n",
    "    data = [3, 2, 1]\n",
    "    m = len(data)\n",
    "    n = 30\n",
    "    ns = range(m, n)\n",
    "\n",
    "    constructors = [Species, Species5]\n",
    "    iters = [1000, 100]\n",
    "\n",
    "    for constructor, iters in zip(constructors, iters):\n",
    "        suite = MakePosterior(constructor, data, ns, iters)\n",
    "        pmf = suite.DistN()\n",
    "        pmf.name = '%s' % (constructor.__name__)\n",
    "        thinkplot.Pmf(pmf)\n",
    "\n",
    "    thinkplot.Show()\n",
    "\n",
    "\n",
    "def ProcessSubjects(codes):\n",
    "    \"\"\"Process subjects with the given codes and plot their posteriors.\n",
    "\n",
    "    code: sequence of string codes\n",
    "    \"\"\"\n",
    "    thinkplot.Clf()\n",
    "    thinkplot.PrePlot(len(codes))\n",
    "\n",
    "    subjects = ReadRarefactedData()\n",
    "    pmfs = []\n",
    "    for code in codes:\n",
    "        subject = subjects[code]\n",
    "\n",
    "        subject.Process()\n",
    "        pmf = subject.suite.DistN()\n",
    "        pmf.name = subject.code\n",
    "        thinkplot.Pmf(pmf)\n",
    "\n",
    "        pmfs.append(pmf)\n",
    "\n",
    "    print 'ProbGreater', thinkbayes.PmfProbGreater(pmfs[0], pmfs[1])\n",
    "    print 'ProbLess', thinkbayes.PmfProbLess(pmfs[0], pmfs[1])\n",
    "\n",
    "    thinkplot.Save(root='species4',\n",
    "                xlabel='Number of species',\n",
    "                ylabel='Prob',\n",
    "                formats=FORMATS,\n",
    "                )\n",
    "\n",
    "\n",
    "def RunSubject(code, conc=1, high=500):\n",
    "    \"\"\"Run the analysis for the subject with the given code.\n",
    "\n",
    "    code: string code\n",
    "    \"\"\"\n",
    "    subjects = JoinSubjects()\n",
    "    subject = subjects[code]\n",
    "\n",
    "    subject.Process(conc=conc, high=high, iters=300)\n",
    "    subject.MakeQuickPrediction()\n",
    "\n",
    "    PrintSummary(subject)\n",
    "    actual_l = subject.total_species - subject.num_species\n",
    "    cdf_l = subject.DistL().MakeCdf()\n",
    "    PrintPrediction(cdf_l, actual_l)\n",
    "\n",
    "    subject.MakeFigures()\n",
    "\n",
    "    num_reads = 400\n",
    "    curves = subject.RunSimulations(100, num_reads)\n",
    "    root = 'species-rare-%s' % subject.code\n",
    "    PlotCurves(curves, root=root)\n",
    "\n",
    "    num_reads = 800\n",
    "    curves = subject.RunSimulations(500, num_reads)\n",
    "    ks = [100, 200, 400, 800]\n",
    "    cdfs = MakeConditionals(curves, ks)\n",
    "    root = 'species-cond-%s' % subject.code\n",
    "    PlotConditionals(cdfs, root=root)\n",
    "\n",
    "    num_reads = 1000\n",
    "    curves = subject.RunSimulations(500, num_reads, frac_flag=True)\n",
    "    ks = [10, 100, 200, 400, 600, 800, 1000]\n",
    "    cdfs = MakeFracCdfs(curves, ks)\n",
    "    root = 'species-frac-%s' % subject.code\n",
    "    PlotFracCdfs(cdfs, root=root)\n",
    "\n",
    "\n",
    "def PrintSummary(subject):\n",
    "    \"\"\"Print a summary of a subject.\n",
    "\n",
    "    subject: Subject\n",
    "    \"\"\"\n",
    "    print subject.code\n",
    "    print 'found %d species in %d reads' % (subject.num_species,\n",
    "                                            subject.num_reads)\n",
    "\n",
    "    print 'total %d species in %d reads' % (subject.total_species,\n",
    "                                            subject.total_reads)\n",
    "\n",
    "    cdf = subject.suite.DistN().MakeCdf()\n",
    "    print 'n'\n",
    "    PrintPrediction(cdf, 'unknown')\n",
    "    \n",
    "\n",
    "def PrintPrediction(cdf, actual):\n",
    "    \"\"\"Print a summary of a prediction.\n",
    "\n",
    "    cdf: predictive distribution\n",
    "    actual: actual value\n",
    "    \"\"\"\n",
    "    median = cdf.Percentile(50)\n",
    "    low, high = cdf.CredibleInterval(75)\n",
    "    \n",
    "    print 'predicted %0.2f (%0.2f %0.2f)' % (median, low, high)\n",
    "    print 'actual', actual\n",
    "\n",
    "\n",
    "def RandomSeed(x):\n",
    "    \"\"\"Initialize random.random and numpy.random.\n",
    "\n",
    "    x: int seed\n",
    "    \"\"\"\n",
    "    random.seed(x)\n",
    "    numpy.random.seed(x)\n",
    "\n",
    "\n",
    "def GenerateFakeSample(n, r, tr, conc=1):\n",
    "    \"\"\"Generates fake data with the given parameters.\n",
    "\n",
    "    n: number of species\n",
    "    r: number of reads in subsample\n",
    "    tr: total number of reads\n",
    "    conc: concentration parameter\n",
    "\n",
    "    Returns: hist of all reads, hist of subsample, prev_unseen\n",
    "    \"\"\"\n",
    "    # generate random prevalences\n",
    "    dirichlet = thinkbayes.Dirichlet(n, conc=conc)\n",
    "    prevalences = dirichlet.Random()\n",
    "    prevalences.sort()\n",
    "\n",
    "    # generate a simulated sample\n",
    "    pmf = thinkbayes.MakePmfFromItems(enumerate(prevalences))\n",
    "    cdf = pmf.MakeCdf()\n",
    "    sample = cdf.Sample(tr)\n",
    "\n",
    "    # collect the species counts\n",
    "    hist = thinkbayes.MakeHistFromList(sample)\n",
    "\n",
    "    # extract a subset of the data\n",
    "    if tr > r:\n",
    "        random.shuffle(sample)\n",
    "        subsample = sample[:r]\n",
    "        subhist = thinkbayes.MakeHistFromList(subsample)\n",
    "    else:\n",
    "        subhist = hist\n",
    "\n",
    "    # add up the prevalence of unseen species\n",
    "    prev_unseen = 0\n",
    "    for species, prev in enumerate(prevalences):\n",
    "        if species not in subhist:\n",
    "            prev_unseen += prev\n",
    "\n",
    "    return hist, subhist, prev_unseen\n",
    "\n",
    "\n",
    "def PlotActualPrevalences():\n",
    "    \"\"\"Makes a plot comparing actual prevalences with a model.\n",
    "    \"\"\"\n",
    "    # read data\n",
    "    subject_map, _ = ReadCompleteDataset()\n",
    "\n",
    "    # for subjects with more than 50 species,\n",
    "    # PMF of max prevalence, and PMF of max prevalence\n",
    "    # generated by a simulation\n",
    "    pmf_actual = thinkbayes.Pmf()\n",
    "    pmf_sim = thinkbayes.Pmf()\n",
    "\n",
    "    # concentration parameter used in the simulation\n",
    "    conc = 0.06\n",
    "\n",
    "    for code, subject in subject_map.iteritems():\n",
    "        prevalences = subject.GetPrevalences()\n",
    "        m = len(prevalences)\n",
    "        if m < 2:\n",
    "            continue\n",
    "\n",
    "        actual_max = max(prevalences)\n",
    "        print code, m, actual_max\n",
    "\n",
    "        # incr the PMFs\n",
    "        if m > 50:\n",
    "            pmf_actual.Incr(actual_max)\n",
    "            pmf_sim.Incr(SimulateMaxPrev(m, conc))\n",
    "\n",
    "    # plot CDFs for the actual and simulated max prevalence\n",
    "    cdf_actual = pmf_actual.MakeCdf(name='actual')\n",
    "    cdf_sim = pmf_sim.MakeCdf(name='sim')\n",
    "\n",
    "    thinkplot.Cdfs([cdf_actual, cdf_sim])\n",
    "    thinkplot.Show()\n",
    "\n",
    "\n",
    "def ScatterPrevalences(ms, actual):\n",
    "    \"\"\"Make a scatter plot of actual prevalences and expected values.\n",
    "\n",
    "    ms: sorted sequence of in m (number of species)\n",
    "    actual: sequence of actual max prevalence\n",
    "    \"\"\"\n",
    "    for conc in [1, 0.5, 0.2, 0.1]:\n",
    "        expected = [ExpectedMaxPrev(m, conc) for m in ms]\n",
    "        thinkplot.Plot(ms, expected)\n",
    "\n",
    "    thinkplot.Scatter(ms, actual)\n",
    "    thinkplot.Show(xscale='log')\n",
    "\n",
    "\n",
    "def SimulateMaxPrev(m, conc=1):\n",
    "    \"\"\"Returns random max prevalence from a Dirichlet distribution.\n",
    "\n",
    "    m: int number of species\n",
    "    conc: concentration parameter of the Dirichlet distribution\n",
    "\n",
    "    Returns: float max of m prevalences\n",
    "    \"\"\"\n",
    "    dirichlet = thinkbayes.Dirichlet(m, conc)\n",
    "    prevalences = dirichlet.Random()\n",
    "    return max(prevalences)\n",
    "        \n",
    "\n",
    "def ExpectedMaxPrev(m, conc=1, iters=100):\n",
    "    \"\"\"Estimate expected max prevalence.\n",
    "\n",
    "    m: number of species\n",
    "    conc: concentration parameter\n",
    "    iters: how many iterations to run\n",
    "\n",
    "    Returns: expected max prevalence\n",
    "    \"\"\"\n",
    "    dirichlet = thinkbayes.Dirichlet(m, conc)\n",
    "\n",
    "    t = []\n",
    "    for _ in range(iters):\n",
    "        prevalences = dirichlet.Random()\n",
    "        t.append(max(prevalences))\n",
    "\n",
    "    return numpy.mean(t)\n",
    "\n",
    "\n",
    "class Calibrator(object):\n",
    "    \"\"\"Encapsulates the calibration process.\"\"\"\n",
    "\n",
    "    def __init__(self, conc=0.1):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.conc = conc\n",
    "\n",
    "        self.ps =  range(10, 100, 10)\n",
    "        self.total_n = numpy.zeros(len(self.ps))\n",
    "        self.total_q = numpy.zeros(len(self.ps))\n",
    "        self.total_l = numpy.zeros(len(self.ps))\n",
    "\n",
    "        self.n_seq = []\n",
    "        self.q_seq = []\n",
    "        self.l_seq = []\n",
    "\n",
    "    def Calibrate(self, num_runs=100, n_low=30, n_high=400, r=400, tr=1200):\n",
    "        \"\"\"Runs calibrations.\n",
    "\n",
    "        num_runs: how many runs\n",
    "        \"\"\"\n",
    "        for seed in range(num_runs):\n",
    "            self.RunCalibration(seed, n_low, n_high, r, tr)\n",
    "\n",
    "        self.total_n *= 100.0 / num_runs\n",
    "        self.total_q *= 100.0 / num_runs\n",
    "        self.total_l *= 100.0 / num_runs\n",
    "\n",
    "    def Validate(self, num_runs=100, clean_param=0):\n",
    "        \"\"\"Runs validations.\n",
    "\n",
    "        num_runs: how many runs\n",
    "        \"\"\"\n",
    "        subject_map, _ = ReadCompleteDataset(clean_param=clean_param)\n",
    "\n",
    "        i = 0\n",
    "        for match in subject_map.itervalues():\n",
    "            if match.num_reads < 400:\n",
    "                continue\n",
    "            num_reads = 100\n",
    "\n",
    "            print 'Validate', match.code\n",
    "            subject = match.Resample(num_reads)\n",
    "            subject.Match(match)\n",
    "\n",
    "            n_actual = None\n",
    "            q_actual = subject.prev_unseen\n",
    "            l_actual = subject.total_species - subject.num_species\n",
    "            self.RunSubject(subject, n_actual, q_actual, l_actual)\n",
    "            \n",
    "            i += 1\n",
    "            if i == num_runs:\n",
    "                break\n",
    "\n",
    "        self.total_n *= 100.0 / num_runs\n",
    "        self.total_q *= 100.0 / num_runs\n",
    "        self.total_l *= 100.0 / num_runs\n",
    "\n",
    "    def PlotN(self, root='species-n'):\n",
    "        \"\"\"Makes a scatter plot of simulated vs actual prev_unseen (q).\n",
    "        \"\"\"\n",
    "        xs, ys = zip(*self.n_seq)\n",
    "        if None in xs:\n",
    "            return\n",
    "\n",
    "        high = max(xs+ys)\n",
    "\n",
    "        thinkplot.Plot([0, high], [0, high], color='gray')\n",
    "        thinkplot.Scatter(xs, ys)\n",
    "        thinkplot.Save(root=root,\n",
    "                       xlabel='Actual n',\n",
    "                       ylabel='Predicted')\n",
    "\n",
    "    def PlotQ(self, root='species-q'):\n",
    "        \"\"\"Makes a scatter plot of simulated vs actual prev_unseen (q).\n",
    "        \"\"\"\n",
    "        thinkplot.Plot([0, 0.2], [0, 0.2], color='gray')\n",
    "        xs, ys = zip(*self.q_seq)\n",
    "        thinkplot.Scatter(xs, ys)\n",
    "        thinkplot.Save(root=root,\n",
    "                       xlabel='Actual q',\n",
    "                       ylabel='Predicted')\n",
    "\n",
    "    def PlotL(self, root='species-n'):\n",
    "        \"\"\"Makes a scatter plot of simulated vs actual l.\n",
    "        \"\"\"\n",
    "        thinkplot.Plot([0, 20], [0, 20], color='gray')\n",
    "        xs, ys = zip(*self.l_seq)\n",
    "        thinkplot.Scatter(xs, ys)\n",
    "        thinkplot.Save(root=root,\n",
    "                       xlabel='Actual l',\n",
    "                       ylabel='Predicted')\n",
    "\n",
    "    def PlotCalibrationCurves(self, root='species5'):\n",
    "        \"\"\"Plots calibration curves\"\"\"\n",
    "        print self.total_n\n",
    "        print self.total_q\n",
    "        print self.total_l\n",
    "\n",
    "        thinkplot.Plot([0, 100], [0, 100], color='gray', alpha=0.2)\n",
    "\n",
    "        if self.total_n[0] >= 0:\n",
    "            thinkplot.Plot(self.ps, self.total_n, label='n')\n",
    "\n",
    "        thinkplot.Plot(self.ps, self.total_q, label='q')\n",
    "        thinkplot.Plot(self.ps, self.total_l, label='l')\n",
    "\n",
    "        thinkplot.Save(root=root,\n",
    "                       axis=[0, 100, 0, 100],\n",
    "                       xlabel='Ideal percentages',\n",
    "                       ylabel='Predictive distributions',\n",
    "                       formats=FORMATS,\n",
    "                       )\n",
    "\n",
    "    def RunCalibration(self, seed, n_low, n_high, r, tr):\n",
    "        \"\"\"Runs a single calibration run.\n",
    "\n",
    "        Generates N and prevalences from a Dirichlet distribution,\n",
    "        then generates simulated data.\n",
    "\n",
    "        Runs analysis to get the posterior distributions.\n",
    "        Generates calibration curves for each posterior distribution.\n",
    "\n",
    "        seed: int random seed\n",
    "        \"\"\"\n",
    "        # generate a random number of species and their prevalences\n",
    "        # (from a Dirichlet distribution with alpha_i = conc for all i)\n",
    "        RandomSeed(seed)\n",
    "        n_actual = random.randrange(n_low, n_high+1)\n",
    "\n",
    "        hist, subhist, q_actual = GenerateFakeSample(\n",
    "            n_actual, \n",
    "            r, \n",
    "            tr, \n",
    "            self.conc)\n",
    "\n",
    "        l_actual = len(hist) - len(subhist)\n",
    "        print 'Run low, high, conc', n_low, n_high, self.conc\n",
    "        print 'Run r, tr', r, tr\n",
    "        print 'Run n, q, l', n_actual, q_actual, l_actual\n",
    "\n",
    "        # extract the data\n",
    "        data = [count for species, count in subhist.Items()]\n",
    "        data.sort()\n",
    "        print 'data', data\n",
    "\n",
    "        # make a Subject and process\n",
    "        subject = Subject('simulated')\n",
    "        subject.num_reads = r\n",
    "        subject.total_reads = tr\n",
    "\n",
    "        for species, count in subhist.Items():\n",
    "            subject.Add(species, count)\n",
    "        subject.Done()\n",
    "\n",
    "        self.RunSubject(subject, n_actual, q_actual, l_actual)\n",
    "\n",
    "    def RunSubject(self, subject, n_actual, q_actual, l_actual):\n",
    "        \"\"\"Runs the analysis for a subject.\n",
    "\n",
    "        subject: Subject\n",
    "        n_actual: number of species\n",
    "        q_actual: prevalence of unseen species\n",
    "        l_actual: number of new species\n",
    "        \"\"\"\n",
    "        # process and make prediction\n",
    "        subject.Process(conc=self.conc, iters=100)\n",
    "        subject.MakeQuickPrediction()\n",
    "\n",
    "        # extract the posterior suite\n",
    "        suite = subject.suite\n",
    "\n",
    "        # check the distribution of n\n",
    "        pmf_n = suite.DistN() \n",
    "        print 'n'\n",
    "        self.total_n += self.CheckDistribution(pmf_n, n_actual, self.n_seq)\n",
    "\n",
    "        # check the distribution of q\n",
    "        pmf_q = suite.DistQ()\n",
    "        print 'q'\n",
    "        self.total_q += self.CheckDistribution(pmf_q, q_actual, self.q_seq)\n",
    "\n",
    "        # check the distribution of additional species\n",
    "        pmf_l = subject.DistL()\n",
    "        print 'l'\n",
    "        self.total_l += self.CheckDistribution(pmf_l, l_actual, self.l_seq)\n",
    "\n",
    "    def CheckDistribution(self, pmf, actual, seq):\n",
    "        \"\"\"Checks a predictive distribution and returns a score vector.\n",
    "\n",
    "        pmf: predictive distribution\n",
    "        actual: actual value\n",
    "        seq: which sequence to append (actual, mean) onto\n",
    "        \"\"\"\n",
    "        mean = pmf.Mean()\n",
    "        seq.append((actual, mean))\n",
    "\n",
    "        cdf = pmf.MakeCdf()\n",
    "        PrintPrediction(cdf, actual)\n",
    "\n",
    "        sv = ScoreVector(cdf, self.ps, actual)\n",
    "        return sv\n",
    "\n",
    "\n",
    "def ScoreVector(cdf, ps, actual):\n",
    "    \"\"\"Checks whether the actual value falls in each credible interval.\n",
    "    \n",
    "    cdf: predictive distribution\n",
    "    ps: percentages to check (0-100)\n",
    "    actual: actual value\n",
    "\n",
    "    Returns: numpy array of 0, 0.5, or 1\n",
    "    \"\"\"\n",
    "    scores = []\n",
    "    for p in ps:\n",
    "        low, high = cdf.CredibleInterval(p)\n",
    "        score = Score(low, high, actual)\n",
    "        scores.append(score)\n",
    "\n",
    "    return numpy.array(scores)\n",
    "\n",
    "\n",
    "def Score(low, high, n):\n",
    "    \"\"\"Score whether the actual value falls in the range.\n",
    "\n",
    "    Hitting the posts counts as 0.5, -1 is invalid.\n",
    "\n",
    "    low: low end of range\n",
    "    high: high end of range\n",
    "    n: actual value\n",
    "\n",
    "    Returns: -1, 0, 0.5 or 1\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        return -1\n",
    "    if low < n < high:\n",
    "        return 1\n",
    "    if n == low or n == high:\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def FakeSubject(n=300, conc=0.1, num_reads=400, prevalences=None):\n",
    "    \"\"\"Makes a fake Subject.\n",
    "    \n",
    "    If prevalences is provided, n and conc are ignored.\n",
    "\n",
    "    n: number of species\n",
    "    conc: concentration parameter\n",
    "    num_reads: number of reads\n",
    "    prevalences: numpy array of prevalences (overrides n and conc)\n",
    "    \"\"\"\n",
    "    # generate random prevalences\n",
    "    if prevalences is None:\n",
    "        dirichlet = thinkbayes.Dirichlet(n, conc=conc)\n",
    "        prevalences = dirichlet.Random()\n",
    "        prevalences.sort()\n",
    "\n",
    "    # generate a simulated sample\n",
    "    pmf = thinkbayes.MakePmfFromItems(enumerate(prevalences))\n",
    "    cdf = pmf.MakeCdf()\n",
    "    sample = cdf.Sample(num_reads)\n",
    "\n",
    "    # collect the species counts\n",
    "    hist = thinkbayes.MakeHistFromList(sample)\n",
    "\n",
    "    # extract the data\n",
    "    data = [count for species, count in hist.Items()]\n",
    "    data.sort()\n",
    "\n",
    "    # make a Subject and process\n",
    "    subject = Subject('simulated')\n",
    "\n",
    "    for species, count in hist.Items():\n",
    "        subject.Add(species, count)\n",
    "    subject.Done()\n",
    "\n",
    "    return subject\n",
    "\n",
    "\n",
    "def PlotSubjectCdf(code=None, clean_param=0):\n",
    "    \"\"\"Checks whether the Dirichlet model can replicate the data.\n",
    "    \"\"\"\n",
    "    subject_map, uber_subject = ReadCompleteDataset(clean_param=clean_param)\n",
    "\n",
    "    if code is None:\n",
    "        subjects = subject_map.values()\n",
    "        subject = random.choice(subjects)\n",
    "        code = subject.code\n",
    "    elif code == 'uber':\n",
    "        subject = uber_subject\n",
    "    else:\n",
    "        subject = subject_map[code]\n",
    "\n",
    "    print subject.code\n",
    "\n",
    "    m = subject.GetM()\n",
    "\n",
    "    subject.Process(high=m, conc=0.1, iters=0)\n",
    "    print subject.suite.params[:m]\n",
    "\n",
    "    # plot the cdf\n",
    "    options = dict(linewidth=3, color='blue', alpha=0.5)\n",
    "    cdf = subject.MakeCdf()\n",
    "    thinkplot.Cdf(cdf, **options)\n",
    "\n",
    "    options = dict(linewidth=1, color='green', alpha=0.5)\n",
    "\n",
    "    # generate fake subjects and plot their CDFs\n",
    "    for _ in range(10):\n",
    "        prevalences = subject.suite.SamplePrevalences(m)\n",
    "        fake = FakeSubject(prevalences=prevalences)\n",
    "        cdf = fake.MakeCdf()\n",
    "        thinkplot.Cdf(cdf, **options)\n",
    "\n",
    "    root = 'species-cdf-%s' % code\n",
    "    thinkplot.Save(root=root,\n",
    "                   xlabel='rank',\n",
    "                   ylabel='CDF',\n",
    "                   xscale='log',\n",
    "                   formats=FORMATS,\n",
    "                   )\n",
    "\n",
    "\n",
    "def RunCalibration(flag='cal', num_runs=100, clean_param=50):\n",
    "    \"\"\"Runs either the calibration or validation process.\n",
    "\n",
    "    flag: string 'cal' or 'val'\n",
    "    num_runs: how many runs\n",
    "    clean_param: parameter used for data cleaning\n",
    "    \"\"\"\n",
    "    cal = Calibrator(conc=0.1)\n",
    "\n",
    "    if flag == 'val':\n",
    "        cal.Validate(num_runs=num_runs, clean_param=clean_param)\n",
    "    else:\n",
    "        cal.Calibrate(num_runs=num_runs)\n",
    "\n",
    "    cal.PlotN(root='species-n-%s' % flag)\n",
    "    cal.PlotQ(root='species-q-%s' % flag)\n",
    "    cal.PlotL(root='species-l-%s' % flag)\n",
    "    cal.PlotCalibrationCurves(root='species5-%s' % flag)\n",
    "\n",
    "\n",
    "def RunTests():\n",
    "    \"\"\"Runs calibration code and generates some figures.\"\"\"\n",
    "    RunCalibration(flag='val')\n",
    "    RunCalibration(flag='cal')\n",
    "\n",
    "    PlotSubjectCdf('B1558.G', clean_param=50)\n",
    "    PlotSubjectCdf(None)\n",
    "\n",
    "\n",
    "def main(script):\n",
    "    RandomSeed(17)\n",
    "    RunSubject('B1242', conc=1, high=100)\n",
    "\n",
    "    RandomSeed(17)\n",
    "    SimpleDirichletExample()\n",
    "\n",
    "    RandomSeed(17)\n",
    "    HierarchicalExample()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main(*sys.argv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
